RAII обертки мьютекса
#новичкам 

Иногда замечаю, что неопытные либо вообще не используют raii обертки над замками, либо используют их неправильно. Давайте сегодня разберемся с этим вопросом.

Для начала - для работы с мьютексами нужны обертки. Очень некрасиво в наше время использовать чистые вызовы lock и unlock. Это наплевательское отношение к современному и безопасному(посмеемся) С++.

Здесь прямая аналогия с выделением памяти. Для каждого new нужно вызывать соответствующий delete. Чтобы случайно не забыть этого сделать(а в большом объеме кода что-то забыть вообще не проблема), используют умные указатели. Это классы, используя концепцию Resource Acquisition Is Initialization, помогают нам автоматически освобождать ресурсы, когда они нам более не нужны.

Также для каждого lock нужно вызвать unlock. Так может по аналогии сделаем класс, который в конструкторе будет лочить мьютекс, а в деструкторе - разблокировать его?

Хорошая новость в том, что это уже сделали за нас. И таких классов даже несколько. Если не уходить в специфическую функциональность, то их всего 2. Это std::lock_guard и std::unique_lock.

lock_guard - базовая и самая простая обертка. В конструкторе лочим, в деструкторе разлачиваем. И все. Больше ничего мы с ним делать не можем. Мы можем только создать объект и удалить его. Даже получить доступ к самому мьютексу нельзя. Очень лаконичный и безопасный интерфейс. Но и юзкейсы его применения довольно ограничены. Нужна простая критическая секция. Обезопасил и идешь дальше.

```cpp

bool MapInsertSafe(std::unordered_map<int, int> map, const Key& key, Value value) {
	std::lock_guard lck(mtx);
	if (auto it = map.find(key))
		return false;
	else {
		it->second = std::move(value);
		return true;
	}
}
```

unique_lock же больше походит на std::unique_ptr. Уже можно получить доступ в объекты, поменяться содержимым с другим объектом unique_lock, поменять нижележащий объект на другой. Ну и раз мы все равно даем возможность пользователю получить доступ к нижележащему объекту, то удобно вынести в публичный интерфейс unique_lock те же методы, которыми можно управлять самим мьютексом. То есть lock, unlock, try_lock и тд - это часть интерфейса std::unique_lock.

Уже понятно, что этот вид обертки нужно использовать в более сложных случаях, когда функциональности lock_guard не хватает.

А в основном не хватает возможности использовать методы lock и unlock. Например, при работе в кондварами std::unique_lock просто необходим. Читатель заходит в критическую секцию, локает замок и затем видит, что определенные условия еще не наступили. Допустим еще нет данных для чтения. В такой ситуации надо отпустить мьютекс и заснуть до лучших времен. А при пробуждении  и наступлении подходящих условий, опять залочить замок и начать делать работу. 

```cpp
void worker_thread()
{

    std::unique_lock lk(m);
    cv.wait(lk, []{ return ready; });
	// process data
    lk.unlock();
}
```

Кондвар в методе wait при ложном условии вызывает unlock у unique_lock. При пробуждении и правдивом условии вызывает lock и ждет освобождения мьютекса.

По итогу: всегда используйте обертки над мьютексами! Они возможно спасут вашу жизнь. 

А уж какую обертку использовать подскажет сама задача.

Stay safe. Stay cool.

#concurrency 


Еще один плюс RAII
#опытным

Основная мотивации использования raii - вам не нужно думать об освобождении ресурсов. Мол ручное управление ресурсами небезопасно, так как можно забыть освободить их и вообще не всегда понятно, когда это нужно делать. 

Но не все всегда зависит от вашего понимания программы. Вы можете в правильных местах расставить все нужные освобождения, но код будет все равно небезопасен. В чем проблема? В исключениях.

Это такие противные малявки, которые прерывают нормальное выполнение программы в исключительных ситуациях. Так вот вы рассчитываете на "нормальное выполнение программы" и, исходя из этого, расставляете освобождения. А тут бац! И программа просто не доходит до нужной строчки.

```cpp
std::shared_ptr<Value> DB::SelectWithCache(const Key& key) {
	mtx_.lock();
    if (auto it = cache.find(key)) {
	    mtx_.unlock();
	    return it->second;
    } else {
	    std::shared_ptr<Value> result = Select(key);
	    cache.insert({key, result});
	    mtx_.unlock();
	    return result;
    }
}
```

Простой код запроса к базе с кэшом. Что будет в том случае, если метод Select бросит исключение? Мьютекс коннектора к базе будет навсегда залочен! Это очень печально, потому что ни один поток больше не сможет получить доступ к критической секции. Даже может произойти deadlock текущего потока, если он еще раз попытается захватить этот мьютекс. А это очень вероятно, потому что на запросы к базе скорее всего есть ретраи.

Мы могли бы сделать обработку исключений и руками разлочить замок:

```cpp
std::shared_ptr<Value> DB::SelectWithCache(const Key& key) {
	try {
		mtx_.lock();
	    if (auto it = cache.find(key)) {
		    mtx_.unlock();
		    return it->second;
	    } else {
		    std::shared_ptr<Value> result = Select(key);
		    cache.insert({key, result});
		    mtx_.unlock();
		    return result;
	    }
	}
	catch (...) {
		Log("Caught an exception");
		mtx_.unlock();
	}
}
```

Однако самое обидное, что исключения, связанные с работой с базой, мы даже обработать не может внутри метода SelectWithCache. Это просто не его компетенция и код сверху некорректен с этой точки зрения.

А снаружи метода объекта мы уже не сможем разблокировать мьютекс при обработке исключения, потому что это приватное поле.

Выход один - использовать RAII. 

```cpp
std::shared_ptr<Value> DB::SelectWithCache(const Key& key) {
	std::lock_guard lg{mtx_};
    if (auto it = cache.find(key)) {
	    return it->second;
    } else {
	    std::shared_ptr<Value> result = Select(key);
	    cache.insert({key, result});
	    return result;
    }
}
```

При захвате исключения происходит раскрутка стека и вызов деструкторов локальных объектов. Это значит, что в любом случае вызовется деструктор lg и мьютекс освободится.

Спасибо [Михаилу](https://t.me/grokaemcpp/569?comment=40106) за идею)

Stay safe. Stay cool.

#cpp11 #concurrency #cppcore #goodpractice 


Ревью

Сегодня вам на суд выносится довольно простой, может даже игрушечный, кусок многопоточного кода, чтобы даже начинающие смогли высказать, чем они в нем недовольны. Однако там несколько не самых очевидных подводных камней, так что будьте внимательны.

Для новичков, кто еще не видел эту рубрику. В рубрике #ревью мы выкладываем сюда отрывок кода, а вы в комментах по существу говорите, что в этом коде не так и как бы вы это исправили. Как бы вы это делали на реальном ревью в своем проекте. Того, кто найдет больше всего недостатков, я завтра упомяну в итоговом посте-компиляции из всех найденных проблем.

Вот собственно код:

```cpp
struct Task {
	void Execute() {
		// very long calculations
		std::this_thread::sleep_for(std::chrono::seconds(2));
	}
}; 

void WorkingThread(std::deque<Task> queue) {
	std::mutex mtx;
	mtx.lock();
	while (!queue.empty()) {
		auto elem = queue.front();
		queue.pop_front();
		elem.Execute();
		lck.unlock();
		// to get other threads opportunity to work
		std::this_thread::sleep_for(std::chrono::milliseconds(1));
		lck.lock();
	}
}

int main() {
	std::deque<Task> queue(10);
	std::thread thr1{WorkingThread, queue}, thr2{WorkingThread, queue};
}
```

Чего ждем? Айда в комменты поливать г(ЗАЧЕРКНУТЬ) ревьюить код.

Ask for objective critique. Stay cool.


Результаты ревью

Всем участникам спасибо за развернутые ответы. 

Итак, пойдем по порядку:

1 Очередь копируется в воркер потока, поэтому мы обрабатываем не просто копию очереди, а копии!. Каждый поток имеет свою копию. Это конечно не порядок. Меняем параметр функции на ссылку.

2 Но если вы думаете, что вы так передадите потоку ссылку - вы ошибаетесь! На самом деле для всех объектов-аргументов потоковой функции во внутреннем сторадже нового потока создается их копия, чтобы не иметь дело с висячими ссылками. Если вы хотите передать истинную ссылку в поток, то надо воспользоваться std::ref.

3 Нет join'ов у потоков. Надо их либо вызвать, либо использовать jthread из С++20.

4 Если вы используете мьютекс, это не значит, что все автоматически становится потокобезопасным. В этом примере мьютекс никак не защищает критическую секцию! А как он может защитить, если он является локальной переменной. То есть каждый поток будет иметь свою копию этого мьютекса. Не порядок. Его надо сделать либо глобальным вообще, либо статической локальной переменной.

5 Использование чистых вызовов lock и unlock на мьютексах является очень плохой практикой. В случае изначально пустой очереди или такого распределения расписания потоков, что очередь окажется пуста до входа в while, один из потоков никогда не отпустит лок. 
Да и вот это засыпание после execute выглядит очень криво.
Нужно использовать RAII обертки, типа std::lock_guard.

6 Но в нашем случае lock_guard будет плохим решением. Во-первых, не очень понятно, куда его вставлять. Изначальная проверка на пустоту тоже должна быть обезопашена. Тогда надо ставить до while. Но в этом случае один из потоков будет выполнять всю работу целиком. А нам хотелось бы использовать преимущества многопоточки. 

И еще один нюанс: у нас под локом выполняется довольно тяжелая функция, которая долго выполняется. И все это время другие потоки будут простаивать без дела. А если у нас со временем их станет больше? Еще больше простоя. А время - это деньги.

В общем, нехватает гибкости. Хочется иметь возможность отпускать замок на время, а потом опять его захватывать. Но и преимуществами RAII тоже хочется пользоваться.
Выход - std::unique_lock. Он позволяет делать и то, и то.

7 В изначальном примере происходит копия фронтального объекта очереди в переменную elem. Плохая история, копирования нужно избегать по возможности. На и не всегда оно возможно. Поэтому оборачиваем вызов front() в std::move, чтобы переместить фронтальный объект в новое место.

Не будет уж погружаться совсем далеко в дебри и не будет совсем переписывать кусок, чтобы в нем появлялись атомики, кондвары и бечконечный разбор очереди до graceful shutdown. 

Пусть этот пример останется "учебным", но теперь хотя бы корректным.

Вот исправленная версия.

```cpp
struct Task {
	void Execute() {
		// very long calculations
		std::this_thread::sleep_for(std::chrono::seconds(2));
	}
};

void WorkingThread(std::deque<Task>& queue) {
	static std::mutex mtx;
	std::unique_lock lck{mtx};
	while (!queue.empty()) {
		auto elem = std::move(queue.front());
		queue.pop_front();
		lck.unlock();
		try {
			elem.Execute();
		}
		catch(...) {
			std::cout << "Failed to execute task. Moving on."
		}
		lck.lock();
	}
}

int main() {
	std::deque<Task> queue(10);
	std::thread thr1{WorkingThread, std::ref(queue)}, thr2{WorkingThread, std::ref(queue)};
	thr1.join();
	thr2.join();
}
```

Если нравятся интерактивы - отметьте этот пост лайком и их будет больше на канале.

Fix your flaws. Stay cool.



Квиз
#новичкам

Сегодня довольно простой #quiz на знание оптимизаций. Для опытных людей совсем просто будет, но новичков, думаю, заставит задуматься.

У меня к вам всего один вопрос. Какой будет результат попытки компиляции и запуска следующего кода?

```cpp
#include <iostream>

struct Resource {
	Resource() {}
	Resource(const Resource &other) {
		std::cout << "copy\n";
	}
};

Resource getResource() {
	Resource a;
	return a;
}

int main() {
	Resource resource1 = getResource();
	Resource resource2(resource1);
}
```

Stay tricky. Stay cool.

Ошибка компиляции

copy

copy
copy

copy
copy
copy


Ответ

Для начала - это валидный С++ код, поэтому ошибки компиляции не будет. Да и не такой интересный этот вариант.

Теперь давайте пойдем в рассуждения, как бы это делал новичок. 

Смотрим на функцию getResource. Она возвращает объект по значению. Значит при вызове функции объект `a` будет скопирован в возвращаемый объект. Одна копия есть.

Дальше мы создаем объект resource1 из возвращаемого значения. Вот и вторая копия.

И при создании resource2 тоже будет копия.

Итого, ответ copy\ncopy\ncopy\n.

Но это неверный ответ!

Верный ответ: выведется copy. Один раз!

Все из-за оптимизации под названием copy elision. Она предотвращает вызов копирующего и перемещающего конструкторов при возврате объектов из функции по значению. Точнее это группа оптимизаций, некоторые имеют даже свои названия.

В данном случае используется Named Return Value Optimization или NRVO. Эта оптимизация позволяет возвращать **именованые** объекты из функции по значению и никаких лишних конструкторов не будет вызываться!

Именно с помощью таких оптимизации в эпоху до С++11 справлялись с отсутствием мув-семантики aka дешевого копирования

И именно из-за нее рассуждения о копии в getResource и resource1 неверные.

У нас кстати есть хорошая и более глубокая статья про RVO/NRVO [тык](https://t.me/grokaemcpp/136) для пытливых умов.

Avoid needless actions. Stay cool.

#optimization


Безымянный lock_guard

Бывает иногда, что при определение объекта забываешь что-то написать. Параметры конструктора, шаблонный параметр класса, точка с запятой - всякое бывает. Такое обычно спокойно детектируется на этапе компиляции и без проблем исправляется. Но вот есть одна "забывашка", которая может привести к действительно неприятным последствиям и не так просто детектируется.

Пишите вы такие критическую секцию. Например, просто хотите потокобезопасно обновить мапу. Как полагается в книжках, используете std::lock_guard, но забываете одну деталь.

```cpp

// std::map<std::string, int> SomeClass::map_;
// std::mutex SomeClass::mtx_;

void SomeClass::UpdateMap(const std::string& key, const std::string& value) {
	std::lock_guard{mtx_};
	auto result = map_.insert(key, value);
	return result.second;
}
```

Для С++17 вполне синтаксически верный код. И он будет запускаться. Но потокобезопасности не будет. 

Но как же! Я же использовал lock_guard!

Да вот только этот lock_guard безымянный. То есть является временным объектом. Соответственно, его деструктор вызовется ровно до insert'а и мьютекс освободится. А значит ничего безопасного тут нет.

Мапа будет теперь постоянно в неконсистентном состоянии и удачи потом в поиске этого места, особенно с замыленным глазом.

Вроде банальная ошибка, но на собесах даже опытные люди ее совершают. Так что будьте бдительны в следующий раз и будет вам многопоточное счастье!

Stay alerted. Stay cool.

#interview #cppcore 


Мапа и оператор[]
#новичкам

Не так редко можно увидеть код примерно такого вида:

```cpp
void UpdateFrequencies(const std::string& token) {
	if (map_.count(token)) {
		map[token]++;
	} else {
		map[token] = 1;
	}
}
```

Типа если в мапе нет ключа, то создаем там объект со значением 1, если есть, то просто инкрементируем значение.

Не знаю, почему многие боятся написать просто вот так:

```cpp
void UpdateFrequencies(const std::string& token) {
	map[token]++;
}
```

Наверное не знают пары секретиков. Сегодня я о них поведаю.

Первый - оператор[] для мапы создает объект, если его не было в мапе. То есть неважно, был ли ключ в мапе или нет, вы можете вызвать operator[] и ничего плохого не произойдет. Просто в словаре будет еще один ключ, если до этого не было.

Посмотрим на пример:

```cpp
struct CLASS {
	CLASS() {std::cout << "default" << std::endl; i = 0;}
	void operator++(int) {std::cout << "increment" << std::endl; i++; }
	int i;
};

int main() {
	std::map<std::string, CLASS> map;
	map["qwe"]++;
	std::cout << map["qwe"].i << std::endl;
}
```

Простая оберточка, чтобы показать все наглядно. Создаем пустую мапу и инкрементируем значение по ключу, которого в ней нет. И выводим значение после инкремента.

Вывод:
```
default
increment
1
```

То есть для значения нового элемента мапы вызывается конструктор по умолчанию. Объект создается налету.

Одно беспокойство убрали.

"Но тут в примере в дефолтном конструкторе вы явно инициализируете поле i в ноль. Почему реальное интовое значение в мапе будет выставляться в ноль?"

Потому что гарантируется value initialization при создания объектов в ассоциативных контейнерах.

Value инициализация для интовой переменной может выглядеть вот так:

```cpp
int();
int{};
int object{};
new int();
new int{};
```

Эффект value initialization на тривиальных типах - они инициализируются нулем.

```cpp
std::cout << int() << std::endl;
std::cout << int{} << std::endl;
int object{};
std::cout << object << std::endl;
std::cout << *(new int()) << std::endl;
std::cout << *(new int{}) << std::endl;
```

Вывод:
```
0
0
0
0
0
```

Этих двух "секретных знаний" достаточно, чтобы не бояться изменять значения в словарях даже если желаемого ключа в нем нет.

Know secrets. Stay cool.

#cppcore #STL


std::visit

Не так уж и просто работать с вариантными типами. Надо точно знать, какого типа объект находится внутри. Если не угадали - получили исключение. Ну или тестить объект на содержание в нем конкретного типа с помощью лапши из if-else.

Так вот чтобы голова не болела при работе с std::variant надо 2 раза в день после еды принимать std::visit.

Эта функция позволяет применять функтор к одному или нескольким объектам std::variant. И самое главное, что вам не нужно беспокоиться по поводу того, какой именно объект находится за личиной варината. Компилятор все сам сделает. 

```cpp
template< class Visitor, class... Variants >  
constexpr visit( Visitor&& vis, Variants&&... vars );

template< class R, class Visitor, class... Variants >  
constexpr R visit( Visitor&& vis, Variants&&... vars );
```

Так выглядят ее сигнатуры. Первым параметром передаем функтор, дальше идут варианты.

Попробуем использовать эту функцию:

```cpp
using var_t = std::variant<int, long, double, std::string>;

std::vector<var_t> vec = {10, 15l, 1.5, "hello"};

for (auto& v: vec)
{
	var_t w = std::visit([](auto&& arg) -> var_t { return arg + arg; }, v);
	std::visit([](auto&& arg){ std::cout << arg; }, w);
}
//OUTPUT:
// 20 30 3 hellohello
```

Главное, чтобы функтор умел обрабатывать любую комбинацию типов, которую вы можете передать в него. Обратите внимание, что мы используем здесь generic лямбду, которая может принимать один аргумент любого типа.

Если вы хотите передать в std::visit несколько объектов, то функтор должен принимать ровно такое же количество аргументов и уметь обрабатывать любую комбинацию типов, которая может содержаться в вариантах.

```cpp
std::visit([](auto&&... arg){ ((std::cout << arg << " "), ..., (std::cout << std::endl)); }, vec[0], vec[1]);
std::visit([](auto&&... arg){ ((std::cout << arg << " "), ..., (std::cout << std::endl)); }, vec[0], vec[1], vec[2]);
// OUTPUT
// 10 15 
// 10 15 1.5
```

Используем здесь дженерик вариадик лямбду, чтобы она могла принимать столько аргументов, сколько нам нужно. И эта конструкция работает для любого количества переданных объектов std::variant;

Так что std::variant и std::visit - закадычные друзья и им друг без друга грустно! Не заставляйте их грустить.

Have a trustworthy helper. Stay cool.

#template #cpp17


Наследование? От лямбды? Ч1
#опытным 

Наследованием в языке С++ никого не удивить. Все постоянно его видят в коде и используют. Но что, если я вам скажу, что вы можете наследоваться от лямбды! Как? Давайте разбираться.

Как это вообще возможно?

Ну это не удивительно для тех, кто знает, чем на самом деле являются лямбды. Это по сути своей классы, чей тип знает только сам компилятор, с перегруженным оператором(). То, что ее называют безымянной функцией, это обман. Все у нее есть.

То есть это класс, у которого есть вполне конкретный метод и даже поля(тут зависит от того, что захватила лямбда).

Значит это вполне легальный кандидат на наследование!

Придется конечно немного поколдовать вокруг отсутствия имени, но для современного С++ это уже давно не проблема.

```cpp
template<class Lambda>
struct DerivedFromLambda : public Lambda
{
	DerivedFromLambda(Lambda lambda) : Lambda(std::move(lambda)) {}
	using Lambda::operator();
};

int main(){
	auto lambda = [](){return 42;};
	DerivedFromLambda child{lambda};
	std::cout << child() << std::endl;
}

// OUTPUT:
// 42
```

Ничего особенного. Мы просто создали класс-обертку над каким-то функциональным объектом и используем его оператор(), как свой.

Дальше создаем лямбду и создаем объект обертки, просто передавая лямбду в конструктор. Мы специально не указываем явно шаблонный параметр DerivedFromLambda, потому что мы не знаем настоящего имени лямбды. Мы даем возможность компилятору самому вывести нужный шаблонный тип на основании инициализатора. Это возможно благодаря фиче С++17 [Class Template Argument Deduction](https://t.me/grokaemcpp/14). 

Но даже и на С++11-14 можно написать подобное. Ведь у нас есть оператор decltype, который возвращает в точности тип того выражения, которое мы в него передали. Тогда мы бы создавали объект так:

```cpp
auto lambda = [](){return 42;};
DerivedFromLambda<decltype(lambda)> child{lambda};
```

Зачем это нужно только? К этому мы будем потихоньку подбираться следующие пару постов.

Do surprising things. Stay cool.

#template #cppcore #cpp11 #cpp17


Наследование? От лямбды? Ч2
#опытным

Лямбды - это функциональные объекты по своей сути. Объекты классов с перегруженным оператором(). Зачем вообще от такой сущности наследоваться? Можно же просто сделать обычный класс с такими же перегруженным оператором и расширять его сколько влезет.

Ну как будто бы да. От одной лямбды наследоваться особо нет смысла. А что насчет множественного наследования?

Идейно - наш наследник будет наследовать публичный интерфейс всех своих родителей. То есть в наследнике будет много перегруженных операторов() для разных входных параметров. Вот это уже чуть удобнее. Мы можем находу создавать объект, который единообразно с помощью перегрузок обрабатывать какие-то вещи.

Покажу чуть подробнее:

```cpp
template<class Lambda1, class Lambda2>
struct DerivedFromLambdas : public Lambda1, Lambda2
{
DerivedFromLambdas(Lambda1 lambda1, Lambda2 lambda2)
	: Lambda1(std::move(lambda1))
	, Lambda2{std::move(lambda2)} {}
using Lambda1::operator();
using Lambda2::operator();
};

int main(){
	DerivedFromLambdas child{[](int i){return "takes int";}, [](double d){return "takes double";}};
	std::cout << child(42) << std::endl;
	std::cout << child(42.0) << std::endl;
	return 0;
}
// OUTPUT:
// takes int
// takes double
```

Логика и механика те же, что и в прошлом посте. Только теперь мы налету конструируем объект, который умеет в 2 перегрузки функции. Если эти перегрузки действительно небольшие, то не особо понятно, зачем мне определять их как отдельные перегрузки отдельной функции. Это нужно будет их потом по коду искать. А тут все рядышком и смотреть приятно.

Только не наследуйтесь от нескольких лямбд, которые принимают одинаковый набор параметров. Компилятор не сможет разрезолвить, от какого конкретно родителя вы хотите вызвать перегрузку и билд упадет.

Дальние ряды уже начали догадываться зачем такая конструкция реально может быть нужна. Но все объяснения в следующий раз.

Have a sense. Stay cool.

#template #cppcore #cpp17

Наследование? От лямбды? Ч3

А давайте сделаем еще один шаг вперед. Зачем нам наследоваться от какого-то фиксированного количества лямбд? Не будем себя ничем ограничивать. Давайте наследоваться от произвольного количества!

```cpp
template<typename ... Lambdas>
struct DerivedFromLambdas : Lambdas...
{
	DerivedFromLambdas(Lambdas... lambdas) : Lambdas(std::forward<Lambdas>(lambdas))... {}
	
	using Lambdas::operator()...;
};
```

И что нам этот шаг дал?

Теперь мы можем благодаря variadic templates в компайл-тайме генерить структурки, которые включают произвольное количество различных вариантов вызвов оператора(). И слово "вариант" здесь неспроста.

Помните наш std::visit? Который применяет визитор к объекту варианта.

Так вот теперь мы можем налету делать наши визиторы!

```cpp
template<typename ... Lambdas>
struct Visitor : Lambdas...
{
	Visitor(Lambdas... lambdas) : Lambdas(std::forward<Lambdas>(lambdas))...
	{
	}
	using Lambdas::operator()...;
};

using var_t = std::variant<int, double, std::string>;

int main(){
std::vector<var_t> vec = {10, 1.5, "hello"};  
std::for_each(vec.begin(),
			  vec.end(),
			  [](const auto& v)
			  {
			  std::visit(Visitor{
				  [](int arg) { std::cout << arg << ' '; },
				  [](double arg) { std::cout << std::fixed << arg << ' '; },
				  [](const std::string& arg) { std::cout << std::quoted(arg) << ' '; } }
						, v);
			  });
}
```

Создаем вектор, который может содержать 3 типа. И не так уж просто обрабатывать элементы такого вектора. Но вооружившись std::visit и созданным налету нашим Visitor'ом мы играючи обошли все элементы и красиво вывели их на экран:

```
10 1.500000 "hello"
```

Визитор - довольно интересный паттерн. И круто, что мы с вами смогли до него дойти из, казалось бы, такой неочевидной темы, как наследование от лямбд.

Но вообще, конкретно вот эта конструкция с наследованием от лямбд и использование их операторов() в std::visit называется паттерн overload. Это стандартное и более короткое название для этого дизайн решения.

@monah_tuk напомнил о прекрасной тулзе, где вы можете посмотреть чуть более легкосмотрибельную версию вашего кода. Жмякнув [сюда](https://cppinsights.io/s/186879b8) вы сможете посмотреть, во что превращается код из этого поста и, возможно, понять чуть больше.

Visit your close ones. Stay cool.

#template #design #cpp17


Смешиваем std::visit и std::apply
#опытным

Подумал об интересном сочетании функций std::visit и std::apply. В прошлом посте мы в цикле проходились по вектору вариантов и к каждому элементу применяли std::visit. Но прикольно было бы просто взять и за раз ко всем элементам коллекции применить std::visit. Ну как за раз. Без явного цикла.

И такую штуку можно сделать для tuple-like объектов, среди которых std::pair, std::tuple и std::array. Функция [std::apply](https://t.me/grokaemcpp/539)может распаковать нам элементы этих коллекций и вызвать для них функцию, которая принимает в качестве аргументов все эти элементы по отдельности. Это же то, что нам нужно!

Давайте попробуем на примере std::array запихать все его элементы в функтор и лаконично вызвать std::visit.

```cpp
template<typename ... Lambdas>
struct Visitor : Lambdas...
{
	Visitor(Lambdas... lambdas) : Lambdas(std::forward<Lambdas>(lambdas))... {}
	using Lambdas::operator()...;
};

using var_t = std::variant<int, double, std::string>;

int main(){
	std::array<var_t, 3> arr = {1.5, 42, "Hello"};
	Visitor vis{[](int arg) { std::cout << arg << ' '; },
				[](double arg) { std::cout << std::fixed << arg << ' '; },
				[](const std::string& arg) { std::cout << std::quoted(arg) << ' '; } };
	
	std::apply([&](auto&&... args){(std::visit(vis, std::forward<decltype(args)>(args)), ...);}, arr);
}
```

Начало в целом такое же, только теперь у нас std::array. Нам интересна последняя строчка. 

В std::apply мы должны передать функтор, который может принимать любое количество параметров. Благо у нас есть вариадик лямбды, которые позволяют сделать именно это. Компилятор сам сгенерирует структуру, которая сможет принимать ровно столько аргументов, сколько элементов в массиве arr.

Дальше мы все эти аргументы распаковываем в серию вызовов std::visit так, чтобы каждый элемент массива передавался в отдельный std::visit. Естественно, все делаем по-красоте, с [perfect forwarding](https://t.me/grokaemcpp/123) и [fold-expression](https://t.me/grokaemcpp/194) на операторе запятая.

Выглядит клево!

Опять же оставляю [ссылочку](https://cppinsights.io/s/f4b37cee) на cppinsights с этим примером.

Look cool. Stay cool.

#template #cpp17



Время от времени в сети появляются комментарии и персонажи, которые продвигают нарротив, что алгосы не нужны.

Я понимаю их. Приходишь на собес и тебе предлагают решить совсем какую-то оторванную от реальности задачу. "Обведите острова на карте". Это почти смешно. Когда и кому эти навыки пригодятся - не понятно.

Однако не все лежит на поверхности.

На собеседовании интервьюеры решают очень важную и нетривиальную задачу - за очень ограниченное время понять, справится ли человек с будущими задачами или нет.

И нужен инструмент, который поможет это проверить. Именно таким инструментом и являются алгосы.

Во-первых, знания алгоритмов и структур данных - база компьютер сайенса. Без нее в плюсах особо делать нечего. Мы часто работаем на низких уровнях абстракций и высоких нагрузка, где знания базы просто жизненно необходимы.

Во-вторых, нужно абстрактный текст задачи уметь перенести на язык компьютерных сущностей. Это очень важный навык. Бизнес приносит задачи в формате "мне нужно клиенту отправлять пиццу квадракоптером". И важным этапом работы будет перенос этих слов на язык кода. Тут и требования надо уточнять, и в целом понимать, чего от тебя хотят(не все понимают).

В-третьих. Компьютерные сущности нужно правильно уметь перенести в код на конкретном языке. Тут хоть базово, но проверяются навыки работы непосредственно с языком.

в-четвертых. Нужно понять, что алгоритм работает. Для этого кандидат должен уметь тестировать свой код, в том числе и устно. Тесты в проекты нужны, никто с этим спорить не будет. Но вот прилетела вам бага с прода. И иногда ее сложно вопроизвести. Чтобы побороть багу нужно вычитывать много кода и пытаться найти в нем ошибки чисто имперически. Или написать дополнительные тесты. Так что устно проверить свой код на ошибки - это такая демо-версия обычной рабочей рутины и стрессовых событий.

Можно перечислять еще много. Но если все эти навыки нужны работодателю, то они нужны и нам всем. Алгоритмы нужны не только для собеседований, но и для реальной разработки. Они помогают стать более сильным специалистом в реальности и в глазах работодателя.

Какой вывод?

Нужно прокачиваться в алгоритмах. Можно конечно начать изучать все самостоятельно, но зная многих людей — без кнута извне их сложно заставить самообучаться. Поэтому предлагаю тебе пойти на курс от Яндекс Практикума — "Алгоритмы и структуры данных".

Хочешь писать эффективный код? Тебе туда.

Хочешь успешно проходить собесы? Тебе туда.

Хочешь качать мышцу компьютер сайенса? Тебе туда.

Хочешь знать, что за птица эта Дейкстра, где в коде можно встретить бор, и кто сделал кучу на дереве? Тебе тоже туда.

Все дороги идут туда. Так чего ждать?

Если сомневаешься, пройди бесплатный вводный тест - на нем поймешь формат обучения и разберешься, что тебя будет ожидать на курсе.




Сколько минимально нужно мьютексов, чтобы вызвать дедлок?
#опытным

Мы уже рассматривали [похожий вопрос](https://t.me/grokaemcpp/503) и на собесах правильными ответом будет 2. 2 потока локают по одному мьютексу и пытаются захватить тот замок, который уже находится во владении другого потока. Они будут пытаться бесконечно исполнение в них перестанет двигаться вперед.

Но это скорее для всех ЯП некий универсальный ответ. У всех языков немного разные подходы к многопоточности и немного отличающиеся инструменты для работы с ней. А что если мы не будем ориентироваться на общую универсальную для всех языков теорию многопоточного программирования и сфокусируется чисто на с++? Какой тогда будет ответ?

Ответы 0, 1, 2


Ответ
#опытным 

Правильный ответ - 0. Вообще ни одного мьютекса не нужно. Достаточно чтобы 2 потока запустились в попытке присоединить друг друга. Естественно, что они будут бесконечно ждать окончания работы своего визави.

Однако не совсем очевидно, как это организовать. Вот мы определяем первый объект потока и его надо запустить с функцией, которая ждем еще не существующего потока. 

Заметьте, что мы пытаемся сделать очень вещь. Так давайте же применим самые опасные вещи из плюсов и у нас все получится! Надо лишь добавить 50 грамм указателей и чайную ложку глобальных переменных. Получается вот такая каша:

```cpp
std::thread * t_ptr = nullptr;

void func1() {
	std::this_thread::sleep_for(std::chrono::seconds(1));
	t_ptr->join();
	std::cout << "Never reached this point1" << std::endl;
}

void func2(std::thread& t) {
	t.join();
	std::cout << "Never reached this point2" << std::endl;
}

int main() {
	std::thread t1{func1};
	t_ptr = new std::thread(func2, std::ref(t1));
	while(true) {
		std::this_thread::sleep_for(std::chrono::seconds(1));
	}
}
```

Все просто. Вводим глобальный указатель на поток. В функции первого потока мы даем время инициализировать указатель и присоединяем поток по указателю. А тем временем в main создаем динамический объект потока и записываем его по указателю t_ptr. Таким образом первый поток получает доступ ко второму. В функцию второго потока передаем объект первого потока по ссылке и присоединяем его. Обе функции после инструкции join выводят на консоль запись. 

Чтобы это все дело работало, нужно продлить существование основных потоков. В обратном случае, вызовутся деструкторы неприсоединенных потоков, а эта ситуация в свою очередь стриггерит вызов std::terminate. Поэтому делаем бесконечный цикл, чтобы иметь возможность посмотреть на этот самый дедлок.

И действительно. При запуске программы ничего не выводится. Более того, пока писался этот пост, программа работала и ничего так и не вывела. Учитывая, что потоки особо ничего не делают, то логично предположить, что ситуация и не поменяется.

Естественно, что потоков может быть больше и кольцо из ожидающих потоков может быть больше. Но это такой минимальный пример.

Если вы думаете, что это какая-то сова в вакууме, то подумайте еще раз. Владение потоками можно передавать в функции. Могут быть довольно сложные схемы организации взаимодействия потоков. И если вы присоединяете поток не в его родителе, то возникает благоприятные условия для возникновения такого безлокового дедлока. 

Поэтому лучше избегать такого присоединения, или быть супервнимательным, если вы уж решились вступить на эту дорожку.

Stay surprised. Stay cool.

#concurrency #cppcore


Дедлокаем один поток
#опытным

Мы привыкли, что для дедлоков нужно несколько потоков. Не удивительно. Давайте прочитаем определение дедлока по Коффману. Там речь про процессы, но если поменять слово "процесс" на "поток" ничего не изменится. Ну и перевод будет вольный.

Дедлок - это ситуация в коде, когда одновременно выполняются все следующие условия:

А ну, мальчики, играем поочереди. Только один поток может получить доступ к ресурсу в один момент времени.

У меня уже есть красный паровозик, но я хочу синий!. Поток в настоящее время хранит по крайней мере один ресурс и запрашивает дополнительные ресурсы, которые хранятся в других потоках.

Я тебя захватил, я тебя и отпущу. Ресурс может быть освобожден только добровольно потоком, удерживающим его.

Все: Я хочу твой паровозик! Каждый поток должен ждать ресурс, который удерживается другим потоков, который, в свою очередь, ожидает, когда первый поток освободит ресурс. В общем случае ждунов может быть больше двух. Важно круговое ожидание.

Судя по этому определению, минимальное количество потоков, чтобы накодить дедлок - 2.

Но это такая общая теория работы с многозадачностью в программах.

Определение оперирует общим термином ресурс. И не учитывает поведение конкретного ресурса и деталей его реализации. А они важны!

Возьмем пресловутый мьютекс. Что произойдет, если я попытаюсь его залочить дважды в одном потоке?

```cpp
std::mutex mtx;
mtx.lock();
mtx.lock();
```

Стандарт говорит, что будет UB. То есть поведение программы неопределено, компилятор может делать с кодом, что угодно.

Может, но обычно этого не происходит. Программа в большинстве случаев ведет себя по одному из нескольких сценариев.

1 Компилятор имплементировал умный мьютекс, который может задетектить double lock и, например, кинуть в этом случае исключение. 

2 Мьютекс у нас обычный, подтуповатый и он делает ровно то, что ему говорят. А именно пытается залочить мьютекс. Конечно у него ничего не получится и он вечно будет ждать его освобождения. Результат такого сценария - дедлок одного потока одним мьютексом!

Результат не гарантирован стандартом, но мой код под гццшкой именно так себя и повел. Поэтому теперь у вас есть еще один факт, которым можно понтануться перед коллегами или на собесах.

Be self-sufficient. Stay cool.

#concurrency #cppcore #compiler

Потокобезопасный интерфейс
#новичкам 

Не для всех очевидная новость: не всегда можно превратить класс из небезопасного в потокобезопасный, просто по уши обложившись лок гардами. Да, вызов конкретного метода будет безопасен. Но это не значит, что классом безопасно пользоваться.

Возьмем максимально простую реализацию самой простой очереди:

```cpp
struct Queue {
	void push(int value) {
		storage.push_back(value);
	}
	void pop() {
		storage.pop_front();
	}
	bool empty() {
		return storage.empty();
	}
	int& front() {
		return storage.front();
	}
private:
	std::deque<int> storage;
};
```

Она конечно потоконебезопасная. То есть ей можно адекватно пользоваться только в рамках одного потока.

Как может выглядеть код простого консьюмера этой очереди?

```cpp
while(condition)
	if (!queue.empty()) {
		auto & elem = queue.front();
		process_elem(elem);
		queue.pop();
	}
```

И вот мы захотели разделить обязанности производителя чисел и их потребителя между разными потокам. Значит, нам надо как-то защищать очередь от многопоточных неприятностей.

Бабахаем везде лок гард на один мьютекс и дело в шляпе!

```cpp
struct Queue {
	void push(int value) {
		std::lock_guard lg{m};
		storage.push_back(value);
	}
	void pop() {
		std::lock_guard lg{m};
		storage.pop_front();
	}
	bool empty() {
		std::lock_guard lg{m};
		return storage.empty();
	}
	int& front() {
		std::lock_guard lg{m};
		return storage.front();
	}
private:
	std::deque<int> storage;
	std::mutex m;
};
```

Все доступы к очереди защищены. Но спасло ли реально это нас?

Вернемся к коду консюмера:

```cpp
while(true)
	if (!queue.empty()) {
		auto & elem = queue.front();
		process_elem(elem);
		queue.pop();
	}
```

А вдруг после получения во время обработки последнего элемента  продюсер добавит в очередь еще один элемент? Тогда в 5 строчке из очереди выкинется совсем не тот элемент, который мы ожидаем! В итоге останемся без обработки новых данных и повторно обработанными старыми.

А вдруг у нас появится еще один консюмер? Тогда в первом из них мы можем войти условие, а в это время второй достанет последний элемент. Получется, что мы получим доступ к неинициализированной памяти в методе front.

То есть по факту в многопоточном приложении полученный стейт сущности сразу же утрачивает свою актуальность.

Что делать? Не только сами методы класса должен быть потокобезопасными. Но еще и комбинации использования этих методов тоже должны обладать таким свойством. И с данным интерфейсом это сделать просто невозможно.

Если стейт утрачивает актуальность, то мы вообще не должны давать возможность приложению получать стейт очереди. Нам нужны только команды управления. То есть push и pop.

```cpp
struct ThreadSafeQueue {
	void push(int value) {
		std::lock_guard lg{m};
		storage.push_back(value);
	}
	std::optional<int> pop() {
		std::lock_guard lg{m};
		if (!storage.empty()) {
			int elem = storage.front();
			storage.pop_front();
			return elem;
		}
		return nullopt;
	}
private:
	std::deque<int> storage;
	std::mutex m;
};
```

Внутри метода `pop` мы можем использовать проверять и получать стейт очереди, так как мы оградились локом. Возвращаем из него std::optional, который будет хранить фронтальный элемент, если очередь была непуста. В обратном случае он будет пуст.

Теперь консюмер выглядит так:

```cpp
while(true) {
	auto elem = queue.pop();
	if (!elem)
		process_elem(elem.value());
}
```

Можно конечно было использовать кондвары и прочее. Но я хотел сфокусироваться именно на интерфейсе. Теперь реализация просто не позволяет получать пользователю потенциально неактульные данные.

Stay safe. Stay cool.

#concurrency #design #goodpractice 


Не вызывайте пользовательский код по локом
#опытным

Вы пишите свой потокобезопасный класс, вставляете свои любимые примитивы синхронизации, обмазываете это все подходящим интерфейсом. И тут вам понадобилось вызвать какой-то пользовательский код, какой-нибудь метод или функцию, которую вы сами не писали. И вы это вставляете под замок. Ошибка!

А вдруг эта функция очень долго выполняется? Какой-нибудь долгий запрос к базе Тогда вы будете долго держать замок, что не очень хорошо. Другие потоки будут потенциально простаивать в ожидании вашего мьютекса. Это может сильно пессимизировать скорость обработки данных. Код под защитой должен быть максимально коротким.

А если функция сама использует блокировку? Локать несколько мьютексов подряд - плохая затея. Это повышает вероятность возникновения дедлока и придется заботиться о его предотвращении. Что довольно сложно сделать с кодом, который вы неполностью контролируете. 

А если функция кинет исключение, а вы блокируете мьютекс без оберток(осуждаем)? Сразу получили UB.

То есть делайте все приготовления за пределами критической секции. Достаньте из базы нужные данные, решите большую систему уравнений, посчитайте факториал че-го-нибудь, покурите(не пропаганда, администрация канала решительно осуждает никотин) и только потом локайте свою структуру данных, быстро поменяйте там что-нибудь и выходите. Вот примерно так оно должно быть.

```cpp
std::shared_ptr<Value> IStorage::SelectWithCache(const Key& key) {
	std::unique_lock ul{mtx_};
    if (auto it = cache.find(key)) {
	    return it->second;
    } else {
	    ul.unlock()
	    std::shared_ptr<Value> result = Select(key);
	    ul.lock()
	    cache.insert({key, result});
	    return result;
    }
}
```

Конечно, бывают всякие ситуации. Но, если у вас есть большая критическая секция, то это как минимум признак того, что неплохо бы посмотреть новым взглядом на это безобразие и, возможно, получится что-то улучшить.

#goodpractice 


https://stackoverflow.com/questions/2139724/design-options-for-a-c-thread-safe-object-cache


ref-qualified методы
#опытным

В С++ можно довольно интересными способами перегружать методы класса. Один из самых малоизвестных и малоиспользуемых - помечать методы квалификатором ссылочности.

Чтобы было понятнее. Примерно все знают, что бывают константные и неконстантные методы.

```cpp
struct SomeClass {
	void foo() {std::cout << "Non-const member function" << std::endl;}
	void foo() const {std::cout << "Const member function" << std::endl;}
};

SomeClass nonconst_obj;
const SomeClass const_obj;
nonconst_obj.foo();
const_obj.foo();

// OUTPUT
// Non-const member function
// Const member function
```

Константные объекты могут вызывать только константные методы. Поэтому мы можем перегрузить метод класса, чтобы он мог работать с константными объектами.

В примере видно что у константного объекта вызывается константная перегрузка.

По аналогии с cv-квалификаторами методов начиная с С++11 существуют ref-квалификаторы. Мы можем перегрузить метод так, чтобы он мог раздельно обрабатывать левые и правые ссылки.

```cpp
struct SomeClass {
	void foo() & {std::cout << "Call on lvalue reference" << std::endl;}
	void foo() && {std::cout << "Call on rvalue reference" << std::endl;}
};

SomeClass lvalue;
lvalue.foo();
SomeClass{}.foo(); 

// OUTPUT
// Call on lvalue reference
// Call on rvalue reference
```

Обратим внимание на сигнатуру методов. Метки ссылочных квалификаторов ожидаемо принимают форму одного и двух амперсандов, по аналогии с типами данных левых и правых сслылок соотвественно. Располагаются они после скобок с аргументами метода.

Работают они примерно также, как вы и ожидаете. lvalue-ref перегрузка вызывается на именованном объекте, rvalue-ref перегрузка - на временном.

Зачем это придумано? Здесь на самом деле большие параллели с cv-квалификацией методов. Допустим, у вас класс - это какая-то коллекция. И вы хотите давать пользователям доступ к элементам этой коллекции через оператор[]. Для неконстантных объектов удобно возвращать ссылку. А вот для константных возвращение ссылки - потенциальное нарушение неизменяемости объекта. Поэтому в таких случаях константный оператор может возвращать элемент по значению.

Также и с ссылочностью. В каких-то случаях оптимально или просто необходимо использовать для правых ссылок иную логику метода.

Подробнее об этом чуде-юде будем разбираться в следующих постах.

Stay flexible. Stay cool.

#cpp11 #design 

Совмещаем ссылочные и cv квалификаторы методов

Далеко не всегда очевидно, какая именно функция является лучшим кандидатом для перегрузки в том или ином случае. Да, когда это только & или &&, то все довольно просто. Но что получается, когда мы добавим константность методам?

Компилятор будет выбирать подходящую перегрузку по определенному алгоритму.

```cpp
struct SomeClass {
	void foo() & {std::cout << "Call on lvalue reference" << std::endl;} //1
	void foo() const & {std::cout << "Call on const lvalue reference" << std::endl;} //2
	void foo() && {std::cout << "Call on rvalue reference" << std::endl;} //3
	void foo() const && {std::cout << "Call on const rvalue reference" << std::endl;} //4
};
```

Дело в том, что все правые ссылки могут каститься к const lvalue reference, а левые к правым - ни при каких обстоятельствах. Неконстантные типы могут каститься к константным. И никак наоборот.

Исходя из этих правил компилятор и разрешает перегрузки. Пометил методы из примера порядковыми номерами, чтобы потом было легче делать отсылки

```cpp
SomeClass lvalue;
const SomeClass const_lvalue;

lvalue.foo();
const_lvalue.foo();
```

В случае `lvalue.foo()` вызываем перегрузку для неконстантной левой ссылки. Левые ссылки не могут приводиться к правым. Поэтому методы под номерами 3 и 4 не подходят. 
Неконстантные типы могут приводиться к константным. Поэтому нам подходят и 1, и 2 методы. Однако для вызова 2 придется сделать шажок - добавить константности, а для вызова первого - ничего. Поэтому выбирается первая перегрузка.

В случае `const_lvalue.foo()` вызываем перегрузку для константной левой ссылки. 3 и 4 также откидываем по тем же причинам. Однако в этот раз нам подходит лишь 2 перегрузка, так как константный тип не может быть приведен к неконстантному.

Итого вывод получится такой:

```
Call on lvalue reference
Call on const lvalue reference
```

Для rvalue ссылки нехитрыми рассуждениями можно прийти к правильному ответу о вызываемой перегрузке

```cpp
SomeClass.foo();
// OUTPUT
// Call on rvalue reference
```

Тут довольно все просто. Но самая жесть начинается, когда у нас нет какой-то перегрузки/перегрузок из полного набора. В следующий раз забомбардирую вас мини-квизами на эту тему. Посмотрим, как хорошо вы шарите за overload resolution.

Choose the right way. Stay cool.

#cppcore 


Мини-квизы

Сейчас пойдет пачка мини-квизов на проверку того, как хорошо вы понимаете выбор ref-qualified перегрузок. Для меньшей запутанности я буду оставлять все перегрузки в тексте кода, но закомменчу ненужные в каждом случае. Также подключены все необходимые инклюды и компиляция происходит под 17-1 стандарт.

```cpp
struct SomeClass {
	// void foo() & {std::cout << "Call on lvalue reference" << std::endl;} //1
	void foo() const & {std::cout << "Call on const lvalue reference" << std::endl;} //2
	void foo() && {std::cout << "Call on rvalue reference" << std::endl;} //3
	void foo() const && {std::cout << "Call on const rvalue reference" << std::endl;} //4
};

int main() {
	SomeClass lvalue;
	lvalue.foo();
	SomeClass{}.foo();
}
```

Варианты ответа:
Ошибка компиляции

Call on const lvalue reference
Call on rvalue reference

Call on const rvalue reference
Call on const lvalue reference

Ответ: Вызовутся методы 2 и 3 по порядку. За неимением неконстантной перегрузки для левых ссылок, остается только константная перегрузка для первого вызова.Во втором случае rvalue reference может приводиться к константной левой ссылке, но в этот раз есть более подходящие кандидаты на перегрузку. И самым подходящим будет 3 метод.

  
  
```cpp
struct SomeClass {
	// void foo() & {std::cout << "Call on lvalue reference" << std::endl;} //1
	void foo() const & {std::cout << "Call on const lvalue reference" << std::endl;} //2
	// void foo() && {std::cout << "Call on rvalue reference" << std::endl;} //3
	void foo() const && {std::cout << "Call on const rvalue reference" << std::endl;} //4
};

int main() {
	SomeClass lvalue;
	lvalue.foo();
	std::move(lvalue).foo();
}
```


Каков результат попытки компиляции и запуска кода выше?

Варианты ответа:
// ошибка компиляции

// Call on const lvalue reference
// Call on const rvalue reference

// Call on const lvalue reference
// Call on const lvalue reference

Ответ:
Вызовутся методы 2 и 4 по порядку. rvalue reference может приводиться к константной левой ссылке, но также может приводиться к const rvalue ref. Второе преобразование достигается меньшими усилиями, поэтому вызовется 4 метод.


```cpp
struct SomeClass {
	// void foo() & {std::cout << "Call on lvalue reference" << std::endl;} //1
	void foo() const & {std::cout << "Call on const lvalue reference" << std::endl;} //2
	// void foo() && {std::cout << "Call on rvalue reference" << std::endl;} //3
	void foo() const && = delete; //4
};

int main() {
	SomeClass lvalue;
	lvalue.foo();
	SomeClass{}.foo();
}
```

Варианты ответа:
// ошибка компиляции

// Call on const lvalue reference
// Call on const lvalue reference

Ответ: здесь будет ошибка компиляции на втором вызове. Для него подходили бы 3, 4 и 2 перегрузки в порядке приоритета. Но 3 нет, а следующая наиболее подходящая перегрузка удалена. Удаленные функции участвуют в разрешении перегрузки, поэтому компилятор решит, что мы хотим вызвать удаленную форму, и запретит нам это делать.

  
```cpp
struct SomeClass {
	void foo() & {std::cout << "Call on lvalue reference" << std::endl;} //1
	void foo() const & {std::cout << "Call on const lvalue reference" << std::endl;} //2
	// void foo() && {std::cout << "Call on rvalue reference" << std::endl;} //3
	// void foo() const && {std::cout << "Call on const rvalue reference" << std::endl;} //4
};

int main() {
	SomeClass lvalue;
	lvalue.foo();
	SomeClass{}.foo();
}
```
  
Варианты ответа
// ошибка компиляции

// Call on const lvalue reference
// Call on const lvalue reference

// Call on lvalue reference
// Call on const lvalue reference

Ответ: Вызовутся 1 и 2 методы. Для первого вызова идеальным кандидатом будет метод номер 1. Для второго, за неимением rvalue перегрузок, выберется 2 метод, так как любые rvalue ref могут приводиться к const lvalue ref.

  
```cpp
struct SomeClass {
	// void foo() & {std::cout << "Call on lvalue reference" << std::endl;} //1

	void foo() const & {std::cout << "Call on const lvalue reference" << std::endl;} //2

	void foo() && = delete; //3

	void foo() const && {std::cout << "Call on const rvalue reference" << std::endl;} //4
};

int main() {
	SomeClass lvalue;
	lvalue.foo();
	SomeClass{}.foo();
}
```

// ошибка компиляции

// Call on const lvalue reference
// Call on const rvalue reference

Ответ: ошибка компиляции на втором вызове. Удаленные функции участвуют в разрешении перегрузки. И даже если у нас есть методы 2 и 4, которые могут быть вызваны для rvalue ref, самым подходящим вариантом будет именно метод 3. А он удален. Поэтому компилятор решит, что мы хотим вызвать удаленную форму, и запретит нам это делать.

```cpp
struct SomeClass {
	// void foo() & {std::cout << "Call on lvalue reference" << std::endl;} //1
	void foo() const & {std::cout << "Call on const lvalue reference" << std::endl;} //2
	void foo() && {std::cout << "Call on rvalue reference" << std::endl;} //3
	// void foo() const && {std::cout << "Call on const rvalue reference" << std::endl;} //4
};

int main() {
	SomeClass lvalue;
	lvalue.foo();
	const_cast<const SomeClass&&>(lvalue).foo();
}
```


// ошибка компиляции

// Call on const lvalue reference
// Call on rvalue reference

// Call on const lvalue reference
// Call on const lvalue reference

Ответ: Оба раза вызовется 2 метод. Для первого вызова единственным подходящим кандидатом будет 2 метод. Второй вызов похитрее - мы конст кастом кастим lvalue к const rvalue ref и потом вызываем метод. Для rvalue у нас есть перегрузка, однако для константных объектов она не может быть выбрана. Поэтому для второго вызова единственным подходящим вариантом будет 2 метод.





https://stackoverflow.com/questions/21934810/why-a-class-has-only-one-destructor


Обзор книжки #1

Сегодня довольно необычный пост. Много людей любят читать книжки и часто спрашивают, что же им такого почитать, чтобы преисполниться познанием. Прислушиваемся к болям людей. И поэтому мы будем иногда делать разборы на клевые книжки по плюсовой тематике.

Но начнем не с базовых книжке. Есть один очень крутой фундаментальный труд по многопоточке в плюсах - "С++. Практика многопоточного программирования" Энтони Уильямса. Та самая знаменитая "Concurrency in Action".

Для большинства новичков(да и для опытных тоже, что уж скрывать) многопоточка - это какой-то отдельный мир. Опасный и неизведанный мир. И они начинают пробираться сквозь густые заросли мьютексов, атомиков и потоков совсем одни, вооружившись какими-то огрызками видосов и статей. 

Нужен нормальный, опытный гид, который сможет провести за ручку по всем ухабам, обучить человека всем азам и вооружить мощными практиками, чтобы он дальше сам мог жить в этом конкурентном мире.

Так вот Энтони Уильямс - как раз такой гид. Все в книге разложено четко и выверено. 

1 Сначала погружаемся в саму концепцию параллелизма и многозадачности. Понимаем ее преимущества, способы организации и требования. И наконец-то понимаем разницу между потоками и процессами.

2 Изучаем самый простой механизм обеспечения безопасности - мьютекс.

3 Изучаем более сложные инструменты синхронизации - кондвары, фьючи, промисы.

4 Только после этого всего, когда вы уже наловчились думать в многопотоке и выявлять потенциальные проблемы, он переходит к модели памяти и атомикам. Тут конечно, все не просто и эта тема очень сложна для понимания. Возможно придется перечитывать несколько раз.

После этого можно сказать, что вы знаете про все инструменты из threading STL. И вас можно отпускать. Но нет!

Знание инструментов не равно способности их применять. И вот остальная часть книжки посвящена проектированию потокобезопасных структур данных, лок-фри структур данных и, в целом, проектированию многопоточных систем. Там вы научитесь именно что применять инструменты, которые вы выучили.

Хотите знать, что делать с проблемами обработки исключений в многопотоке? А с нюансами проектирования интерфейса потокобезопасных структур данных? Вот такие тонкости там разбираются.

Кому подойдет эта книга? Да вообще всем. Вкатунам в многопоточку, чтобы просто уметь читать и понимать этот код. Даже не обязательно всю книгу читать. Джунам, которые хотят нарабатывать уже практические навыки и что-то писать самим. Миддлам и сеньорам - для углубления своих знаний и познания тех самых деталей, в которых дьявол скрывается.

Я сам начинал познание многопоточки именно с нее. Тогда была версия только для 14-х плюсов(сейчас уже для 17-х). Есть такие книги, которые читаешь снова и снова. И с каждым прочтением переосмысливаешь свои знания и по-другому смотришь на мир. Вот это одна из таких книжек. Но вот реально, каждый раз читаю и что-то новое узнаю. Моя любимая часть - модель памяти, лок-фри программы. Там всегда взрыв мозга и новые инсайты.

Знаю, знаю. У вас в голове уже вопрос: "Куда деньги нести? Дайте мне уже это золото!"

Не спешите. Специально для наших подписчиков мы совместно с издательством "[Питер](https://www.piter.com/collection/kompyutery-i-internet)" проводим розыгрыш одного экземпляра этой замечательной книги в печатном виде!

Все, что вам надо сделать, чтобы поучаствовать в розыгрыше - написать один раз в комментариях под этим постом слово "Конкурс". Повторные комментарии будут удаляться.

Знаю, что много наших читателей читают посты не сразу, а скопом раз в недельку. Поэтому шанс залететь у всех будет еще ровно 7 дней, начиная с этого момента. На 8 день выйдет пост с результатами.

Победителя естественно выберем рандомайзером.

Если вы уже читали эту книжку, то оставьте свои впечатления о ней в комментах.

Be lucky. Stay cool.

#books


Безопасный для исключений new
#опытным

Большинство приложений не могут физически жить без исключений. Даже если вы проектируете все свои классы так, чтобы они не возбуждали исключений, то от одного вида exception'ов вы вряд ли уйдете. Дело в том, что оператор new может бросить std::bad_alloc - исключение, которое говорит о том, что система не может выделить нам столько ресурсов, сколько было запрошено.

Однако мы можем заставить new быть небросающим! Надо лишь в скобках передать ему политику std::nothow:

```cpp
MyClass * p1 = new MyClass; // привычное использование
MyClass * p2 = new (std::nothrow) MyClass; // небросающая версия
```

В первом случае при недостатке памяти выброситься исключение. А во втором случае - вернется нулевой указатель. Прям как в std::malloc.

Так что, если хотите избавиться от исключений - вот вам еще один инструмент.

#cppcore 

Еще один способ сделать new небросающим
#опытным 

Дело в том, что new - не совсем ответственнен за поведение при недостатке памяти. По плюсовой традиции тут можно кастомизировать почти все. Встречайте: std::new_handler.

Это такой typedef'чик:

```cpp
typedef void (*new_handler)();
```

И алиас для функций, которые отвечают за обработку ситуации нехватки памяти. И вызываются они аллоцирующими функциями operator new и operator new[].

Чтобы установить такой хэдлер используется функция std::set_new_handler:
```cpp
std::new_handler set_new_handler(std::new_handler new_p) noexcept;
```

Она делает new_p новой глобальной функцией нового обработчика и возвращает ранее установленный новый обработчик.

 Предполагаемое назначение хэндлера - одна из трех вещей:

1 Сделать больше памяти доступной. (За гранью фантастики)

2  Залогировать проблему и завершить программу (например, вызовом std::terminate) +. Если вам плевать на graceful shutdown, то ок.

3 Кинуть исключение типа std::bad_alloc или его отпрысков с какой-нибудь кастомной надписью и/или залогировать проблему.

Раз std::new_handler - алиас на указатель функции, то что будет, если мы передадим nullptr в качестве хэндлера?

На самом деле это и делается по умолчанию. При старте программы nullptr выставляется в качестве хэндлера. При невозможности выделить память operator new вызывает std::get_new_handler. Если указатель на функцию нулевой,  то в этом случае new ведет себя дефолтно - просто кидает исключение std::bad_alloc. В ином случае вызывает хэндлер.

С обработчиками есть один нюанс.

Если обработчик успешно заканчивает работу, то operator new повторяет ранее неудачную попытку выделения и снова вызывает обработчик, если выделение снова не удается. Чтобы закончить цикл, new-handler может вызвать std::set_new_handler(nullptr): если после неудачной попытки new обнаружит, что std::get_new_handler возвращает нулевое значение указателя и выбросит std::bad_alloc.

Примерно так это работает:

```cpp
void handler()
{
    std::cout << "Memory allocation failed, terminating\n";
    std::set_new_handler(nullptr);
}
 
int main()
{
    std::set_new_handler(handler);
    try
    {
        while (true)
        {
            new int[1000'000'000ul]();
        }
    }
    catch (const std::bad_alloc& e)
    {
        std::cout << e.what() << '\n';
    }
}
```

Пользуйтесь, чтобы оставлять на проде девопсерам сообщение: "А че так мало памяти в конфиге пода прописано, мм?"

Спасибо @Nikseas_314 за идею для поста)

Customize your tools. Stay cool.
#memory #cppcore

Почему мы везде не используем nothrow new?
#опытным

В прошлый раз мы обсудили, что существует форма оператора new, которая не возбуждает исключений, а вместо этого при ошибке возвращает нулевой указатель. Однако я почему-то уверен, что большинство из вас впервые увидели эту форму. Почему же ее практически нигде не используют?

1  В современных плюсах вообще не часто можно увидеть прямой вызов new. Контейнеры и функции helper'ы std::make_* инкапсулируют в себе аллокации. И только в очень специфических кейсах явный вызов new оправдан. Поэтому пул примеров в принципе очень небольшой.

2 Представьте, что у вас закончилась память и nothrow new вернул вас nullptr. Можете ли вы локально обработать ошибку недостатка памяти? 99.9%, что нет. Поэтому вы будете вести эту ошибку по всему стеку вызовов до того места, где ее возможно обработать. То есть весь проект должен быть построен с учетом возможности возврата ошибки и постоянной проверкой этих ошибок.

3 И все же есть те люди, которых устраивает такая форма проекта с возвратом ошибки из функции и постоянной ее проверкой. Но если немного подумать, то выяснится, что очень часто ошибку недостатка памяти вы примерно никак не сможете обработать, кроме как напишите об этом в лог. То есть, шо словите вы std::bad_alloc, шо просто напишите об этом в лог - разница не большая.

Раз разница небольшая, мы можем обработать ошибку только на определенном слое приложения, а исключения предоставляют возможность централизованной их обработки, то давайте только там и поставим эту обработку.В одном единственном месте. Скорее всего это будет где-то в функции main или в главной функции потока.  

То есть работать с этим исключением банально проще, чем обрабатывать nullptr. Именно поэтому вы скорее всего вообще не увидите nothrow new.

Handle problems easily. Stay cool.

#cppcore


Когда мы вынуждены явно использовать new
#опытным 

Сырые указатели - фуфуфу, бееее. Это не вкусно, мы такое не едим. new expression возвращает сырой указатель на объект. Соотвественно, мы должны максимально избегать явного использования new. У нас все-таки умные указатели и функции std::make_* довольно давно завезли.

Однако все-таки есть кейсы, когда мы просто вынуждены использовать new явно:

1 std::make_unique не может в кастомные делитеры. Если хотите создать уникальный указатель со своим удалителем - придется использовать new.

```cpp
auto ptr = std::unique_ptr<int, void(*)(int*)>(new int(42), [](int* p) {
    delete p;
    std::cout << "Custom deleter called!\n";
});
```

2 Приватный конструктор у класса. Странно вообще пытаться создать объект такого класса, но не торопитесь. Приватный конструктор может быть нужен, чтобы оставить только один легальный способ создания объекта - фабричную функцию Create. Она возвращает уникальный указатель на объект и обычно является статическим членом класса. Функция Create имеет доступ к приватным методам, поэтому может вызвать конструктор. Но вот std::make_unique ничего не знает о приватных методах класса и не сможет создать объект. Придется использовать new.

```cpp
struct Class {
	static std::unique_ptr<Class> Create() {
		// return std::make_shared<Class>(); // It will fail.
		return std::unique_ptr<Class>(new Class);
	}
private:
	Class() {}
}
```

3 Жизнь без 20-го стандарта. До 20-го стандарта вы не могли создать объект POD класса без указания фигурных скобок. Но именно так и делает std::make_unique.

То есть вот так нельзя делать в С++17:
```cpp
struct MyStruct {
	int a, b, c;
};
auto ptr = std::make_unique<MyStruct>(1, 2, 3); // Will fail C++17
auto ptr = std::unique_ptr<MyStruct>(new MyStruct{1, 2, 3}); // Norm
```

Но можно в С++20. Так что тем, кто необновился, придется использовать new.

В целом, все. Если что забыл - накидайте в комменты.

Но помимо этого, администрация этого канала не рекомендует в домашних и рабочих условиях явно вызывать new. Это может привести к потери конечности(отстрелу ноги).

Stay safe. Stay cool.

#cppcore #memory #cpp20 #cpp17


Ограничения в конструировании POD типов
#опытным 

Довольно часто приходится работать с plain old data типами. Они не имеют никаких специальных методов и конструкторов, это просто структуры с полями. Например:

```cpp
struct Point {
	int x;
	int y;
	int z;
}
```

Создают объекты таких типов с помощью синтаксиса универсальной инициализации через фигурные скобки {}:

```cpp
Point p{1, 2, 3};
Point p(1, 2, 3); // Wrong
```

При этом через круглые скобки создать объект такого класса нельзя.

С повсеместным использованием универсальной инициализации с точки зрения код стайла создание таких объектов даже не выбивается из общего кода.

Но все-таки у этого есть проблемы.

Часто такие структурки хочется хранить в каком-нибудь векторе. Для добавления в вектор можно использовать push_back и emplace_back. Использование emplace_back выгоднее по перформансу, поэтому нужно обычно использовать именно этот метод.

emplace_back принимает в себя аргументы для конструирования объекта и создает объект прямо на том месте, где он и должен быть, минуя всякие мувы и копирования. Но с POD типами он работает хреново.

```cpp
std::vector<Point> vec;
vec.emplace_back(1, 2, 3); // Error!
```

Вот так вы написать не можете. emplace_back под капотом использует создание объекта с помощью new именно через круглые скобки. А как мы помним, так инициализировать POD типы нельзя.

Поэтому приходится в этих случаях либо явно конструировать объект и вызывать мув-конструктор:

```cpp
vec.emplace_back(Point{1, 2, 3});
```

что убивает преимущества emplace_back перед push_back. Либо использовать непросредственно push_back.

Та же проблемы и в использовании функций std::make_\*. Под капотом они тоже используют new с круглыми скобками и просто невозможно нормально использовать эти функции. Приходится явно вызывать new с фигурными скобками, что усугубляет проблему:

```cpp
std::unique_ptr<Point>(new Point{1, 2, 3}); 
```

Конечно кейс с emplace_back намного чаще встречается в практике. POD типам не нужны фабличные методы и, обычно, контроль времени жизни.

В общем, не жизнь, а страдания.

Однако есть свет в конце тоннеля! Но об этом в следующий раз.

See the light. Stay cool.

#cppcore 


Фиксим проблему с конструированием POD типов
#опытным 

В прошлом посте говорили о том, что тяжело POD типам работать с функциями, которые внутри себя вызывают new. Клятые скобки!

Это очевидные недоработки стандарта. Которые взяли и пофиксили в С++20!

Теперь объекты POD типов можно создавать как через фигурные скобки, так и через круглые. Хотя небольшая разница есть. Но это уже супердетали:

```cpp
struct A {  
  int a;  
  int&& r;  
};  
  
int f();  
int n = 10;  
  
A a1{1, f()};               // OK, lifetime is extended  
A a2(1, f());               // well-formed, but dangling reference  
A a3{1.0, 1};               // error: narrowing conversion  
A a4(1.0, 1);               // well-formed, but dangling reference  
A a5(1.0, std::move(n));    // OK
```

Теперь можно использовать все преимущества метода emplace_back и писать такой код:

```cpp
std::vector<Point> vec;
vec.emplace_back(1, 2, 3);
```

Вроде мелочь, а раньше это выбивало из колеи. Правило almost always use emplace_back здесь не работало. А push_back кстати спокойно переваривал следующий код:

```cpp
std::vector<Point> vec;
vec.push_back({1, 2, 3});
```

Пуш бэк принимает аргументом уже сконструированный объект нужного типа. И компилятору достаточно знаний о типе вектора и фирурных скобок, чтобы понять, как конструируется объект.

Как видите здесь нет явного указания типа. И это работало до 20-х плюсов и было причиной делать исключения для правила с emplace_back'ом. Сравните:

```cpp
std::vector<Point> vec;
vec.push_back({1, 2, 3});
vec.emplace_back(Point{1, 2, 3});
```

Больше букав! А если название структуры длинное? Вот вот.

Ну и функции std::make_* тоже работают как надо с POD типами.

Теперь наши пальцы сильнее защищены от стачивания, что не может не радовать!

Enjoy small things. Stay cool.

#cppcore #cpp20 


emplace_back vs push_back
#новичкам 

Раз уж такая масленица пошла, расскажу про весь сыр-бор с методами вектора(да и не только вектора).

В последовательные контейнеры можно запихнуть данные в конец двумя способами: метод push_back и метод emplace_back.

```cpp
template< class... Args >  
reference emplace_back( Args&&... args ); // returns ref to created element

void push_back( const T& value );
void push_back( T&& value );
```

По сигнатуре видно, что они предназначены немного для разного.

Начнем со сложного. emplace_back принимает пакет параметров. Эти параметры предполагаются как аргументы конструктора хранимого типа T.  Реализован он примерно так:
```cpp
template <typename... Args>
    reference emplace_back(Args&&... args) {
        if (size == capacity) grow();
        return *new (start + size++) T(std::forward<Args>(args)...);
    }
```

Если надо, то расширяемся и делаем placement new на участке памяти для нового объекта, попутно используя perfect forwarding для передачи аргументов в конструктор. Вот тут кстати те самые круглые скобки используются.

push_back принимает ссылку на уже готовый объект. То есть объект должен быть создан до входа в метод. И на основе этого значения уже конструируется объект в контейнере. В простейшем случае push_back вызывает внутри себя emplace_back:

```cpp
void push_back(T&& value) {
	emplace_back(std::move(value));
}
```

Чтобы вызвать пуш бэк нужно вызвать 2 конструктора: от аргументов и copy|move. Для emplace_back же нужен только один конструктор - от аргументов. 

То есть emplace_back банально эффективнее, чем push_back. Для случаев, когда мы почему-то не можем создать объект внутри emplace_back(POD типы и < С++20) мы его создаем снаружи и копируем/муваем внутрь. Тогда эффективности двух методов одинаковая.

Получается, что emplace_back в любом случае не менее эффективнее, чем push_back. Именно поэтому нужно всегда предпочитать использовать emplace_back.

Be just better. Stay cool.

#STL




**Считаем единички**
#задачки

Меня всегда забавляли задачки на бинарное представление чисел. Всегда можно найти занимательные и новые для себя подходы.

Вроде бы простая и популярная задача: посчитать количество единиц в битовом представлении числа. Уверен, что большинство из вас решали эту задачу.

Однако популярный подход - не самый эффективный, элегантный и интересный.

Благо существует множество непопулярных, но очень интересных решений! О них я расскажу в завтра в ответном посте.

А пока предлагаю вам порешать эту задачку. Если вы знаете какие-то нетривиальные решения, то расскажите о них в комментах тоже.

А чтобы умудренным опытом людям было немного интереснее, давайте ограничим условия. Задачу надо решить либо за константное время(в среднем), либо за наименьшее количество строчек. Выражения вне цикла for разделенные символом `;` считаются разными строчками.

```cpp
int count_ones(int num) {
	// Here your code
}
```

Challenge yourself. Stay cool.


**Считаем единички**. Решения

Давайте быстро пробежимся через самое банальное решение. Нужно в цикле проверять по маске последний бит числа и сдвигать его вправо, пока число не превратится в ноль.

```cpp
int count_ones(unsigned num) {
	int result = 0;
	while(num > 0) {
		result += num & 1;
		num >>= 1;
	}
	return result;
}
```

Алгоритмическая сложность этого решения - О(log(num)).
Что может быть интереснее? Например, знали ли вы, что выражение num & (num - 1) лишает число его самой правой единички? Посмотрите сами:

```
10 = 1010
1010 & (1010 - 1) = 1010 & 1001 = 1000

118 = 111011
111011 & (111011 - 1) = 111011 & 111010 = 111010
```

Поэтому в цикле, вместо сдвига числа вправо можно просто бинарно умножать число на это же число, уменьшенное на единицу. Даже считать отдельно ничего не нужно, количество итераций цикла определять число единичек. Это кстати в среднем в 2 раза эффективнее, чем просто каждый раз смотреть последний бит числа, но ассимптотическую сложность не меняет. Ну и для любителей кода покороче, все это можно написать так:

```cpp
int count_ones(unsigned num) {
	int result = 0;
	for(; num > 0; num &= (num - 1), ++result);
	return result;
}
```

А что насчет самого короткого решения? Зачем писать велосипед, если можно просто воспользоваться встроенной функцией компилятора(или С++20 фичей):

```cpp
int count_ones(unsigned num) {
	return std::popcount(num); 
	// or compiler extension 
	// return __builtin_popcount(num);
}
```


А что, если мы хотим константную сложность? Такое вообще возможно?

Конечно. Нам потребуется всего sizeof(num)* 8 итераций цикла, чтобы найти нужное число. Константа? Да. Эффективно ли это? Нет 

Однако давайте подумаем еще чуть-чуть. Комбинаций битов в инте на самом деле не такой уж и и много. Всего 2^32. Можно создать массив байтов на 2^32 элементов и в каждой ячейке хранить количество единичек для числа равного индексу этой ячейки. Мы это как-то можем заранее нагенерить(или при первом вызове функции) и потом все вызовы функции count_ones будут занимать константное время. Правда памяти сожрется на это предостаточно.

```cpp
static std::array<uint8_t, std::numeric_limit<uint32_t>::max()> ones;
// somehow fill array
int count_ones(unsigned num) {
	return ones[num];
}
```

Кстати полезный ход. Иногда из-за сильных ограничений по входным данным задачи ее можно решить намного более оптимальным способом.

Если боитесь больших массивов, то можно немного схитрить. Мы можем запомнить в таблице количество единиц для каждого возможного байта, разбить число на 4 части, найти для этих частей количество хранящих в них единичек по таблице и сложить это дело. Получится, что нужно всего 256 байт доп памяти и 4 итерации цикла.

Но массив можно сделать еще меньше, если брать по 4 бита(тетрад). Различных тетрадов всего 16 штук, поэтому и нужно будет всего 16 байт доп памяти и 8 итераций цикла. Спасибо, @tutralex, за решение)

```cpp
int BitOnesCount(unsigned n)
{
	static unsigned char c[16]={0,1,1,2,1,2,2,3,1,2,2,3,2,3,3,4};
	int count=0;
	while (n!=0)
	{
		count+=c[n&0x0F];
		n>>=4;
	}
	return count;
};
```

В общем, вы поняли. Чем меньше массив, тем больше итераций цикла и наоборот. Выбирайте, что вам больше подходит.

Если вы еще не устали, то у меня для вас есть banger. Нахождение количества единичных бит в числе - это не просто задача с литкода. У нее есть практическое применение. Дело в том, что расстояние Хемминга для двоичных чисел- это количество символов, которое отличает данную строку битов от строки, заполненной нулями. То есть это и есть наше число единичек. Эта штука используется во многих дисциплинах, в том числе и криптографии. Не удивительно, что много народу совершенствовало решение этой задачи. На мой взгляд, самое мозгодробительное решение выглядит примерно так:

```cpp
int count_ones(unsigned num)
{
    num = (num & 0x5555555555555555 ) + ((num >>  1) & 0x5555555555555555 );
    num = (num & 0x3333333333333333 ) + ((num >>  2) & 0x3333333333333333 );
    num = (num & 0x0f0f0f0f0f0f0f0f ) + ((num >>  4) & 0x0f0f0f0f0f0f0f0f );
    num = (num & 0x00ff00ff00ff00ff ) + ((num >>  8) & 0x00ff00ff00ff00ff );
    num = (num & 0x0000ffff0000ffff ) + ((num >> 16) & 0x0000ffff0000ffff);
    return x;
}
```
Выглядит все это, как будто кот случайно блеванул на экран, но естественно у этой каши есть логичное объяснение, которое можете найти [тут](https://en.wikipedia.org/wiki/Hamming_weight).

Кому интересно, что же все-таки быстрее, то наш подписчик Леонид оставил по этому поводу [интересный комментарий](https://t.me/c/2009887601/41924).

Honorable mentions:
Питонисты часто в этой задаче упоминают, что они одной левой могут превратить число в бинарное представление, потом в строку и просто посчитать одной функцией количество вхождений единички. А мы вообще-то ничем не хуже! И даже лучше! Нам не нужно конвертировать бинарное представление в строку. Достаточно std::bitset и его метода count:

```cpp
int count_ones(unsigned num) {
	return std::bitset<32>{num}.count();
}
```

Solve your problems. Stay cool.

Header only либы. Pros and cons.
#новичкам

Мы живем в мире С++, где почти нет ничего общепринятого. Часто даже не для очень специфичной задачи, типа сериализации, приходится искать какие-то сторонние решения и сравнивать их. Давайте отложим в сторону вопросы о качестве кода и дизайне и сконцентрируемся вот на чем. Какую библиотеку выбрать: уже скомпилированную или полностью header-only? Будем рассматривать вопрос с точки зрения header-only либ. Какие у них преимущества и недостатки?

Преимущества:

Упрощенный процесс сборки. Вам не нужно ничего компилировать библиотеку и в кишках симейка указывать кучу зависимостей. Подключил хэдэр, указал к нему путь и вперед!

Упрощенная поддержка. Если у вас есть скомпилированная библиотека, вы, вероятно, захотите создать несколько ее версий: одну скомпилированную с включенной отладкой, другую с включенной оптимизацией и, возможно, еще одну без символов. И, возможно, даже больше для мультиплатформенного приложения. Все это довольно сильно усложняет интеграцию библиотеки и будущее обновление.

Можно нормально дебажить. Большинство бинарных либ распространяются именно в релизной версии и их функции невозможно нормально дебажить. Я знаю, что большинство из вас дебажатся принтами и ваша хата с краю, но иногда очень полезно было бы иметь дебажную версию.

Большая переносимость. Не все компиляторы одинаково компилируют одни и те же сущности даже на одной и той же платформе. Ваша ддлка или сошник может просто по [ABI](https://t.me/grokaemcpp/102) вам не подходить. Хэдэр-онли либы приходится компилировать вместе с проектом, что убирает проблему несовместимости ABI.

Возможность использования нестандартной стандартной либы. Оксюморон? Может быть. Но иногда вам может понадобиться использовать либо свою, либо пропатченную стандартную библиотеку. Возможно, в вашем проекте запрещены вызовы каких-то стдшных функций или вы сами подкручиваете и оптимизируете код в узких местах. Тогда ваше единственное спасение - хэдэр онли либы. Только они позволят вашим изменениям отразиться на скомпилированном коде библиотечных сущностей.

Недостатки:

Крупные объектные файлы. Раз нам доступно определение сущностей, то мы можем попробовать их встроить. Это само по себе увеличивает размер бинарного файла. Так еще и на каждую единицу трансляции будет свое определение слабого символа этой сущности. Да, в конце они объединятся, но в объектные файлы все еще будут повторения.

Более длинная компиляция. Раз код еще не скомпилирован, то надо его скомпилировать. Причем даже те сущности, которые используются в нескольких единицах трансляции, придется компилировать в каждой из них отдельно. Большое обилие компилируемых сущностей и слабых символов сильно тормозят работу компилятора и линкера.

Перекомпиляция. При изменении исходников вам скорее всего будет нужно перекомпилировать весь проект. С бинарными либами такой проблемы нет. Перекомпилировать нужно только те единицы трансляции, которые непосредственно используют код библиотеки.

Кожаным труднее читать. Даже с лучшей документацией пользователям библиотеки часто приходится прибегать к чтению заголовков библиотеки. Заголовки в хэдэр-онли либах заполнены деталями реализации, которые мешают пониманию интерфейса. С скомпилированной библиотекой все, что вы видите, это интерфейс и краткий комментарий о том, что делает реализация, и это обычно все, что вам нужно. Даже так, ничего кроме этого вам не должно быть нужно! Нафиг детали реализации, концентрируемся на интерфейсе.

Как header only либы обходят ODR
#новичкам 

В С++ есть одно очень важное правило, которое действует при компиляции и линковке программы. Это правило одного определения. Или One Definition Rule(ODR). Оно говорит о том, что во всей программе среди всех ее [единиц трансляции](https://t.me/grokaemcpp/184) должно быть всего одно определение сущности.

Действительно, если будут 2 функции с одинаковыми названиями, но разной реализацией, то непонятно, какую из них выбрать для линковки с использующим функцию кодом.

Тогда встает вопрос: А как тогда header-only библиотеки обходят это требование? Сами посудите, подключаем какую-нибудь json заголовочную либу, везде ее используем, линкуем программу и все как-то работает. Хотя во многих единицах трансляции есть определение одних и тех же сущностей.

В чем подвох?

Подвоха нет. Даже так, чисто заголовочная природа библиотеки это не совсем цель, а следствие. Следствие того, что часто библиотеки напичканы шаблонами по самые гланды. А шаблоны просто вынуждены находиться в хэдэрах, ничего уж тут не поделаешь. У нас даже [целый пост](https://t.me/grokaemcpp/215) про это есть.

Сами посмотрите на некоторые примеры: [cereal](https://github.com/USCiLab/cereal) для сериализации, [nlohmann](https://github.com/nlohmann/json/tree/develop) для json'ов, почти весь Boost. Там все жестко шаблонами и измазано.

А там, где шаблоны неприменимы можно использовать [inline|static функции и поля класса](https://t.me/grokaemcpp/169), а также [анонимные пространства имен](https://t.me/grokaemcpp/157) .

В общем, в С++ есть много средств обхода ODR и ими всеми активно пользуются header-only библиотеки.


Еще одно отличие С и С++
#опытным 

Продолжаем рубрику, где мы развеиваем миф о том, что С - это подмножество С++. Вот предыдущие части: [тык](https://t.me/grokaemcpp/279) и [тык](https://t.me/grokaemcpp/111).

В С давно можно инициализировать структуры с помощью так называемой designated initialization. Эта фича позволяет при создании массива или экземпляра структура указать значения конкретным элементам и конкретным полям с указанием их имени! 

Например, хочу я определить разреженный массив из 100 элементов и только 3 их них я хочу инициализировать единичками. Не проблема! В С это можно сделать одной строчкой:

```c
int array[100] = {[13] = 1, [45] = 1, [79] = 1};
```

В плюсах такое можно сделать только с помощью нескольких инструкций.

```cpp
int array[100] = {};
array[13] = array[45] = array[79] = 1;
```

Не так удобно.

Можно даже задавать рэндж значений.

```c
int array[100] = {[13] = 1, [30 ... 40] = 1, [45] = 1, [79] = 1};
```

Теперь элементы с 31 по 41 будут инициализированы единичками. Очень удобно!

Для структур задавать значения полям можно вот так:

```c
struct point { int x, y, z; };

struct point p1 = { .y = 2, .x = 3 };
struct point p2 = { y: 2, x: 3 };
struct point p3 = { x: 1};
```

Нужно обязательно при инициализации указать конкретное поле, которому будет присвоено значение. При чем порядок указания полей неважен! А неупомянутые поля будут инициализированы нулем.

До С++20 в плюсах вообще не было подобного синтаксиса. Начиная с 20-х плюсов при создании объекта класса мы можем аннотировать, каким полям мы присваиваем значение. Но в плюсах намного больше ограничений: поля нужно указывать в порядке объявления в теле класса, никакой инициализации массивов и еще куча тонкостей.

Так что вот вам еще один пример, которым вы сможете парировать интервьюера на вопрос: "верно ли что С - подмножество С++?". Иначе где вам это еще пригодится?

Be different. Stay cool.

#goodoldc #cppcore #cpp20



Designated initialization
#опытным 

В продолжение предыдущего поста, почему бы нам не поговорить о том, что такое designated initialization в контексте С++ и какие особенности она имеет в языке.

Эта фича С++20, которая позволяет явно указывать поля, которым присваиваются значения, при создании объекта.

```cpp
struct Person {
	std::string name;
	std::string surname;
	std::string id;
};

struct Item {
	std::string name;
	double price;
	std::string id;
};

struct Order {
	Person person;
	Item purchase;
};
```

Пусть у нас есть заказ, который состоит из данных о человеке, который заказал товар, и самого заказанного товара. Мы хотим распарсить входящий запрос от клиента и сформировать структуру Order для дальнейшей обработки. Теперь мы можем сделать это очень просто и почти играючи.

```cpp
Order order{.person = {.name = "Golum",
					   .surname = "Iz shira",
					   .id = "666"},
			.purchase = {.name = "Precious",
						 .price = 9999999.9,	
						 .id = "13"},
			.pick_up_address = "Mordor"};
```

То, как мы указываем каждый член структуры и присваиваем ему значение - и есть designated initialization. Собственно пример показывает всю прелесть фичи. Теперь по коду явно видно, каким полям какое значение присваивается. Это сильно повышает читаемость кода.

Если хотите использовать наследование, то синтаксис такой:

```cpp
struct Person
{
	std::string name;
	std::string surname;
	unsigned age;
};

struct Employee : Person
{
	unsigned salary;
};

Employee e1{ { .name{"John"}, .surname{"Wick"}, .age{40} }, 50000 };
```

Так как у полей родителького класса нет какого-то имени, то используются просто вложенные скобки.

А еще вы можете пропускать любые поля  и они будут инициализированны по умолчанию! Давно не хватало такой возможности:

```cpp
struct Point{
	int x, y, z;
};

Point p{.x = 2, .z = 3}; // y is not mentioned, but it will have value of 0
```
Хоть `y` строит в середине, но это не мешает нам не указывать его при создании класса и это поле гарантированно будет равно 0.

Правда у фичи есть определенные ограничения:

1 Поля должны идти по порядку их объявления в классе. out-of-order инициализация, как в сишке, запрещена. То есть нельзя делать так:

```cpp
struct Point{
	int x, y;
};

Point p{.y = 2, .x = 3}; // not valid in C++!
```

Почему бы не сделать так же, как в С? Дело в том, что в С нет деструкторов. А в С++ есть. И поля класса инициализируются в порядке их появления в объявлении класса, а уничтожаются - в обратном. 

Программист может подумать, что раз я указываю какое-то поле первым в инициализации, то и значение ему будет присвоено в первую очередь. Но это не так. А учитывая, что инициализаторы могут иметь какие-то спецэффекты, например, как-то зависеть друг от друга, это может приводить к путанице.

2 Структуры должны быть POD типами, то есть вот такими же структурами без каких-либо конструкторов и специальных методов. Объекты с конструкторами должны создаваться через онные, а не напрямую. Ну это собственно просто ограничения аггрегированной инициализации, через которую и реализованы designated инициализаторы.

3 Если используете designated инициализаторы для одних полей, то нужно в этом же формате задавать значения другим полям. Смешанный формат запрещен:

```cpp
struct Point{
	int x, y;
};

Point p{2, .y = 3};  // Not allowed
```

Несмотря на все ограничения, они мне кажутся вполне оправданными, а сама фича вообще супергуд. Пользуйтесь, это сильно повысит читаемость кода.

Have a clear intentions. Stay cool.

#cpp20 #cppcore



Тип возвращаемого значения тернарного оператора
#опытным 

Представьте, что вам пришел какой-то запрос с json'ом и вам его нужно переложить в плюсовую структуру и дальше как-то ее обрабатывать. В джейсоне записаны какие-то персональные данные человека, но они не всегда присутствуют в полном составе. Давайте посмотрим на структуру, чтобы было понятнее:

```cpp
struct PersonalData {
	std::string name;
	std::string surname;
	std::string patronymic;
	std::optional<std::string> address;
	std::optional<std::string> email;
	std::optional<std::string> phone;
};
```

Пусть мы обрабатываем какие-то анкетные данные или что-то в таком духе. И человеку обязательно указать свои ФИО, но адрес, эл. почту и телефон - не обязательно.

Берем джейсон и перекладываем(то есть занимаемся тем, чему 6 лет учат в тех вузах):

```cpp
PersonalData person{
	.name = json["name"],
	.surname = json["surname"],
	.patronymic = json["patronymic"],
	.address = json.HasMember("address") ? json["address"] : std::nullopt,
	.email = json.HasMember("email") ? json["email"] : std::nullopt,
	.phone = json.HasMember("phone") ? json["phone"] : std::nullopt};
```

Просто, чтобы кучу if'ов не плодить, воспользуемся тернарным оператом. Если в json'е есть данное поле, то инициализируем опциональное поле им, если нет, то std::nullopt'ом.

Ничего криминального не сделали. Вдобавок использовали designated initialization из с++20.

Компилируем ииииииии..... Ошибка компиляции.

Пишет, что тернарный оператор не может возвращать разные типы. Дело в том, что std::nullopt - это константа типа nullopt_t. А поле джейсона имеет тип строки. 

Конечно, из обоих типов можно сконструировать объект std::optional. Но тернарный оператор не знает, что мы хотим. Ему просто не разрешается возвращать разные типы.

Но почему? Это же так удобно.

С++ - это не всегда про удобство)

Представьте себе шаблонную функцию, возвращаемый тип которой выводит сам компилятор. Условно - try_stoi. Если строка может быть преобразована в int, то возвращаем число, если нет - то возвращаем нетронутую строку.

```cpp
auto try_stoi(const std::string& potential_num) {
	if (can_be_converted_to_int(potential_num)) {
		return std::stoi(potential_num);
	} else {
		return potential_num;
	}
}
```

Разные ветки возвращают неконвертируемые друг в друга типы, поэтому компилятор не сможет вывести единый тип и произойдет ошибка компиляции.

Равно тоже самое происходит и с тернарным оператором. Не могут две ветки условия возвращать разные типы.

Придется явно писать все эти условия...

Be flexible. Stay cool.

#cppcore


Удобно сравниваем объекты
#опытным 

Иногда нам нужно сортировать объекты кастомных классов. Для этого нам нужно определить оператор<, чтобы объекты могли сравниваться друг с другом. Давайте попробуем это сделать для простой структуры:

```cpp
struct Time {
	int hours;
	int minutes;

	bool operator<(const Time& other) {
		if ((hours < other.hours) || (hours == other.hours && minutes < other.minutes))
			return true;
		else
			return false;
	}
};
```

Выглядит уже довольно сложно. А если мы захотим уточнить класс дополнительным полем секунд? Условие будет просто нечитаемым.

Однако есть элегантное решение этой проблемы. Можно использовать оператор сравнения для тупла. Он работает ровно, как мы и ожидаем в нашем случае. Сравнивает первые поля тупла, если они равны, то сравнивает вторые поля и так далее. В общем, сравнивает свои поля по [короткой схеме](https://t.me/grokaemcpp/187).

Чтобы из наших полей класса получился тупл, нужно использовать функцию std::tie, которая и крафтит кортеж из переданных аргументов. Получится примерно так:

```cpp
struct Time {
	int hours;
	int minutes;

	bool operator<(const Time& other) {
		return std::tie(hours, minutes) < std::tie(other.hours, other.minutes);
	}
};
```

Теперь при добавлении поля класса, мы всего лишь должны добавить аргумент к std::tie:

```cpp
struct Time {
	int hours;
	int minutes;
	int seconds;

	bool operator<(const Time& other) {
		return std::tie(hours, minutes, seconds) < std::tie(other.hours, other.minutes, other.seconds);
	}
};
```

Фишка рабочая и удобная. Так что пользуйтесь.

Use lifehacks. Stay cool.

#goodpractice 


