
Graceful shutdown
#новичкам 

Любое приложение рано или поздно завершает свою работу. Кто-то обязательно нажмет ctrl+c или убьет процесс.

И также, как человек готовится к своей смерти, если знает, что она близко(завершает незаконченные дела, споры или обиды, готовит завещание), приложение тоже должно приготовиться с своей смерти.

Зачем? Почему бы просто не прекратить работу? В некоторых случаях это сделать можно, но скорее всего это не очень большие и сложные приложения.

У больших приложений много обязанностей. Они скорее всего как-то взаимодействуют с внешним миром и у них есть определенные контракты на взаимодействие. Например, очень бы желательно, чтобы каждый "запрос" из внешнего мира был удостоин "ответа". Иногда это даже критически необходимо, например со всякими финансовыми операциями. Клиентам нельзя терять деньги, это подорвет репутацию банка.

Да и просто в житейском плане будет очень некруто, если при заказе вашей любимой пиццы, вы будете бесконечно смотреть на крутящийся кружок с надписью "processing order". Ваш запрос отправился, но дальше упал сервис и ответ от него не приходит.

Именно поэтому и нужно правильно подготовить приложение к завершению. Это и называется graceful shutdown. Мы плавно завершаем работу, чтобы выполнить все накопившиеся обязательства и соблюсти все контракты.

Например, у нас есть очередь задач. Там есть какие-то таски, мы их разбираем воркерами, а продюсеры накидывают в нее новые таски. А какой-то момент мы захотим убить программу. Graceful завершением в данном случае будет разгрести и выполнить все оставшиеся задачи. Либо хотя бы сказать им честно и прямо, что мы не собираемся их выполнять. И только после этого завершиться.

Однако это понятие можно распространить не только на завершение приложений. Но и на завершение цикла жизни отдельных объектов. Например, у вас есть какой-то записывающий стрим в базу. Бывает такое, что не прям обязательно, чтобы эти данные были доступны из базы здесь и сейчас. Поэтому стрим может копить записи какое-то время и по порогу флашить буфер в базу. Так вот частью graceful завершением работы такого класса должен быть сброс буфера в базу, чтобы все накопившиеся данные все-таки в ней оказались, а не потерялись.

Это был такой балабольский первый пост из большой серии для тех, кто не знаком с понятием. Дальше мы будем разбирать детали и тонкости плавного завершения.

Complete your tasks. Stay cool.

#goodpractice 


Graceful shutdown
#новичкам 

Как мы и говорили в предыдущем посте - у нормального приложения есть определенные контракты с клиентом. Как минимум, клиент ожидает либо выполнения своего запроса, либо индикации, что его невозможно выполнить. Не хочется иметь каких-то промежуточных результатов или состояний. Да и серверу тоже не нужно, чтобы клиент прислал какой-то кривой запрос, потому что он неожиданно грохнулся.

Короче, всем хочется добра, позитива и мягкого завершения.

Часто программы крутятся в так называемом цикле событий. Программа бесконечно проверяется доступность каких-то данных и если они есть - обрабатывает их. Самый простой event_loop - обычный бесконечный цикл. Работаем от обеда и до самой смерти программы.

Давайте пример:

```cpp
void Worker() {
	std::string line;
	while(true) {
		std::getline(std::cin, line);
		process_line(line);
	}
}
```

Тут программа мониторит стандартный ввод и обрабатывает все "команды", которая она получит оттуда.

Что может пойти не так? Ну например мы убьем приложение где-то посередине функции process_line. И команда не отработает, как надо. 

Какой выход?

Не крутиться бесконечно в цикле. Ничего реально бесконечного в нашей жизни нет и глупо предполагать, что когда-то будет. Да и вообще. Я сам художник своей судьбы! Хочу иметь возможность останавливать этот цикл.

Не проблема. Давайте введем внешнюю булеву переменную, которая будет индикатором того, нужно ли крутиться в цикле или нет.

```cpp
bool is_working = true;

void Worker() {
	std::string line;
	while(is_working) {
		std::getline(std::cin, line);
		process_line(line);
	}
}
```

Теперь любой внешний код может поставить is_working в false, мы обработам последнюю команду и выйдем из Worker'а. То что нужно!

Но подождите. У нас же бесконечный цикл. Как мы можем исполнять другой код, пока мы в нем?

Подходов может быть несколько. Но это уже тема следующего поста.

Rule your life by yourself. Stay cool.

#goodpractice 


Прерываем цикл в потоке
#новичкам

Бесконечный цикл - это конечно проблема для исполнения стороннего кода. Но только не для многопоточных приложений. 

Мы можем иметь второй поток, в котором мы и будем изменять переменную is_working.

Причем, скорее всего это будет родительский поток для воркера, потому что обычно только он может иметь достаточно знаний и власти, чтобы завершить работу потомка.

То есть мы когда-то сами запустили воркера и сами знаем, когда его пришибнуть. Например так:

```cpp
std::atomic<bool> is_working = true;

void Worker() {
	std::string line;
	while(is_working.load()) {
		std::getline(std::cin, line);
		process_line(line);
	}
}

struct LineProcessor {
	LineProcessor() {th = std::thread{Worker};}
	~LineProcessor() {is_working = false; th.join();}
private:
	std::thread th;
};
```

Пока нам нужен объект LineProcessor, он работает. Как только он нам перестал быть нужным aka мы вызвали его деструктор, то мы останавливаем цикл, ждем завершения обработки последней переданной команды и только после этого считаем, что объект LineProcessor уничтожен. 

Ну и да, важное уточнение. Так как мы уже в многопотоке, то нам надо позаботиться о синхронизации доступа к переменной is_working, так как мы ее читаем и изменяем в разных потоках. 

Можно было бы добавить привычный мьютекс, но в данном кейсе это слишком дорого. Есть замечательный шаблонный класс std::atomic, который оборачивает объекты разных классов и делает доступ к ним "атомарным", то есть потокобезопасным.

В целом, идея тут в том, чтобы показать один из механизмов управления состоянием воркера, когда программа точно знает, когда его завершить.

Но не всегда программа знает, когда надо делать определенные действия. И зачастую именно так и происходит завершение программы: она спокойно себе работает, а тут приходит человек(ЗАЧЕРКНУТЬ) кожаный мешок и в 4 часа утра вероломно без объявления войны нажимает ctrl+c. И все, приплыли.

Поэтому важно уметь обрабатывать такие внешние воздействия на приложение. Но об этом в следующий раз.

Listen to your parent. Stay cool.

#concurrency #goodpractice 


Сигналы
#новичкам 

Стандартные сигналы в С++ - программные прерывания, которые доставляются процессу операционной системой. Важно их отличать от концепции сигналов в Qt. Там это другая, хоть и идейно похожая история. Сфокусируемся именно на стандартных сигналах.

Не так просто понять, исходя из определения, что такое сигналы в С++. Но даже если вы думаете, что ни разу ими не пользовались, то спешу вас огорчить. И пользовались и страдали от их эффектов.

Самый простой способ сгенерировать сигнал - запустить программу в терминале и, не дожидаясь момента ее завершения, нажать ctrl+c. Это действие стригерит ОС послать сигнал SIGINT вашей программе, который по дефолту завершит ее. 

Ну или еще один пример. Пишите вы сложную прогу и случайно набагали там. Допустим, разыименовали нулевой указатель. Запускаем эту прогу и получаем примерно такое сообщение: Program received signal SIGSEGV, Segmentation fault. Операционная система послала нашему процессу сигнал SIGSEGV и сообщила ему, что во время выполнения программы произошла ошибка сегментации.

Да даже когда у вас неожиданно вылетело исключение и вы его не обработали, то это необработанное исключение приведет к вызову функции abort(), которая в свою очередь триггерит генерацию сигнала SIGABRT.

То есть все мы более или менее с ними работали.

Давайте посмотрим, какие вообще по стандарту С++ есть сигналы.

SIGTERM - запрос на окончание работы, посланный программе
SIGSEGV - попытка неправомерного доступа к памяти(segmentation fault)
SIGINT - внешнее прерывание процесса, обычно инициируемое пользователем в консоли
SIGILL - попытка использовать нелегальную инструкцию(например чужую хардварную инструкцию)
SIGABRT - появление условия ненормального завершения, инициированного функцией abort
SIGFPE - ошибочная арифметическая операция, например деление на 0

Понятное дело, что сигналы сообщают в возникновении какой-то ситуации. Но на них программа должна как-то среагировать. И вот мы можем влиять на то, как программа реагирует на определенные сигналы! 

В рамках этой серии в деталях поразбираем, как обрабатывать сигналы в пользовательском коде. Но это в будущих постах.

React to important signals. Stay cool.

#cppcore

std::signal
#новичкам

В плюсах не так много стандартных средств работы с сигналами. Да и вообще, в стандарте вообще никак не описываются сигналы, для чего они нужны и как с ними работать. Мы типа  должны это как-то сами узнать непонятно откуда. Один из источников - сишный стандрат, так как все средства обработки сигналов плюсы переняли оттуда.

Сигнал — это механизм оповещения процесса о том, что произошло некое событие. И процесс как-то реагирует на эти сигналы. 

Та специфичная процедура, которую выполняет процесс при получении сигнала, называется обработчиком сигнала(signal handler).

Для одного процесса можно установить всего один обработчик на каждый сигнал.

У процессов на все стандартные сигналы есть дефолтные обработчики. Большинство из них просто немедленно завершают приложение.

Но весь сок в том, что мы сами можем выставить свои кастомные обработчики сигналов!

В сишном и плюсовом стандарте единственный инструмент, позволяющий это сделать - функция signal()(по плюсовому std::signal).

```cpp
/* signal-handler */* signal( int sig, /* signal-handler */* handler )
```

Так она выглядит. Ей на вход передаются 2 параметра - сам сигнал и указатель на функцию-обработчик.

На функцию обработчика есть строгие требования:

```cpp
extern "C" void fun(int sig);|
```

Она не должна ничего возвращать, принимать один единственный параметр - сигнал и иметь сишную линковку.

Это требования стандарта, но более менее все компиляторы обычно позволяют использовать в качестве хэндлеров плюсовые функции и даже статические методы классов.

Такая сигнатура ОЧЕНЬ сильно ограничивает применимость std::signal. Сами посудите, мы не можем передавать в функцию никакие кастомные данные. Нас просто вынуждают использовать глобальные переменные. Ну и собственно, первый же пример на цпп референс об этом и говорит.

```cpp
namespace
{
    volatile std::sig_atomic_t gSignalStatus;
}
 
void signal_handler(int signal)
{
    gSignalStatus = signal;
}
 
int main()
{
    // Install a signal handler
    std::signal(SIGINT, signal_handler);
 
    std::cout << "SignalValue: " << gSignalStatus << '\n';
    std::cout << "Sending signal: " << SIGINT << '\n';
    std::raise(SIGINT);
    std::cout << "SignalValue: " << gSignalStatus << '\n';
}
// OUTPUT
// SignalValue: 0
// Sending signal: 2
// SignalValue: 2
```

Регистируем обработчик сигнала SIGINT, который изменяет глобальную переменную gSignalStatus на тот сигнал, который пришел обработчику. С помощью std::raise мы инициируем сигнал и проверяем результат.

Внимательные читатели обратили внимание на тип глобальной переменной. `volatile std::sig_atomic_t` - довольно необычный тип. 

"Нельзя было чтоли использовать обычный int?"

Нет, нельзя. В будущем узнаем почему.

Don't be limited. Stay cool.

#cppcore 



Возбуждаем сигнал
#опытным 

Нет, тема поста никак не связана с черно-оранжевым сайтом. 

Судя по названию стандартных сигналов, как бы подразумевается, что операционная система сама без нашего участия отправляет их процессу. У программы все-таки есть свои средства сообщения внешнему миру о наступлении неожиданного события - исключения.

Но как-то несправедливо получается. Раз программа может принимать и обрабатывать сигналы, то должна уметь и отправлять их. А то что, программа - раб?! Даешь права программе отправлять сигналы!

Оказывается мы можем стандартными средствами возбудить сигнал. Для этого существует функция std::raise().

```cpp
int raise( int sig );
```

Она посылает сигнал `sig` только текущей программе. Никому другому послать сигнал невозможно средствами С++. Это можно сделать через unxi api и функцию kill, но это уже немного не С++.

На самом деле, raise говорит операционной системе отправить сигнал текущему процессу, но это уже детали.

Причем сигнал отправляется тому потоку программы, из которого был вызван std::raise. И обработчик выполняется именно в этом потоке.

Пример:

```cpp
namespace
{
    volatile std::sig_atomic_t gSignalStatus;
}
 
void signal_handler(int signal)
{
    gSignalStatus = signal;
}
 
int main()
{
    // Install a signal handler
    std::signal(SIGINT, signal_handler);
 
    std::cout << "SignalValue: " << gSignalStatus << '\n';
    std::cout << "Sending signal: " << SIGINT << '\n';
    std::raise(SIGINT);
    std::cout << "SignalValue: " << gSignalStatus << '\n';
}
// OUTPUT
// SignalValue: 0
// Sending signal: 2
// SignalValue: 2
```

Здесь std::raise стриггерил вызов хэндлера `signal_handler`, который изменил статус на двоечку.

Зачем вообще может быть нужен std::raise?

Повторюсь, у программы есть свои более подходящие средства сообщения о чрезвычайных ситуациях. 

Мы конечно дали права программе саму себя прибить, но непонятно, нужно ли ей это вообще. Довольно странно выглядит перспектива, что программа сама по своему хотению сможет завершиться, послав сама себе сигнал об этом. 

Поэтому обычно эту функцию используют только для тестов. Вы можете тестировать свой кастомный модуль обработки сигналов. Или опять же в тесте прекратить выполнять бесконечный цикл в другом потоке, чтобы нормально gracefully завершиться.

Give up harmful rights. Stay cool.

#cppcore


Пояснение про сигналы
#опытным 

Как я уже говорил, в плюсовом стандарте очень мало написано про сигналы, что это такое, как они работают и обрабатываются на низком уровне. Поэтому в рамках С++ писать нормальную обработку сигналов очень сложно.

Но мы можем заглянуть в posix стандарт и узнать немного больше о сигналах. Сегодня я дам небольшое пояснение, которое возможно вам поможет чуть лучше понимать тему.

Есть два вида сигналов в posix - стандартные и real-time'овые. Будем говорить только про стандартные, так как они хоть как-то пересекаются с плюсовым стандартом.

Итак, сигналы - средство, которым операционная система может донести информацию до процесса. Да, хоть мы и можем посылать сигналы от одного процесса другому, делается это только через ядро ОС:

```
process_1 -> OS kernel -> process_2
```

Просто процесс может попросить ОС отправить сигнал в то или иное место. Именно поэтому у сигналов нет никаких аттрибутов, говорящих о его отправителе. Потому что отправитель всегда один.

Каждый процесс для каждого сигнала хранит обработчик этого сигнала. Он может быть по дефолту установленный или ваш кастомный.

Важно: один сигнал в рамках одного процесса может иметь только один уникальный обработчик. Вы не можете установить 2 обработчика. При попытке установить второй хэндлер, вы просто перезапишите старый.
Но несколько сигналов могут иметь одинаковые обработчики, никто этого не запрещает. Частое явление, когда на SIGTERM и SIGINT устанавливают одинаковые обработчики. А дефолтное поведение для 80% сигналов одинаковое - немедленное завершение программы.

Обработчик сигнала - атрибут непосредственно процесса. В многопоточной программе, даже если вы создадите огромную такую кучу тредов, все равно обработчик сигналов один на все потоки. В каком бы потоке вы не зарегистрировали обработчик - он зарегистрируется для всего процесса. Поток тут просто выступает исполнителем кода регистратора этого обработчика, ничего более.

Как мы рассматривали ранее, std::raise посылает сигнал в тот же поток программы, из которого он вызван. Тогда это была вскользь брошенная фраза, сейчас разберемся с тем, как это работает.

Стандартный способ послать сигнал в posix - системный вызов kill:
```c
int kill(pid_t pid, int sig);
```

В него передается pid процесса и номер сигнала. kill - чисто историческое название. Раньше сигналов было меньше и примерно все они означали, что процесс надо прибить. Сейчас kill просто посылает сигнал без интенции покрошить процесс на молекулы.

Но kill ничего не говорит о том, где этот сигнал будет обрабатываться. А будет он обрабатываться в каком-то потоке программы. Логично.

Каждый поток процесса имеет свою маску сигнала. Это, грубо говоря, индикатор, будет ли поток обрабатывать сигнал с определенным номером.

Вот приходит сигнал процессу через kill. Ядро операционки смотрит на потоки программы и выбирает любой из тех, для которых маска позволяет обрабатывать данный сигнал. Так работает в общем случае.

Но мы можем послать сигнал конкретному потоку в конкретном процессе. Для этого используются системные вызовы pthread_kill(работает внутри процесса) и tg_kill.

Для posix систем std::raise реализован через pthread_kill, потому что в нем необходимо послать сигнал именно текущему потоку.

В принципе, этой информации вам хватит, чтобы правильно использовать std::signal и std::raise и минимально понимать, что вообще там под капотом происходит.

А в следующие разы мы подробнее поговорим про все эти подкапотные дела и узнаем уже не только как правильно применять std::signal и std::raise, но и как правильно писать сами обработчики.

Dig deeper. Stay cool.

#OS #NONSTANDARD #goodoldc 


Квиз
#опытным

Прежде чем разбирать подкапотные дела обработки сигналов, давайте проведем небольшой #quiz.  Выясним средний уровень прошаренности подписчиков в этом вопросе.

Вот очень простой код:

```cpp
#include <iostream>
#include <csignal>
#include <thread>

bool is_running = true;

void signal_handler(int signal)
{
    is_running = false;
    std::cout << "Stop execution" << std::endl;
}

int main()
{
    std::signal(SIGINT, signal_handler);
    while(is_running) {
	    std::cout << "Some Work" << std::endl;
	    std::this_thread::sleep_for(std::chrono::seconds(1));
    }
}
```


Код простой. И вопрос будет простой. Какие опасности есть в этом коде?

А вот уже ответ на этот вопрос не очень простой. Но вы все-таки попытайте свои усилия.

Какие опасности есть в коде выше?

Доступ к неразрешенной памяти. Сегфолт

При попытке скомпилировать будет ошибка

Гонка данных

Чего вы загоняете? Нормальный код. Коммитим в мастер и сразу в прод!

Неопределенное поведение

Дедлок


Ответ

На самом деле в этом коде есть UB. И это очень тесно связано с тем, как обрабатываются сигналы на низком уровне.

Иногда сигналы описываются, как программные прерывания, т.к. приостанавливают нормальное выполнение программы. Но как это происходит в деталях?

Дальше речь пойдет про unix-системы.

Обработчик сигнала может быть вызван в любом из потоков процесса, у которого подходящая маска. Если таких потоков несколько, то ядро выбирает один из них — чаще всего, это будет основной поток программы, но это не гарантировано, и не стоит на это рассчитывать. 

При появлении сигнала ядро выбирает подходящий поток и создает на его стеке специальный фрейм, который:

- во-первых, нужен для непосредственно работы функции-обработчика сигнала

- во-вторых, в него сохраняются данные, необходимые для продолжения работы основной программы, такие как значения регистра счетчика команд (program counter register, адрес, с которого будет продолжено выполнение кода), специфичные для архитектуры регистры, которые необходимы для продолжения выполнения выполнявшегося кода, текущую маску сигналов потока, и т.д. 

После создания фрейма вызывается функция-обработчик сигнала.

О чем это говорит? О том, что выполнение любого потока (который не заблокирован для обработке нашего сигнала) может быть прервано в любой момент. Абсолютно любой. Посреди выполнения любой функции, любого системного вызова. Это может происходить даже при выполнении самого обработчика. Ничто не мешает одни за другим послать 2 сигнала. В этом случае мы можем войти в обработчик, на его середине придет второй сигнал, мы прервем выполнение обработчика на середине и начнем его повторно выполнять.

А теперь представим, если прерванная функция у нас имеет какое-то статическое, глобальное или thread-local внутреннее состояние, например буфер, какие-то флаги, мьютекс, или что-либо еще, то вызов функции еще раз, когда она еще не закончила работу, может привести к совершенно непредсказуемым результатам. В компьютерных науках про такую функцию говорят, что она non-reentrant (нереентерабельна).

В примере кода мы использовали в std::cout. Она использует внутри [статически выделенный буфер данных](https://t.me/grokaemcpp/480) вместе со счетчиками и индексами, которые хранят объем данных и текущую позицию в буфере. Обновляется все это не атомарно, и если вдруг в момент выполнения std::cout в каком-нибудь потоке мы поймаем сигнал и запустим его обработчик, который тоже вызовет std::cout, то эта функция будет работать с некорректным внутренним состоянием, что в лучшем случае приведет просто к неправильному результату, а в худшем случае уронит всю программу в segmentation fault. В общем, UB.

Другой пример: на большинстве платформ malloc() и new() и иже с ними не реентерабельны, потому что они используют внутри статическую структуру данных, в которой хранится, какие блоки памяти свободны. Проблема усугубляется тем, что стандартные аллокаторы могут неявно использоваться в глубине других библиотечных функций, и об этом вы можете даже не подозревать.

То есть в хэндлерах вообще нельзя пользоваться стандартными аллокаторами. А значит и контейнерами, алгоритмами и исключениями. В целом, в стандарте стоит запрет на использование ВСЕЙ стандартной либы, кроме std::abort, std::quick_exit и еще несколько безопасных штук, вроде методов of std::initializer_list, std::forward, std::move, всех type_trait'ов и memcpy|memmove.

Тогда вопрос - если в обработчиках ничего нельзя делать, то выглядят они пока максимально бесполезно. Тронешь - и сразу завоняет.

Однако есть кое-что, что можно разрешается делать внутри хэндлера. И это тесно связано с еще одним поинтом.

Проблемы-то в коде из квиза на этом не закончились...

Но разберем мы их в следующем посте.

Be reliable. Stay cool.

#memory #cppcore #OS 





Что можно делать внутри signal handler'а?
#опытным

Стандарт нам говорит, что 2 действия потенциально конкурентны, если:

1 Они выполняются в разных тредах или 

2 Одно из них выполняется внутри обработчика сигнала.

А гонка данных - это состояние в программе, когда она содержит 2 потенциально конкурентных события и хотя бы одно из них не атомарно или для них не определено зависимости happens before.

Так вот в примере

```cpp
bool is_running = true;

void signal_handler(int signal)
{
    is_running = false;
    std::cout << "Stop execution" << std::endl;
}

int main()
{
    std::signal(SIGINT, signal_handler);
    while(is_running) {
	    std::cout << "Some Work" << std::endl;
	    std::this_thread::sleep_for(std::chrono::seconds(1));
    }
}
```

Мы неатомарно изменяем состояние флага is_running. И значит код содержит гонку данных и UB.

Но почему обработчик сигналов конкурирует с кодом программы?

Даже при условии того, что обработка сигнала не подразумевает создание новых потоков, переключение исполнения на обработчик очень сильно похоже на переключение контекста на новый поток. 

Планировщик потоков в системе так и делает: когда у определенного потока заканчивается квант времени, планировщик его переключает на другой поток. Сохраняет необходимые данные для восстановления исполнения заканчивающего работу потока в контекст и загружает контекст другого потока. И делает он это в абсолютно любом месте "кода".

Практически в точности так делает система при обработке сигналов.

Поэтому к этому процессу можно также применять логику при работе с обычными потоками.

Если 2 потока получают доступ к переменной, которая не является атомиком, и делают это без использования примитивов синхронизации - все понимают, что это data race и UB.

Пользуясь этой же логикой, мы понимаем, что код с обработчиком и неатомарной переменнлй содержит UB.

Поэтому, стандарт нам говорит, что внутри обработчика сигналов мы можем использовать только истинно неблокирующие функции и методы для объектов. Это такие объекты, для которых функция/метод is_lock_free() возвращает true.

В итоге, пример довольно просто переписать, чтобы в нем было все корректно с точки зрения стандарта:

```cpp
std::amotic_flag interrupted = ATOMIC_FLAG_INIT;

void signal_handler(int signal)
{
    interrupted.test_and_set();
}

int main()
{
    std::signal(SIGINT, signal_handler);
    while(!interrupted.test()) {
	    std::cout << "Some Work" << std::endl;
	    std::this_thread::sleep_for(std::chrono::seconds(1));
    }
}
```

Можно было бы в качестве флага использовать volatile std::sig_atomic_t, но с атомиками как-то привычнее.

Don't race for nothing. Stay cool.

#concurrency #cppcore #OS #memory




Почему нельзя использовать другие примитивы синхронизации внутри signal handler?
#опытным 

В прошлый раз мы разобрались, что использование не лок-фри переменных и функций в обработчиках сигналов - это гонка данных и UB.

Но почему именно операция должна быть именно лок фри?

А что, блокировка мьютекса - атомарная операция очевидно. Это проверенный примитив, всем известен. Избавляет от гонки данных. Все должно быть пучком. Не будем даже использовать RAII обертки, чтобы трогать стандартную библиотеку.

Но не будем торопиться с рассуждениями, а посмотрим на код:

```cpp
bool is_running = true;
std::mutex mtx;

void signal_handler(int signal)
{
	mtx.lock();
    is_running = false;
    mtx.unlock();
}

int main()
{
    std::signal(SIGINT, signal_handler);
    bool running = true;
    while(running) {
	    std::cout << "Some Work" << std::endl;
	    std::this_thread::sleep_for(std::chrono::seconds(1));
	    std::lock_guard lg{mtx};
	    running = is_running;
    }
}
```

Со всех сторон защитили флаг is_running мьютексами, гонок не должно быть.

Однако гонка - это не единственное противное явление в многопоточке из-за которого может быть UB.

Дважды локнуть мьютекс в одном и том же треде - тоже UB. И в нашем коде такое может произойти!

Если в процессе выполнение обработчика мы уже блокнули мьютекс и сразу после этого нам придет еще один сигнал, то мы как раз и получим эту ситуацию. Второй раз заблочим мьютекс и скорее всего дедлокнем поток.

Вот почему все должно быть лок фри aka без блокировок.

Don't block yourself. Stay cool.

#concurrency #cppcore 


Атомики и их атомарность
#опытным 

Чисто исходя из названия становится понятно, что операции над атомиками - атомарны, то есть никто не может увидеть промежуточных этапов вычислений в этих операциях.

Однако не все так просто. На самом деле атомики и атомарные операции подразделяются еще на две категории - лок фри и не лок фри.

Лок фри операции реализуются с помощью одной инструкции специальной ассемблера. Она конечно намного более затратна, по сравнению с обычным mov, но  именно за счет того, что она одна и реализуется атомарность. Никто не может увидеть промежуточных результатов операции, если этих промежуточных результатов в принципе нет.

Но не все атомарные типы могут похвастаться использованием таких инструкций. Более того, в стандарте есть всего один атомарный тип, для которого гарантировано свойство лок фри. Это std::atomic_flag. atomic_flag даже является не специализацией шаблонного класса std::atomic<>. У него нет методов load, store, exchange и прочих. Работать с ним можно только так:

```cpp
std::atomic_flag f{}; // до с++20 инициализирует флаг в неопределенное состояние, поэтому не рекомендую использовать
std::atomic_flag f = ATOMIC_FLAG_INIT; // корректная инициализация флага. Заметьте, что даже false|true нельзя использовать в качестве инициализаторов. ATOMIC_FLAG_INIT устанавливает значение флага в опущенное состояние, эквивалентное false
bool state = f.test(); // возвращает текущее состояние флага в текущий момент времени

bool pre_state = f.test_and_set() // меняет текущее состояние флага на поднятое состояние. аналог exchange

f.clear(); // опускает флаг
```

Для остальных атомиков определен метод is_lock_free, который показывает, реализован ли объект конкретной специализации без использования блокировок.

Исходя из существования этого метода, становится очевидным, что не все атомики могут быть реализованы с помощью неблокирующих инструкций процессора. Это может зависеть от архитектуры. На каких-нибудь простеньких цпу даже atomic_int может быть реализован через мьютексы. Или например какие-то типы не выровнены по памяти, тогда чисто технически невозможно пока реализовать лок фри операции для них.

В общем, если вы пишете супер-пупер переносимый кроссплатформенный код, который работает и в облаке амазона, и в умном бачке унитаза, то всегда используйте в качестве атомарного типа для обработки сигналов именно std::atomic_flag.  

Если вы уверены, то на вашей таргетной архитектуре atomic_bool - атомарен, то используйте его.

Be indivisible. Stay cool.

#concurrency #memory #cppcore


Graceful shutdown с использованием std::signal
#новичкам 

Ну что. Мы уже достаточно подробно разобрали сигналы и можем попробовать с их помощью обработать аварийное завершение программы. Вернемся к нашему обработчику строк из stdin.

```cpp
std::atomic<bool> is_working = true;

void Worker() {
	std::string line;
	while(is_working.load()) {
		std::getline(std::cin, line);
		process_line(line);
	}
}

struct LineProcessor {
	LineProcessor() {th = std::thread{Worker};}
	~LineProcessor() {is_working = false; th.join();}
private:
	std::thread th;
};
```

Давайте установим обработчик на сигналы SIGINT и SIGTERM, который опускает флаг is_working и позволяет остановить воркер после завершения текущей итерации.

```cpp
void process_line(std::string str) {
	std::this_thread::sleep_for(std::chrono::seconds(2));
	std::cout << "My dear subscriber, your are the best!" << std::endl;
}

std::atomic<bool> is_working = true;

void handler(int signal) {
	// Stop the loop
	is_working = false;
}

void Worker() {
	while(is_working.load()) {
		std::string line;
		std::getline(std::cin, line);
		process_line(line);
	}
}

struct LineProcessor {
	LineProcessor() {th = std::thread{Worker};}
	~LineProcessor() {th.join();}
private:
	std::thread th;
};

int main() {
	std::signal(SIGINT, handler);
	std::signal(SIGTERM, handler);
	LineProcessor lp;
}
```

У нас есть класс процессора строк, в нем мы запускаем поток, который бесконечно считывает строчки со стандартного ввода и обрабатывает их. В деструкторе объекта мы дожидаемся остановки потока. Этого не произойдет в нормальной ситуации. Но если мы пошлем сигнал, например с помощью ctrl+C, флаг станет равен false, мы дообработаем последнюю считанную строку, поток завершиться, как и сама программа после этого.

Возможный вывод:
```
42
My dear subscriber, your are the best!
42
My dear subscriber, your are the best!
42
^C
My dear subscriber, your are the best!
```

Обработка сообщения занимает 2 секунды, чтобы наглядно продемонстрировать особенности завершения. После того, как я в 3-й раз написал `42` в консоль, я сразу же зажал ctrl+C, что отобразилось на консоли(`^C`).  И после того, как последняя строчка обработается(сообщение `My dear subscriber, your are the best!` появится в выводе), цикл завершается как и соответствующий поток, деструктор дожидается завершения потока и программа сразу же завершается. 

Прекрасно! Рабочая тема, можно использовать.

Как бы да, можно. Но функционал этого инструмента довольно ограниченный. Наверное вы уже заметили, что переменная is_working у нас глобальная. И в принципе сигнатура хэндлеров не позволяет им принимать кастомные параметры.

По идее флаг должен быть вообще приватным полем класса, инкапсуляция, все дела. А здесь мы раскрываем детали реализации. Неужели ничего нельзя поделать?

Можно. Но об этом в следующий раз.

Finish things gracefully. Stay cool.

#cppcore #design #concurrency #goodpractice 


sigaction
#опытным 

В прошлый раз мы поговорили о том, что std::signal предоставляет довольно бедный интерфейс и не позволяет передавать в хэндлеры никаких кастомных данных. Это никуда не годится и с этим что-то нужно делать.

Безусловно, нужно. Только вот загвоздка - стандарт не предоставляет больше никаких средств для того, чтобы обрабатывать сигналы.

Поэтому мы переходим в поле платформенно-специфичных решений. Сегодня разберем крутой инструмент из POSIX стандарта - sigaction. Во всех гайдлайнах рекомендуют использовать именно его в пингвинячьих системах на замену функции signal(std::signal в случае плюсов). Не будем погружаться в тонкости и размусоливать все детали, их там много и мы все-таки не для этого тут. Кратко пройдемся по возможностям и напишем пример работы.

```cpp
#include <signal.h>

// Возвращает 0 при успешном завершении, –1 при ошибке
int sigaction(int signum, const struct sigaction *act, struct sigaction *oldact);
```

Первый аргумент - номер сигнала. Если параметр `act` не равен нулю, то новое действие, связянное с сигналом `signum`, устанавливается соответственно `act`. Если `oldact` не равен нулю, то предыдущее действие записывается в `oldact`.

Обычно старый обработчик получать не особо нужно. И именно через act мы устанавливаем нужное поведение при получении сигнала.

```cpp
struct sigaction {
    void (*sa_handler)(int);
    void (*sa_sigaction)(int, siginfo_t *, void *);
    sigset_t sa_mask;
    int sa_flags;
    void (*sa_restorer)(void);
}
```

Эту структуру нужно заполнить, чтобы установить обработчик. Там много всего прекрасного, но нам нужно знать следующее:

- sa_handler - обработчик такого же вида, как и в std::signal
- sa_sigaction - обработчик на стероидах, принимающий помимо номера сигнала дополнительную информацию о сигнале через siginfo_t. Туда входит в том числе  errno, pid процесса отправителя и даже кастомные данные от отправителя). Третий параметр особо не используется, лишняя деталь.
- sa_mask - можно установить сигналы, которые блокируются при выполнении обработчика.
- sa_flags - флаги. Для простых смертных самый нужный SA_SIGINFO - он позволяет переключится на обработчик на стероидах вместо базового sa_handler.
- sa_restorer - лишняя деталь.

Как мы его используем. Покажу для случая, когда нам могут быть интересны дополнительные сведения о сигнале. То есть будет устанавливать обработчик с тремя аргументами:

```cpp

void Handler(int signum, siginfo_t* signinfo, void* ucontext) {}

struct sigaction act;
act.sa_sigaction = Handler;
sigemptyset(&act.sa_mask);
act.sa_flags = SA_SIGINFO
sigaction(SIGINT, &act, nullptr);
```

Простейший сценарий. Мы создаем структуру sigaction, назначаем туда обработчик, делаем пустую маску и флагом показываем использовать стероидный обработчик. 

Базово должно быть понятно.

В чем же преимущество этого зверя над std::signal?

posix'овый signal вообще имеет unspecified поведение в многопоточной программе. Плюсовый стандарт сказал, что безопасно в любой программе внутри обработчика std::signal использовать только атомарные переменные и функции.
sigaction же, помимо большей вариативности, по стандарту posix разрешается внутри своих обработчиков использовать так называемые async-signal-safe функции. Их список можно найти [тут](https://man7.org/linux/man-pages/man7/signal-safety.7.html). Там можно много всего делать, но нам интересно, что можно писать в сокеты.

Как это может сыграть нам на руку, увидим в будущем.

Be just better. Stay cool.

#NONSTANDARD #goodoldc #concurrency 





Передаем событие от обработчика
#опытным 

В прошлом посте мы выяснили, что мы можем внутри обработчика sigaction использовать манипуляции сокетами. На первый взгляд кажется, что от этого мало пользы будет . Но на самом деле, это открывает очень большой спектр возможностей.

Если мы можем записать в сокет, то кто-то может слушать этот сокет. И слушатель уже ничем не ограничен в плане используемого функционала. Если слушатель увидит приход события на сокет, то он может делать в принципе все, что угодно, и вызывать любые коллбэки. Нам это и нужно. 


https://godbolt.org/z/fqndoqnrY


https://youtube.com/@misha_filitov?si=G3HmZCnoJcYzDSSR

Отличия signal и sigaction https://stackoverflow.com/questions/231912/what-is-the-difference-between-sigaction-and-signal


```cpp
#ifndef _SOURCE_H_
#define _SOURCE_H_

#include <poll.h>
#include <signal.h>
#include <sys/eventfd.h>
#include <unistd.h>

#include <atomic>
#include <csignal>
#include <iostream>
#include <mutex>
#include <stdexcept>
#include <system_error>
#include <thread>
#include <vector>

class SignalHandler {
public:
    // Singleton access
    static SignalHandler& Instance() {
        static SignalHandler instance;
        return instance;
    }

    // Delete copy and move
    SignalHandler(const SignalHandler&) = delete;
    SignalHandler& operator=(const SignalHandler&) = delete;
    SignalHandler(SignalHandler&&) = delete;
    SignalHandler& operator=(SignalHandler&&) = delete;

    // Set the signal handler (can be called once, or after Reset())
    template <typename CallbackT, typename... Args>
    void SetHandler(const std::vector<int>& signals, CallbackT&& callback, Args&&... args) {
        std::lock_guard<std::mutex> lock(mutex_);

        if (running_) {
            throw std::runtime_error("SignalHandler is already running. Call Reset() first.");
        }

        if ((terminate_event_fd_ = eventfd(0, EFD_CLOEXEC)) < 0)
            throw std::system_error(errno, std::system_category(),
                                    "unable to create terminate event FD");
        if ((trigger_event_fd_ = eventfd(0, EFD_CLOEXEC | EFD_SEMAPHORE)) < 0) {
            close(terminate_event_fd_);
            throw std::system_error(errno, std::system_category(),
                                    "unable to create trigger event FD");
        }

        signals_ = signals;

        thread_ =
            std::thread([this, callback = std::forward<CallbackT>(callback),
                         args_tuple = std::make_tuple(std::forward<Args>(args)...)]() mutable {
                this->TriggerHandlerImpl(std::move(callback), std::move(args_tuple));
            });

        InstallSignals();
        running_ = true;
    }

    // Safely stop and reset the handler
    void Reset() {
        std::lock_guard<std::mutex> lock(mutex_);

        if (!running_)
            return;

        UninstallSignals();
        eventfd_write(terminate_event_fd_, 1); // Signal thread to stop

        if (thread_.joinable()) {
            thread_.join();
        }

        close(terminate_event_fd_);
        close(trigger_event_fd_);

        terminate_event_fd_ = -1;
        trigger_event_fd_ = -1;
        running_ = false;
        thread_ready_.store(false, std::memory_order_release);
    }

    // Public method to trigger from signal (signal-safe)
    void Trigger() {
        eventfd_write(trigger_event_fd_, 1);
    }

private:
    SignalHandler() = default;

    ~SignalHandler() {
        if (running_) {
            Reset();
        }
    }

    void InstallSignals() {
        struct sigaction act;
        act.sa_sigaction = TriggerEmitter;
        sigemptyset(&act.sa_mask);
        act.sa_flags = SA_SIGINFO | SA_RESTART;
        for (int sig : signals_) {
            if (sigaction(sig, &act, nullptr) == -1) {
                throw std::system_error(errno, std::system_category(), "sigaction install failed");
            }
        }
    }

    void UninstallSignals() {
        struct sigaction act;
        act.sa_handler = SIG_DFL;
        sigemptyset(&act.sa_mask);
        act.sa_flags = 0;
        for (int sig : signals_) {
            sigaction(sig, &act, nullptr); // Ignore errors
        }
    }

    static void TriggerEmitter(int signum, siginfo_t* info, void* context) {
        SignalHandler::Instance().Trigger();
    }

    template <typename CallbackT, typename ArgsTuple, size_t... I>
    void TriggerHandlerImpl(CallbackT&& callback, ArgsTuple&& args, std::index_sequence<I...>) {
        uint64_t val;
        struct pollfd pfds[2] = {{.fd = terminate_event_fd_, .events = POLLIN, .revents = 0},
                                 {.fd = trigger_event_fd_, .events = POLLIN, .revents = 0}};

        thread_ready_.store(true, std::memory_order_release);

        while (true) {
            int ret = poll(pfds, 2, -1);
            if (ret < 0) {
                if (errno == EINTR) {
                    continue;
                }
                std::cout << "Failed on poll" << std::endl;
                break;
            }

            // Check termination event
            if (pfds[0].revents & POLLIN) {
                auto count = read(terminate_event_fd_, &val, sizeof(val)); // Consume event
                if (count < 0) {
                    std::cout << "Failed on read termination event" << std::endl;
                }
                break;
            }

            // Check trigger event
            if (pfds[1].revents & POLLIN) {
                auto count = read(trigger_event_fd_, &val, sizeof(val)); // Consume event
                if (count < 0) {
                    std::cout << "Failed on read trigger event" << std::endl;
                    break;
                }
                std::forward<CallbackT>(callback)(std::get<I>(std::forward<ArgsTuple>(args))...);
            }
        }
    }

    template <typename CallbackT, typename ArgsTuple>
    void TriggerHandlerImpl(CallbackT&& callback, ArgsTuple&& args) {
        using Indices = std::make_index_sequence<std::tuple_size_v<std::decay_t<ArgsTuple>>>;
        TriggerHandlerImpl(std::forward<CallbackT>(callback), std::forward<ArgsTuple>(args),
                           Indices{});
    }

private:
    std::vector<int> signals_;

    int terminate_event_fd_ = -1;
    int trigger_event_fd_ = -1;

    std::thread thread_;
    std::mutex mutex_;
    std::atomic<bool> thread_ready_{false};
    std::atomic<bool> running_{false};
};

template <typename CallbackT, typename... Args>
void SetSignalHandler(const std::vector<int>& signals, CallbackT&& callback, Args&&... args) {
    SignalHandler::Instance().SetHandler(signals, std::forward<CallbackT>(callback),
                                         std::forward<Args>(args)...);
}

inline void ResetSignalHandler() {
    SignalHandler::Instance().Reset();
}

#endif //_SOURCE_H_


#include <gmock/gmock.h>
#include "source.h"


#include <gtest/gtest.h>
#include <signal.h>

#include <chrono>
#include <condition_variable>
#include <mutex>
#include <thread>
#include <vector>

class SignalHandlerTest: public ::testing::Test {
public:
    static void SignalCallback(SignalHandlerTest* app) {
        // SignalHandlerTest* test_ptr = reinterpret_cast<SignalHandlerTest*>(app);
        std::unique_lock<std::mutex> lock(app->signal_handler_test_mtx_);
        ++app->callback_counter_;
        app->cv_.notify_one();
    };

    static void ThreeParamsCallback(SignalHandlerTest* app, int a, std::string& b) {
        std::unique_lock<std::mutex> lock(app->signal_handler_test_mtx_);
        app->callback_counter_++;
        EXPECT_EQ(a, 42);
        EXPECT_EQ(b, "hello");
        app->cv_.notify_one();
    }

protected:
    std::mutex signal_handler_test_mtx_;
    std::condition_variable cv_;
    int callback_counter_;
    std::vector<int> valid_signals_;
    std::vector<int> non_triger_signals_;

    static void NonTrigerSignalHandler(int signal) {};

    static void MultipleTrigerSignalHandler(int signal) {};

    void SetUp() override {
        callback_counter_ = 0;
        valid_signals_ = {SIGINT, SIGTERM};
        non_triger_signals_ = {SIGTSTP};
        for (const auto& non_triger_signal : non_triger_signals_) {
            std::signal(non_triger_signal, NonTrigerSignalHandler);
        }
    };
};

TEST_F(SignalHandlerTest, SingleSignalHandling) {
    SetSignalHandler(valid_signals_, SignalCallback, this);
    std::raise(valid_signals_[0]);
    std::unique_lock<std::mutex> lock(signal_handler_test_mtx_);
    cv_.wait(lock, [&] { return callback_counter_; });
    EXPECT_TRUE(callback_counter_);
    ResetSignalHandler();
}

TEST_F(SignalHandlerTest, DifferentCallbacks) {
    {
        SetSignalHandler(valid_signals_, [this] { SignalCallback(this); });
        std::raise(valid_signals_[0]);
        std::unique_lock<std::mutex> lock(signal_handler_test_mtx_);
        cv_.wait(lock, [&] { return callback_counter_; });
        EXPECT_TRUE(callback_counter_);
        ResetSignalHandler();
        callback_counter_ = 0;
    }
    {
        std::string str = "hello";
        SetSignalHandler(valid_signals_, ThreeParamsCallback, this, 42, std::ref(str));
        std::raise(valid_signals_[0]);
        std::unique_lock<std::mutex> lock(signal_handler_test_mtx_);
        cv_.wait(lock, [&] { return callback_counter_; });
        EXPECT_TRUE(callback_counter_);
        ResetSignalHandler();
    }
}

TEST_F(SignalHandlerTest, MultipleSignalHandling) {
    int signal_counter = 0;
    for (const auto& signal : valid_signals_) {
        ++signal_counter;
        SetSignalHandler(valid_signals_, SignalCallback, this);
        std::raise(signal);
        std::unique_lock<std::mutex> lock(signal_handler_test_mtx_);
        cv_.wait(lock, [&] { return callback_counter_ == signal_counter; });
        EXPECT_EQ(callback_counter_, signal_counter);
        ResetSignalHandler();
    }
}

TEST_F(SignalHandlerTest, OneSignalMultipleHandling) {
    int signal_counter = 0;
    for (size_t i = 0; i < 10; ++i) {
        ++signal_counter;
        SetSignalHandler(valid_signals_, SignalCallback, this);
        std::raise(valid_signals_[0]);
        std::unique_lock<std::mutex> lock(signal_handler_test_mtx_);
        cv_.wait(lock, [&] { return callback_counter_ == signal_counter; });
        EXPECT_EQ(callback_counter_, signal_counter);
        ResetSignalHandler();
    }
}

TEST_F(SignalHandlerTest, OneHandlerMultpleTriggering) {
    SetSignalHandler(valid_signals_, SignalCallback, this);
    std::raise(valid_signals_[0]);
    std::raise(valid_signals_[0]);
    std::raise(valid_signals_[0]);
    std::unique_lock<std::mutex> lock(signal_handler_test_mtx_);
    cv_.wait(lock, [&] { return callback_counter_ == 3; });
    EXPECT_EQ(callback_counter_, 3);
    ResetSignalHandler();
}

TEST_F(SignalHandlerTest, NonTrigerSignalHandling) {
    for (const auto& signal : non_triger_signals_) {
        SetSignalHandler(valid_signals_, SignalCallback, this);
        std::raise(signal);
        std::this_thread::sleep_for(std::chrono::milliseconds(100));
        EXPECT_EQ(callback_counter_, 0);
        ResetSignalHandler();
    }
}

TEST_F(SignalHandlerTest, MultipleInstance) {
    SetSignalHandler(valid_signals_, SignalCallback, this);
    {
        EXPECT_THROW(SetSignalHandler(valid_signals_, SignalCallback, this), std::runtime_error);
    }
}


```