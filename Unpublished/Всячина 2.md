
Достигаем недостижимое

В прошлом посте вот такой код:

```cpp
int main() {
	while(1);
	return 0;
} 

void unreachable() {
	std::cout << "Hello, World!" << std::endl;
}
```

Приводил к очень неожиданным сайд-эффектам. При его компиляции клангом выводился принт, хотя в функции main мы нигде не вызываем unreachable.

Темная магия это или проделки ГосДепа узнаем дальше.

Для начала, этот код содержит UB. Согласно стандарту программа должна производить какие-то обозримые эффекты. Или завершиться, или работать с вводом-выводом, или работать с volatile переменными, или выполнять синхронизирующие операции. Если программа ничего из этого не делает - код содержит UB.

Так вот у нас тут бесконечный цикл. То есть предполагается, что он будет работать бесконечно и ничего полезного не делать. 

Тут очень важно понять одну вещь. Компилятор следует не вашей логике и ожиданиям, как должна работать программа. У него есть фактически инструкция(стандарт), которой он следует. 

По стандарту программа, содержащая бесконечные циклы без side-эффектов, содержит UB и компилятор имеет право делать с этим циклом все, что ему захочется.

В данном случае он просто удаляет цикл. Но он не только удаляет цикл. Но еще и удаляет инструкцию возврата из main. 

В нормальных программах функция main в ассемблере представляет из себя следующее:

```asm
main:
// Perform some code
ret
```

ret - инструкция возврата из функции. И код функции main выполняется, пока не достигнет этой инструкции.

Так вот в нашем случае этой инструкции нет и код продолжает выполнение дальше. А дальше у нас очень удобненько расположилась функция с принтом, вывод которой мы и видим. Выглядит это так:

```asm
main:

unreachable():
	push rax
	mov rdi, qword ptr [rip + std::cout@GOTPCREL]
	lea rsi, [rip + .L.str]
	call std::basic_ostream<char, std::char_traits<char>>& std::operator<<<std::char_traits<char>>(std::basic_ostream<char, std::char_traits<char>>&, char const*)@PLT
```

Почему удаляется return - не так уж очевидно и для самих разработчиков кланга. У них есть [тред обсуждения](https://github.com/llvm/llvm-project/issues/60622) этого вопроса, который не привел к какому-то знаменателю. Так что не буду городить догадок.

Справедливости ради стоит сказать, что в 19-м шланге поменяли это поведение и теперь таких неожиданностей нет. 

Stay predictable. Stay cool.

#fun #cppcore #compiler

https://gcc.godbolt.org/z/cExT86jeq


Материалы для обучения
#новичкам 

В [этом посте](https://t.me/grokaemcpp/466) вы очень хорошо постарались и накидали много ресурсов. Сейчас мы их немного систематизируем. 

Начнем с самого популярного запроса. Книги.

**База:**

Бьерн Страуструп. "Программирование: принципы и практика использования C++".

Стивен Прата. «Язык программирования C++»

Стенли Липпман. "Язык программирования C++. Базовый курс"

Эндрю Кениг. "Эффективное программирование на С++"

Брайан Керниган. «Язык программирования С»


**Немножко компьютер сайенса:**

Бхаргава Адитья. "Грокаем алгоритмы".

Кирилл Бобров. "Грокаем конкурентность".


[Книжки по продвинутому С++](https://practicum.yandex.ru/cpp/). Накладываются уже на адекватные знания языка и навыки написания кода.

Скотт Майерс. "Эффективный и современный С++"

Бартоломей Филипек. "С++17 в деталях".

Энтони Уильямс. «С++. Практика многопоточного программирования»

Пикус Ф. «Идиомы и паттерны проектирования С++».

Можно еще вот [сюда](https://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) заглянуть. Там еще больше полезных книжек.



**Курсы:**

[Пояса от Яндекса](https://cppcourse.ru). Платный.

["Добрый, добрый ОПП С++"](https://stepik.org/course/Добрый-добрый-ООП-C++-с-Сергеем-Балакиревым-205781/) на Stepik. Совсем недорогой.

1 и 2 части курса программирования на C++ от Computer Science Center на платформе Stepik. Из всех курсов, которые я изучал, это лучший в рунете имхо. 

[Программирование на языке C++](https://stepik.org/course/7/promo) на Stepik. Бесплатный.

[Программирование на языке C++ (продолжение)](https://stepik.org/course/3206/promo) на Stepik. Бесплатный.


[Введение в программирование (C++)](https://stepik.org/course/363/promo)курс Яндекса на Stepik. Бесплатный

[Базовый курс С++](https://code-basics.com/ru/languages/cpp) от Хэкслет. Бесплатный

[Бесплатный курс от Яндекса ](https://education.yandex.ru/handbook/cpp)

[C++ Tutorial ](https://www.w3schools.com/cpp/ ). Бесплатно

[Яндекс Практикум «Разработчик С++»](https://practicum.yandex.ru/cpp/). Платно.


**Ютуб:**

[Константин Владимиров обо всем](https://www.youtube.com/@tilir/featured)

[Илья Мещерин С++](https://www.youtube.com/watch?v=njfH8PHghWo&list=PLoNf82n__sV4_evodYxUhNIQIliCvGXyl)

Роман Липовский. Конкурентность. [Лекции](https://www.youtube.com/watch?v=zw6V3SDsXDk&list=PL4_hYwCyhAva37lNnoMuBcKRELso5nvBm) и [семинары](https://www.youtube.com/watch?v=mvT1Z0g_1jA&list=PL4_hYwCyhAvYTxm55RBm_HA5Bq5W1Nv-R)

[TheCherno](https://www.youtube.com/@TheCherno). Нужен английский.

[Simple Code](https://www.youtube.com/@SimpleCodeIT)


Интернет ресурсы:

https://ravesli.com/uroki-cpp/ Нужен впн

https://www.learncpp.com

https://metanit.com/cpp/tutorial/

Теперь отсебятина

У всех разная подходящая модель обучения. Не концентрируйтесь только на книгах или курсах. У всего есть свои плюсы. Надо попробовать все и найти подходящий ВАМ формат обучения. Но нужны какие-то начальные рекомендации. Я бы начал с одной из базовых книг и обязательно после каждой главы решал бы задачки(это самое главное, иначе не запомнится). "Чтобы научиться программированию, необходимо писать программы" - Брайан Керниган. Поэтому чуть освоившись с языком я бы пошел на какие-нибудь курсы из списка и просто начал бы писать код. Пройдите 3-4 из них и вы уже будете довольно хороши. 

Дальше уже можете на эту базу наваливать и лекции, и специфику, и прочее. 

**Не обязательно делать именно так**. Обучайтесь так, чтобы вам было интересно. Читайте те книги, которые вам по кайфу читать. Не любите читать книги? Пользуйтесь интернет ресурсами и ютуб уроками. 

Но обязательно нужно писать свой пет-проект. Без навыков написания кода, который решает чью-то конкретную жизненную задачу - никуда. Вот там вы хлебнете сполна, протестируете полученные знания и будете остро нуждаться в новых знаниях. Как выбрать пет-проект - вопрос не для этого поста, поэтому оставляю его за кадром.

Это все хорошо. Курсы, материалы, книжки. Но, ИМХО, есть один ресурс интересный. Если вы им научитесь пользоваться аки профи, то перед вами будут открыты все дороги. Это google.com. У новичков катастрофический дефицит знаний и огромное количество вопросов. Правильные запросы в гугл помогут вам нивелировать эти ограничения. Не самый простой навык, но он критически важен для программиста. С гуглом вы бог, а без него как без ног.

Не все ресурсы упомянул в списке. Ребята в комменты накидали много полезной, но все же специфики. Если вам интересна метапрогра, линукс или графика, то спускайтесь в тред под [этим постом](https://t.me/grokaemcpp/466). За отзывами по материалам также туда.




Квиз

Сегодня простенький #quiz на повтор материала. Настолько простенький, что может показаться очевидным. Но не дайте себя обмануть, хорошенько обдумайте и правильно ответьте. Ответ выложу вечером.

У меня к вам всего один вопрос. Что будет в результате попытки компиляции и запуска этого кода?

```cpp
#include <iostream>

int id;

int main()  
{  
	std::cout << id; 
}
```


Результат попытки компиляции и запуска?

Ошибка компиляции

Неопределенное поведение, остальное домыслы

0

Рандомное число(1488?)


Ответ

Для начала - код полностью валидный и успешно соберется. Нехватка ретурна никак не мешает. 

If control reaches the end of main without encountering a return statement, the effect is that of executing return 0;

Дальше. Весь прикол тут в том, что id - глобальная переменная. Действительно, если бы она была локальной переменной main:

```cpp
int main()  
{  
	int id;
	std::cout << id; 
}
```

то было бы использование неинициализированной переменной, неопределенное поведение и на экран вывелся бы мусор. 

Однако id - глобальная переменная. К ним применяются немного другие правила.

Дело в том, что все глобальные переменные инициализируются перед main. Вопрос только в том, как они это делают. 

В данном случае, так как нет явного инициализатора, происходит так называемая [zero-инициализация](https://t.me/grokaemcpp/260). И id будет равно 0.

Итого. На экране появится "0".

Stay defined. Stay cool.

#cppcore 


Разница инициализаций

После вчерашнего поста у некоторых читателей мог возникнуть резонный вопрос. Почему глобальные переменные инициализируются автоматически, а локальные нет? Не легче ли было установить какое-то одно правило для всех?

Единые правила - хорошая вещь. И как многие хорошие вещи, они чего-то стоят. А в С++ есть такой девиз: "мы не платим за то, что не используем". Мне не всегда нужно задавать значение переменной. Иногда меня это вообще не интересует. Я могу создать неинициализированную переменную и передать ее в функцию, где ей присвоится конкретное значение.

```cpp
int i;
FillUpVariable(i);
```

Чтобы ответить на вопрос из начала поста, давайте посмотрим, чем мы вообще платим за инициализацию в обоих случаях.

Рассмотрим локальные переменные. 

В сущности, они являются просто набором байт на текущем фрейме стека. И программа интерпретирует эти байты, как наши локальные переменные.

Чтобы инициализировать локальную переменную, нужно положить нолик в каждый байтик, который ассоциирован с этой переменной. И так нужно делать каждый раз при каждом вызове функции. Итого стоимость инициализации: немножко кода на зануление памяти при каждом входе в скоуп переменной.

Теперь глобальные переменные

Они инициализируются всего один раз при старте программы. Соответственно, стоимость - немножко кода 1 раз при старте программы.

Причем обычно, когда мы говорим про какие-то затраты и перфоманс, мы говорим о времени, когда программа уже делает полезную работу. То есть инициализация глобальных переменных проходит в "бесплатное" с точки зрения производительности время.

Итого мы получаем, что предварительная установка значений глобальных переменных проходит для нас фактически бесплатно, а для локальных переменных мы тратим минимум одну инструкцию на каждый вход в скоуп переменной. 

Теперь представьте, что мы бы потребовали устанавливать валидное значение всегда. Это просто неэффективно.

Кстати, на самом деле zero-инициализация глобальных переменных обходится нам действительно бесплатно. И никаких кавычек! Но об этом в следующем посте.

Be effective. Stay cool.

#cppcore #compiler


Бесплатная zero-инициализация

Вчера я сказал, что иногда в самой программе может попросту отсутствовать код по занулению неинициализированных глобальных переменных. Сегодня разберем, за счет чего это может достигаться.

Во время старта программы ей необходимо выделить память под такие вещи, как стек, кучу, код самой программы и **глобальные переменные**. Память программе предоставляет операционная система. Ну и естественно, что в эту память раньше была записана какая-то информация. Вообще говоря, потенциально конфиденциальная. 

И что получается, наш новорожденный процесс может видеть какую-то конфиденциальную информацию? Это же большая уязвимость.

Может ли операционная система опираться на честность человека, написавшего код, или на компилятор, что кто-то из них останется приличным парнем и сам занулит всю выданную программе память? В большинстве случаев может. Но здесь очень важны исключения, которых быть не должно.

Поэтому ОС никому не доверяет и сама зануляет всю память, которую выдает новому процессу.

А компилятор/линкер собирает все неинициализированные переменные вместе в одну секцию с названием .bss.

Получается, при старте программы у ОС запрашивается память в том числе под секцию .bss, и эта память уже аллоцируется зануленной! И никакого кода не нужно, за нас все делает операционка.

Важное уточнение, что такое поведение наблюдается не у всех операционок. Да, все эти ваши винды, линуксы и прочие макоси зануляют память перед ее передачей другому процессу. Но для каких-нибудь микроконтроллеров это может быть неактуально и компилятор должен честно вставить код зануления для того, чтобы соблюсти требования стандарта.

В чате последние пару дней были бурные обсуждения того, что этого зануления может и не быть. Ну как бы, может и не быть. Только тогда компилятор будет противоречить стандарту. И пользоваться им можно на свой страх и риск.

Don't reveal secrets. Stay cool.

#OS #compiler #cppcore

Почему тогда локальные переменные не зануляются?

Вчера мы разобрали, что когда операционка выдает процессу память, она ее зануляет. Тогда получается, что сегмент глобальных данных автоматически заполнен нулями.

Но возникает вопрос: раз ОС такая молодец и зануляет всю память, то почему локальные переменные и куча заполнены мусором? Какие-то двойные стандарты.

Все на самом деле немножко сложнее.

Есть такое памятие, как "zero-fill on demand". Заполнение нулями по требованию.

Когда процесс запрашивает память под свои сегменты, стек и кучу, ОС на самом деле не дает ему реальные страницы памяти. А дает "виртуальные". То есть ничего не аллоцирует. И эти виртуальные страницы заполнены нулями.

Процесс может свободно читать эти страницы и будет действительно видеть там нули. Однако это не будет физической памятью. Как только процесс захочет что-то записать в нее, только тогда операционка разрождается, реально аллоцирует физическую страницу и копирует содержимое той виртуальной страницы. То есть заполняет физическую нулями.

Вот как появляются нули в реальной памяти. Теперь почему они не остаются навсегда.

Дело в том, что процесс переиспользует свою память. Программа в течение всей своей жизни использует один и тот же стек и кучу. 

Мы выделили маллоком массив байт, попользовали его и освободили. И эта память не вернулась операционке. Процесс может ее переиспользовать.

Также и локальные переменные. Мы выполнили одну функцию, вернулись обратно, и выполняя следующую функцию, мы будем переиспользовать память стека под локальные переменные.

Именно поэтому кстати, мы можем получить доступ к данным, которые лежали на стеке ранее:

```cpp
void fun1() {
	int initialize = 10;
	std::cout << i << std::endl;
}

void fun2() {
	int uninitialize;
	std::cout << i << std::endl;
}

int main() {
	fun2();
	fun1();
	fun2();
}
```

Возможный вывод такого кода:

```
32760
10
10
```

Обратите внимание, что, вызывая функцию с переменной uninitialize в первый раз, мы получили мусор. Однако после вызова func1, где переменная инициализирована, в памяти стека на месте, где лежала initialize будет лежать число 10. Так как сигнатуры и содержимое функций в целом идентичны, то uninitialize во второй раз будет располагаться на том же самом месте, где и была переменная initialize. Соответственно, она будет содержать то же значение.

А учитывая, что до пользовательского кода выполняется некий "скрытый код", то даже в "начале" программы вы будете видеть на стеке мусор.

Reuse resources. Stay cool.

#OS #compiler

Программа без main?

Все мы знаем, что функция main - входная точка в программу. С нее начинается исполнение программы, если не считать глобальные переменные.

Без функции main программа просто не запустится.

Или нет?

Может быть мы можем что-нибудь нахимичить, чтобы, например, написать Hello, World без main?

Оказывается можем. Естественно, это все непереносимо. Но она на то и магия, что у разных магов свои заклинания.

Скомпилируем вот такую программу под gcc с флагом -nostartfiles:

```cpp
#include <iostream>

int my_fun();

void _start()
{
	int x = my_fun(); //calling custom main function
	exit(x);
}

int my_fun() // our custom main function
{
	std::cout << "Hello, World!\n";
	
	return 0;
}
```

И на консоли появится наша горячо-любимая надпись: `Hello, World!`

Для любителей поиграться с кодом вот вам [ссылочка](https://godbolt.org/z/r3vhYP4zW) на годболт.

А вот что за такая функция \_start и какой все-таки код выполняется до main, мы поговорим в следующий раз.

Make impossible things. Stay cool.

#fun #cppcore

Что происходит до main?

Рассмотрим простую программу:

```cpp
#include <iostream>
#include <random>

int a;
int b;

int main() {
	a = rand();
	b = rand();
	std::cout << (a + b);
}
```

Все очень просто. Объявляем две глобальные переменные, в main() присваиваем им значения и выводим их сумму на экран.

Скомпилировав эту программу, мы сможем посмотреть [ее ассемблер](https://godbolt.org/z/814T3hhbq) и увидеть просто набор меток, соответствующих разным сущностям кода(переменным a и b, функции main). Но вы не увидите какого-то "скрипта". Типа как в питоне. Если питонячий код не оборачивать в функции, то мы точно будем знать, что выполнение будет идти сверху вниз. Так вот, такой простыни ассемблера вы не увидите. Код будет организован так, как будто бы им кто-то будет пользоваться. 

И это действительно так! Убирая сложные детали, можем увидеть вот такое:

```asm
a:
	.zero 4

b:
	.zero 4

main:

	push rbp
	mov rbp, rsp
	call rand
	...
	call std::basic_ostream<char, std::char_traits<char> >::operator<<(int)
	mov eax, 0
	pop rbp
	ret
```

Суть программы состоит из меток. Метки нужны, чтобы обращаться к сущностям программы. Да, они и внутри основного кода используются. Но то, что на главной функции стоит метка, говорит нам о том, что ее кто-то вызывает! 

Перед началом работы main нужно проделать большую работу. Давайте просто перечислю, что должно быть сделано:

1 Программа загружается в оперативную память
1 Аллокация памяти для стека. Для исполнения функций и хранения локальных переменных обязательно нужен стек.
2 Аллокация памяти для кучи. Для программы нужна дополнительная память, которую она берет из кучи.
3 Инициализация регистров. Там их большое множество. Например, нужно установить текущий указатель на вершину стека(stack pointer), указатель на инструкции(instruction pointer) и тд.
4 Замамить виртуальное адресное пространство процесса. Процессы не работают с железной памятью напрямую. 
5 Положить на стек аргументы argc, argv(мб envp). Это аргументы для функции main.
6 Загрузка динамических библиотек. Программа всегда линкуется с разными динамическими либами, даже если вы этого явно не делаете)
7 Вызов всякий преинициализирующих функций.

Важная оговорка, что это все суперсильное упрощение. В реале все намного сложнее. Не претендую на полноту изложения и правильность порядка шагов. К тому же я говорю только про эквайромент полноценных ОС типа окон и пингвина. В эмбеде могут быть сильные отличия. Обязательно оставляйте свои дополнения в комментариях.

В этих полноценных осях всю эту грязную работу на себя берет загрузчик программ.
После того, как эти шаги выполнены, загрузчик может вызывать ту самую функцию [_start()](https://t.me/grokaemcpp/478)(название условное, зависит от реализации).

Она уже выполняет более прикладные чтоли вещи:

1 Статическая инициализация глобальных переменных. Это и недавно обсуждаемая [zero-инициализация](https://t.me/grokaemcpp/475) и [константная инициализация](https://t.me/grokaemcpp/266)(когда объект инициализирован константным выражением).

2 Динамическая инициализация глобальных объектов. Выполняется код конструкторов глобальных объектов.

3 Инициализация стандартного ввода-вывода. Об этом мы говорили [тут](https://t.me/grokaemcpp/480).

4 Инициализация еще бог знает чего. Начальное состояние рандомайзера, malloc'а и прочего. Так-то это часть первых шагов, но привожу отдельно, чтобы вы не думали, что только ваши глобальные переменные инициализируются.

И только вот после этого всего, когда состояние программы приведено в соответствие с ожиданиями стандарта С++, функция _start вызывает main.

Так что, чтобы вы смогли выполнить свою программу, кому-то нужно очень мощно поднапрячься...

See what's underneath. Stay cool.

#OS #compiler

std::cout

Кажется, что на начальном этапе становления про-с++-ером, вывод в использование конструкции:

```cpp
std::cout << "Print something in consol\n";
```

воспринимается, как "штука, которая выводит текст на консоль".

Даже со временем картинка не до конца складывается и на вопрос "что такое std::cout?", многие плывут. Сегодня закроем этот вопрос.

В этой строчке мы вызываем такой оператор:

```cpp
std::ostream& operator<< (std::ostream& stream, const char * str)
```

Получается, что std::cout - объект класса std::ostream. И ни какой-то там временный. Раз он принимается по левой ссылке, значит он уже где-то хранится в памяти.

Но мы же ничего не делаем для его создания? Откуда он взялся?

Мы говорили о том, что есть "невидимые" для нас вещи, которые происходят при старте программы. Так вот, это одна из таких вещей.

std::cout - глобальный объект типа std::ostream. За его создание отвечает класс std::ios_base::Init, инстанс которого явно или неявно определяется в библиотеке \<iostream>.

Но это все слова. И новичкам будет достаточно этого. Но мы тут глубоко закапываемся, поэтому давайте закопаемся в код.

Полазаем по исходникам gcc. Ссылочки кликабельные для пытливых умов.

А [хэдэре iostream](https://github.com/gcc-mirror/gcc/blob/master/libstdc%2B%2B-v3/include/std/iostream#L82) мы можем найти вот такую строчку:

```cpp
extern istream cin;		///< Linked to standard input
extern ostream cout;	///< Linked to standard output
extern ostream cerr;	///< Linked to standard error (unbuffered)
extern ostream clog;	///< Linked to standard error (buffered)
...
static ios_base::Init __ioinit;
```

Здесь определяются символы стандартных потоков и создается глобальная переменная класса ios_base::Init и . Пойдемте тогда в [конструктор](https://github.com/gcc-mirror/gcc/blob/master/libstdc%2B%2B-v3/src/c%2B%2B98/ios_init.cc#L85):

```cpp
ios_base::Init::Init()
  {
    if (__gnu_cxx::__exchange_and_add_dispatch(&_S_refcount, 1) == 0)
      {
    // Standard streams default to synced with "C" operations.
    _S_synced_with_stdio = true;

    new (&buf_cout_sync) stdio_sync_filebuf<char>(stdout);
    new (&buf_cin_sync) stdio_sync_filebuf<char>(stdin);
    new (&buf_cerr_sync) stdio_sync_filebuf<char>(stderr);

    // The standard streams are constructed once only and never
    // destroyed.
    new (&cout) ostream(&buf_cout_sync);
    new (&cin) istream(&buf_cin_sync);
    new (&cerr) ostream(&buf_cerr_sync);
    new (&clog) ostream(&buf_cerr_sync);
    cin.tie(&cout);
    cerr.setf(ios_base::unitbuf);
    // _GLIBCXX_RESOLVE_LIB_DEFECTS
    // 455. cerr::tie() and wcerr::tie() are overspecified.
    cerr.tie(&cout);
    ...
    __gnu_cxx::__atomic_add_dispatch(&_S_refcount, 1);
```

Немножко разберем происходящее.

В условии проверяется ref_count, чтобы предотвратить повторную инициализацию. Так как не предполагается, что такие объекты, как cout будут удалены, они просто создаются через placement new с помощью инстансов [stdio_sync_filebuf](https://github.com/gcc-mirror/gcc/blob/master/libstdc%2B%2B-v3/include/ext/stdio_sync_filebuf.h#L56)\<char>. Это внутренний буфер для объектов потоков, который ассоциирован с "файлами" stdout, stdin, stderr. Буферы как раз и предназначены для получать/записывать io данные.

Хорошо. Мы видим как и где создаются объекты. Но это же placement new. Для объектов уже должная быть подготовлена память для их размещения. Где же она?

В файлике [globals_io.cc](https://github.com/gcc-mirror/gcc/blob/ab78ee298864b5db8fb81e263fc0d64bfd8f082d/libstdc%2B%2B-v3/src/c%2B%2B98/globals_io.cc#L52):

```cpp
 // Standard stream objects.
  // NB: Iff <iostream> is included, these definitions become wonky.
  typedef char fake_istream[sizeof(istream)]
  __attribute__ ((aligned(__alignof__(istream))));
  typedef char fake_ostream[sizeof(ostream)]
  __attribute__ ((aligned(__alignof__(ostream))));
  fake_istream cin;
  fake_ostream cout;
  fake_ostream cerr;
  fake_ostream clog;
```

то есть, объекты - это пустые символьные массивы правильного размера и выравнивания.

#cppcore #compiler 


Линкуем массивы к объектам

Опытные читатели могли заметить кое-что странное в [этом посте](https://t.me/grokaemcpp/480). И [заметили](https://t.me/c/2009887601/31465) кстати. Изначально cin, cout и тд определены, как простые массивы. А в iostream они уже становятся объектами потоков и линкуются как онные. То есть в одной единице трансляции

```cpp
extern std::ostream cout;
extern std::istream cin;
...
```

А в другой

```cpp
 // Standard stream objects.
  // NB: Iff <iostream> is included, these definitions become wonky.
  typedef char fake_istream[sizeof(istream)]
  __attribute__ ((aligned(__alignof__(istream))));
  typedef char fake_ostream[sizeof(ostream)]
  __attribute__ ((aligned(__alignof__(ostream))));
  fake_istream cin;
  fake_ostream cout;
  fake_ostream cerr;
  fake_ostream clog;
```

Что за приколы такие? Почему массивы нормально линкуются на объекты кастомных классов?

В С++ кстати запрещены такие фокусы. Типы объявления и определения сущности должны совпадать.

Все потому что линкер особо не заботится о типах, выравнивании и даже особо о размерах объектов. То есть я буквально могу прилинковать объект одного кастомного класса к другому и мне никто никакого предупреждения не влепит. То есть такой код вполне нормально компилится:

```cpp
// header.hpp
#pragma once

struct TwoFields {
	int a;
	int b;
};

struct ThreeFields {
	char a;
	int b;
	long long c;
};

// source.cpp

ThreeFields test = {1, 2, 3};

// main.cpp

#include <iostream>
#include "header.hpp"

extern TwoFields test;

int main() {
	std::cout << test.a << " " << test.b << std::endl;
}
```

На консоли появится "1 2". Но ни типы, ни размеры типов, ни выравнивания у объектов из объявления и определения не совпадают. Поэтому здесь явное UB.

Но в исходниках GCC так удачно сложилось, что массивы реально представляют собой идеальные сосуды для объектов io-потоков. На них даже сконструировали реальные объекты. Поэтому такие массивы можно интерпретировать как сами объекты. 

Это, естественно, все непереносимо. Но поговорка "спички детям - не игрушка" подходит только для тех, кто плохо понимает, что делает. А разработчики компилятора не из этих ребят. 

Take conscious risks. Stay cool.

#cppcore #compiler

Вызываем функцию в глобальном скоупе

В отличие от С в С++ можно вызывать код до входа в main. В С нельзя вызывать функции в глобальном скоупе, и глобальные переменные там должны быть инициализированы константным выражение. Однако для С++ пришлось ослабить правила. Это было нужно для возможности создания объектов кастомных классов, как глобальных переменных. Для создания объектов нужны конструкторы. А это обычные функции. 

Поэтому в плюсах можно выполнять пользовательский код до main. Но этот код должен содержаться внутри конструкторов и вызываемых ими функциях.

Но просто так вызвать рандомную функция я не могу. Это запрещено. 

"Ну блин. Мне очень надо. Может как-то договоримся?"

Со стандартом не договоришься. Но обходные пути все же можно найти.

Например так:

```cpp
static int dummy = (some_function(), 0);

int main() {}
```

Здесь мы пользуемся уникальными свойствами оператора запятая: результат первого операнда вычисляется до вычисления второго и после просто отбрасывается. А значение всего выражения задается вторым операндом.

Получается, что здесь мы создаем статическую переменную-пустышку, чтобы получить возможность оперировать в глобальном скоупе. Инициализаторы глобальных переменных в С++ могут быть вычисляемыми. Поэтому мы используем свойство оператора запятой, чтобы беспоследственно вычислить some_function, а инициализировать dummy нулем.

Вероятнее всего, вам никогда не понадобиться так вызывать функцию. Однако оператор запятая - уникальный инструмент и может выручить даже в таких непростых ситуациях.

Have unique tools in your arsenal. Stay cool.

#cppcore #goodoldc 


Принтуем уникальный указатель
#новичкам

Умные указатели делают нашу жизнь намного проще. Они не только такие умные, что нам не стоит беспокоиться о менеджменте памяти. Они еще и очень удобные с точки зрения использования. Мы пользуемся умным указателем почти также, как мы бы пользовались обычным указателем. Все операторы перегружены так, чтобы мы вообще не видели разницу.

И мы понимаем, что это обертка, когда нам нужно достать сам сырой указатель и вызвать метод get().

Один из таких случаев - вывод указателя в поток. Если мы захотим вывести на консоль адрес объекта, то нам нужно будет вызывать метод get.

```cpp
auto u_ptr = std::make_unique<Type>();
std::cout << u_ptr.get() << std::endl;
```

Но это же странно!

Да, это скорее нужно в каких-то отладочно-логировачных целях и ничего более.

Но нужно же!

Че им стоило перегрузить оператор<<, чтобы мы могли непосредственно сам объект уникального указателя сериализовывать?

Видимо больших затрат. Но ребята справились и в С++20 мы можем использовать сам объект без метода get()!

```cpp
auto u_ptr = std::make_unique<Type>();
std::cout << u_ptr << std::endl;
```

Смысл вывода умного указателя на поток всегда был понятен, поэтому хорошо, что комитет включил такое небольшое изменение в стандарт. Теперь уникальный указатель стал еще более тонкой оберткой.

Make small changes. Stay cool.

#cpp20 #cppcore




Квиз

Вчера в комментах наш подписчик @d7d1cd задал очень интересную задачку, которой мне захотелось с вами поделиться. Да, кто-то уже ее обсудил, но тем, кто не участвовал в дискуссии, тоже будет интересно проверить свои знания в #quiz. 

Как всегда это бывает с плюсами, задачка не простая и сходу вгоняет в ступор. Но без паники! Вдох, выдох и мы опять играем в любимых(ЗАЧЕРКНУТЬ), успокоили разум, подумали и ответили.

Подписчику спасибо за контент, а у меня для вас всего один вопрос. Как правильно вызвать конструктор у такого класса?

```cpp
struct Type {
    template <typename>
    Type() {}
};
```

Challenge your knowledge. Stay cool.


Ответ

Самый главный результат опроса - почти треть канала состоит из красивых людей. In mom's humble opinion. И это прекрасно! И настоящие профессионалы, и внешне обаятельны, и в душе поэты!

Но ладно, это была лирика(поэт из меня так себе). Перейдем к правильному ответу.

Он был замаскирован, видимо поэтому набрал меньше всего голосов. 

Стандарт говорит:

```
Because the explicit template argument list follows the function template name, and because constructor templates are named without using a function name, there is no way to provide an explicit template argument list for these function templates.
```

Невозможно явно указать шаблонные аргументы для шаблонного конструктора. Компилятор должен суметь вывести эти типы на основе переданных в конструктор аргументов.

Но так как в нашем случае конструктор не принимает никаких параметров - компилятор никак не сможет вывести типы.

Поэтому невозможно вызвать конструктор у такого класса:

```cpp
struct Type {
    template <typename>
    Type() {}
};
```

Но! Объект такого класса создать можно.

Некоторые операторы в С++ неявно создают объекты. Например std::bit_cast.

```cpp
struct Type {
  template <typename>
  Type() {};
};

struct Other {};

int main() {
  Type t = std::bit_cast<Type>(Other{});
};
```

Спасибо @cppnyasha за пример.

Но конкретно в нашем случае была задача вызвать конструктор, а это невозможно.

Solve problems. Stay cool.

#cppcore #cpp20


Бросаем число
#новичкам 

Мы привыкли, что исключения какую-то свою иерархию и каждый класс имеет свое конкретное назначение в контексте отображения ошибки. 

А что если мы попытаемся бросить что-то совсем несвязанное с иcключениями? Например, какой-нибудь тривиальный тип вроде int. Это вообще законно?

Абсолютно законно. В С++ можно бросать все, что угодно, кроме объектов неполных типов, абстрактных классов и указателей на неполный тип. Даже указатель на void можно.

Как и число.

Поймать число примерно также просто, как его бросить:

```cpp
void foo() {
	throw 1;
}

int main() {
	try {
		foo();
	}
	catch(int i) {
		std::cout << i << std::endl;
	}
}

// OUTPUT: 1
```

Это кстати один из любимых вопросов у интервьюеров. 

"А можно ли кидать число вместо исключения?"

Теперь вы с полной уверенностью ответите "можно".

А вот зачем это **нужно** поговорим в следующий раз.

Make sense. Stay cool.

#interview #cppcore


BUG

Еще одно слово, которое мы постоянно используем, вроде как знаем его значение, но понятие не имеем о его ориджине. Даже те, кто знает английский, не сразу доходят до скрытых взаимосвязей.

Дело в том, что на инглише "bug" - это жук и иногда какое-то обобщенное название рандомного насекомого.

И как жуки связаны с программными ошибками?

Словом "баг" еще в позапрошлом столетии нарекали какие-то неполадки с электротехникой. В те времена эти технологии были "новинкой" и страдали от всяких детских проблем. Поэтому скорее всего эти проблемы сравнивали с жуками  из-за их схожести  с маленькими, надоедливыми насекомыми, мешающими работать. Они постоянно где-то прячутся, неожиданно появляются и непонятно откуда вылезают.  Томас Эдисон писал:

```
«Так было со всеми моими изобретениями. Первый шаг — интуиция, которая приходит как вспышка, затем возникают трудности — устройство отказывается работать, и именно тогда проявляются „жучки“ — как называют эти мелкие ошибки и трудности — и требуются месяцы пристального наблюдения, исследований и усилий, прежде чем дело дойдёт до коммерческого успеха или неудачи»
```

Поэтому такое значение слова было в принципе всегда известно. Но по отношению к программной ошибке термин стал употребляться после одного знаменитого случая(по одной из версий).

 В 1946 году в работе компьютера Марк-2 ( Harvard Mark-II) обнаружили ошибку. Тогда ЭВМ были размером с баттхертом либералов после победы Трампа. Все работало на больших элементах, лампах и реле и время от времени какой-то из элементов выходил из строя. Это вполне нормальная тема для тех лет. И в этот раз научный сотрудник Грейс Хоппер отследила проблему и была удивлена, обнаружив сгоревшего мотылька, попавшего на контакты. Бездыханный трупик мотылька был извлечен и приклеен к отчету липкой лентой с комментарием «First actual case of bug being found.» («Первый реальный случай нахождения жучка»). Press F.

Так этот жук стал самым знаменитым жуком в мире и увековечил память о себе в умах программистов и не только.
 
Можно кстати сделать один небольшой шажок вперед и понять, что примерно оттуда же растут ноги у слова «дебаггер» (debugger) – буквально «избавитель от жучков».

Dig to the origin. Stay cool.

#fun

Атомарность shared_ptr

Вокруг атомарности использования std::shared_ptr ходит куча мифов и непоняток, поэтому давайте сейчас вместе разберемся, что там неделимого в этом умном указателе.

Очень правильное слово кстати. Атомарная операция - неделимая операция(атом в переводе "неделимый"). Есть состояние объекта до и после нее. Другого не дано. Нельзя увидеть объект в каком-то промежуточном состоянии.

И очень важно отличать семантическую атомарность от аппаратной. Мы программными инструментами(например мьютексами) можем сделать так, что другие потоки не увидят промежуточного состояния. Но мы-то знаем, что в этом случае будут промежуточные состояния. Заблочили замок, сделали раз, сделали два, сделали три, освободили замок. Для других потоков критерий атомарности выполняется, они не видят промежуточных изменений. Но на уровне инструкций мы видим переходы между состояниями.

Реальная аппаратная же атомарность всех уравнивает и никто, даже программист, смотрящий в асм, не видит промежуточных состояний. Все делается одной атомарной инструкцией.

Возвращаемся к shared_ptr. 

Для начала надо понять, что модификация объекта, на который указывает указатель, не может быть по умолчанию атомарной. Методы класса реализуют люди, они могут быть какими угодно. Классы вообще не обязаны быть предназначены для использования в многопоточной среде. Поэтому задача обезопасить объект лежит на самих программистах. 

Но есть более простые операции, для которых стандарт может гарантировать атомарность "из коробки".

Изменение количества объектов std::shared_ptr, указывающих на один объект - атомарная операция. В control блоке шареда есть счетчик ссылок. Так вот операции над этим счетчиком - атомарны, так как сам счетчик представляет из себя атомарную переменную. Инкремент счетчика в конструкторе копирования и операторе копирующего присваивания, декремент счетчика в деструкторе и методе reset и свап двух указателей - это аппаратно атомарные операции. Сейчас будет очень упрощенный код, лишь для вашего более простого понимания:

```cpp
template<typename T>
class shared_ptr {
public:
...
	// Copy constructor
    shared_ptr(const shared_ptr& sp) noexcept
    : _ptr{sp._ptr},
      _ref_count{sp._ref_count},
      _deleter{sp._deleter}
    { if (_ptr) ++_ref_count; }

	// Destructor
	~shared_ptr()
    {
        if (_ptr) {
            if (--_ref_count == 0) {
                delete _ref_count;
                (*_deleter)(_ptr);
                delete _deleter;
            }
        }
    }
	// Assignment
    shared_ptr& operator=(const shared_ptr& sp) noexcept
    {
        /// copy and swap idiom
        shared_ptr tmp{sp};
        tmp.swap(*this);
        return *this;
    }
	// reset
	void reset() noexcept
    {
        shared_ptr tmp{};
        tmp.swap(*this);
    }
    
    /// Swap with another shared_ptr
    void swap(shared_ptr& sp) noexcept {
        using std::swap;
        swap(_ptr, sp._ptr);
        swap(_ref_count, sp._ref_count);
        swap(_deleter, sp._deleter);
    }
...
private:
    T* _ptr;                        /// contained pointer
    std::atomic<int> _ref_count;  /// reference counter
    Deleter* _deleter; /// deleter
};

```

Обратите внимание на поле \_ref_count. Все операции с ним происходят с помощью операторов ++ и --, которые для шаблонного класса std::atomic от арифметических типов реализованы с помощью атомарных аппаратных инструкций.

Однако есть еще одно место, в котором аппаратная атомарность была бы очень и очень полезна. Вот был бы непосредственно указатель на объект T \* атомарным... Тогда бы шаред поинтер можно было бы использовать для реализации lock-free структур данных. 

О том, существуют ли такие возможности  поговорим в следующих сериях.

Be free. Stay cool.

#concurrency #memory 

Atomic shared_ptr Ч1
#опытным 

В каком-то виде атомарные операции над std::shared_ptr появились еще в 11-м стандарте! Из-за того, что нельзя инстанцировать шаблон std::atomic с типом std::shared_ptr, так как он нетривиально копируемый, а атомные операции над шаредом хочется, сделали свободные функции std::atomic_\*, которые могут принимать этот умный указатель в качестве аргумента. 

```cpp
template< class T >  
bool atomic_is_lock_free( const std::shared_ptr<T>* p );

template< class T >  
std::shared_ptr<T> atomic_load( const std::shared_ptr<T>* p );

template< class T >  
void atomic_store( std::shared_ptr<T>* p, std::shared_ptr<T> r );

template< class T >  
std::shared_ptr<T> atomic_exchange  ( std::shared_ptr<T>* p, std::shared_ptr<T> r );

и еще несколько других.
```

Но как говорится "есть нюанс".

Если что-то называется атомик или выполняется какая-то атомарная операция, то это не значит, что тут не задействованы локи. У класса std::atomic есть метод is_lock_free. Так вот если этот метод есть, то это значит, что не все атомики лок-фри.

Так и в этом случае. std::shared_ptr - довольно сложный класс для того, чтобы операции с ним были по истине лок-фри. Поэтому типичная имплементация использует глобальные [локи](https://github.com/gcc-mirror/gcc/blob/41d6b10e96a1de98e90a7c0378437c3255814b16/libstdc%2B%2B-v3/src/c%2B%2B11/shared_ptr.cc#L59)(мьютексы или спинлоки) для защиты доступа к этим операциям. Эти мьютексы содержатся в глобальной хэш-мапе, где ключом является адрес указателя.

Но мало того, что там все замками намазано. Представьте, что у вас есть объект и несколько функций, которые позволяют потокобезопасно работать с этим объектом. Но что будет, если в какой-то части программы мы будем оперировать этим объектов вне потокобезопасных функций? Правильно UB.

```cpp
static std::mutex mtx;

template<class T>
void VecPushBack(std::vector<T>& vec, T value) {
	std::lock_guard lg{mtx};
	vec.push_back(std::move(value));
}

template<class T>
void VecPopBack(std::vector<T>& vec) {
	std::lock_guard lg{mtx};
	vec.pop_back();
}

int main() {
	std::vector<int> vec;
	for(auto i: {0, 1, 2, 3, 4}) {
		VecPushBack(vec, i);
	}
	std::jthread th{[&vec](){vec.erase(vec.begin());}}; // UB
	for (int i = 0; i < 5; i++) {
		VecPopBack(vec);
	}
}
```

Мы запустили поток, к котором напрямую удаляем элемент вектора без какой-либо синхронизации. Естественно, это data race и UB.

Так и с std::shared_ptr. Да, для него есть атомарные операции. Но если вы попытаетесь в нескольких потоках без синхронизации использовать неконстантные методы указателя, то получите ту же гонку данных. Не говоря уже об использовании самого обернутого объекта. Например, очень легко забыть вместо `ptr1 = ptr2` написать `std::atomic_store(&ptr1, ptr2)`.

Минусов в этих функция как будто больше, чем плюсов. Поэтому их в 20-м стандарте их объявили устаревшими, а в 26-м вообще выкинут за ненадобность.

Но атомарный шарик все-таки хочется. Что с этим делать поговорим в следующий раз.

Don't be outdated. Stay cool.

#cpp20 #concurrency 



Atomic shared_ptr Ч2
#опытным 

Одновременно с объявлением устаревшими атомарных функций для std::shared_ptr d C++20, у нас появилась частичная специализация шаблонного класса std::atomic\<std::shared_ptr\<T>>! 

"Но шаред поинтер же не тривиально копируемый, как атомик может инстанцироваться под него?"

Требование тривиально-копируемости подходит скорее для общего случая неизвестного шаблонного параметра. С известным типом можно это требование опустить, так как можно немного переписать конкретную реализацию класса для шареда.

Но!

Это по-прежнему лишь обертка над std::shared_ptr. То есть она по прежнему не предоставляет лок-фри операции над ним. Однако этот апи конечно намного более плюсовый и ООПшный. Все, что было нужно для синхронизации атомарного доступа к шареду, можно хранить в самом объекте, а не в глобальной области.

Пример использования - односвязный список на атомарных шареных указателях:
```cpp
template<typename T> class concurrent_stack {
    struct Node { T t; shared_ptr<Node> next; };
    atomic_shared_ptr<Node> head;
          // in C++11: remove “atomic_” and remember to use the special
          // functions every time you touch the variable
    concurrent_stack( concurrent_stack &) =delete;
    void operator=(concurrent_stack&) =delete;

public:
    concurrent_stack() =default;
    ~concurrent_stack() =default;
    class reference {
        shared_ptr<Node> p;
    public:
       reference(shared_ptr<Node> p_) : p{p_} { }
       T& operator* () { return p->t; }
       T* operator->() { return &p->t; }
    };

    void push_front( T t ) {
      auto p = make_shared<Node>();
      p->t = t;
      p->next = head;         // in C++11: atomic_load(&head)
      while( !head.compare_exchange_weak(p->next, p) ){ }
      // in C++11: atomic_compare_exchange_weak(&head, &p->next, p);
    }
    auto pop_front() {
       auto p = head.load();
       while( p && !head.compare_exchange_weak(p, p->next) ){ }
       // in C++11: atomic_compare_exchange_weak(&head, &p, p->next);
       return reference(p);
    }
};
```

Коммантами помечены строчки с использованием методов нового std::atomic\<std::shared_ptr\<T>> и их замена с использованием устаревшего API.

Become better. Stay cool.

#cpp20 #concurrency 


Проблемы отсутствия блокировок

Вообще лок фри структуры - это такие потокобезопасные структуры, для реализации которых не используются блокирующие примитивы синхронизации: мьютексы, кондвары и прочие. Их потокобезопасность достигается за счет атомарности операций над элементами структуры.

Простейшей lock-free структурой данных может быть стек. Он поддерживает 2 операции - push и pop. Пуш кладет элемент на стек, поп - убирает. Реализован он может быть на основе связанного списка. В стеке хранится всего 1 указатель - указатель на головную ноду. Нода содержит в себе сам объект и указатель на следующую ячейку.

```cpp
struct LockFreeStack {
 struct Node {
	 Type obj;
	 Node * next_ptr;
 }
	Node * head_;
}
```

Теперь возникает вопрос. А как добавить туда элемент?

Вот у нас есть готовая нода. Сделать просто так:

```cpp
void LockFreeStack::push(Node nd) {
	nd.next = head_;
	head_ = &nd;
}
```

и думать, что все пройдет гладко не получится. Посередине между двумя операциями может вклиниться еще один пуш и тогда мы потеряем элемент этой второй вставки. Представьте

```
Изначально было так
nd3 -> nd2 -> nd1
 |
head

Потом мы создали ноду, следующим элементом которой будет голова стека

new_node -> nd3			nd3 -> nd2 -> nd1
						 |
						head
Теперь текущий поток заснул, другой поток удачно выполнил операцию вставки элемента и заснул. Проснулся наш изначальный поток и теперь картина такая:

new_node -> nd3			nd4 -> nd3 -> nd2 -> nd1
						 |
						head
Делаем присвоение голове и получаем следующее:

new_node -> nd3			new_node -> nd3 -> nd2 -> nd1
						   |		 ^
						  head       |
								    nd4
```

Получается утечка памяти и некорректное поведение программы, так как к ноде nd4 теперь ни от куда не получить доступ.

Нужно каким-то образом одновременно получить доступ к актуальному указателю головы и подменить в нем этот указатель. Это должна быть неделимая операция на уровне процессора, чтобы мы точно знали, что делаем операцию над актуальным указателем.

Такая операция существует и она ключ к построению всех lock-free структур данных. Называется она Compare-and-Swap. О ней в следующей серии.

Make 2 things at the same time. Stay cool.

#concurrency #memory 

SpinLock

Один очень важный примитив синхронизации, понимание работы которого нам понадобится в будущем для Compare and Swap.

Чисто внешне - это обычная блокировка, которая позволяет защитить доступ к критической секции. Но дьяво носит прада(зачеркнуть) кроется в деталях.

Блокировка мьютекса - системный вызов, который заставляет поток уснуть(немного упрощаю) и вовлекает в работу планировщик задач. 

А что если можно было бы буквально писюличку подождать, мьютекс освободится и мы смогли бы его захватить? Тогда мы зря засыпали и вовлекали планировщик. 

Это и есть идея спинлока. Busy waiting в цикле на каком-то условии. Пока условие правдивое, мы жжем ресурсы процессора и ждем у море погоды. Благо скорее всего ждать долго не нужно будет(зависит от задачи) и мы получим доступ к критической секции без сна.

Реализуется спинлок на атомарной переменной. Атомик здесь абсолютно необходим, потому что в тот момент, когда один поток "захватил ресурс", все другие потоки на следующем же чтении переменной должны это увидеть. Операции над атомиками подразумевают использование барьеров памяти, которые и позволяют подтянуть изменения во все потоки.

Простейшая реализация спинлока:

```cpp
class SpinLock {
    std::atomic_flag locked = ATOMIC_FLAG_INIT ;
public:
    void lock() {
        while (locked.test_and_set()) { ; }
    }
    void unlock() {
        locked.clear();
    }
};
```

У нас есть атомарная переменная флаг(читай атомарный bool). Инициализируем его false. Дальше в методе lock крутимся в цикле, пока флаг locked не будет опущен(снова не станет нулем) и как только это случается, мы выставляем флаг и локаем замок aka получаем доступ к критической секции. В методе unlock просто опускаем флаг.

Все эти операции выполняются атомарно и все участники вечеринки видят последствия действий друг друга.

Благодаря такому интерфейсу кстати этот SpinLock можно использовать во всем любимых обертках типа std::lock_guard.

Обращу также внимание, что не стоит всегда отдавать предпочтение либо мьютексу, либо спинлоку. У них есть специфические сферы применения и ограничения, поэтому в каждой конкретной ситуации нужно проводить тесты для выбора оптимального решения.

Don't sleep in vain. Stay cool.

#concurrency #memory 



Compare and Swap. Ч1

Краеугольный камень всей lock-free обработки. Эта операция, которая позволяет за одну инструкцию сделать 2 вещи: сравнить два значения и сделать запись(или обменять два значения в оригинале). 

Давайте снова посмотрим на реализацию спинлока

```cpp
class SpinLock {
    std::atomic_flag locked = ATOMIC_FLAG_INIT ;
public:
    void lock() {
        while (locked.test_and_set()) { ; }
    }
    void unlock() {
        locked.clear();
    }
};
```

А конкретно на эту строчку

while (locked.test_and_set()) { ; }

Очень подозрительно выглядит. Метод test_and_set нарушает принцип single responsibility. Он и тестирует значение, и устанавливает его. 2 операции. 

Но нет! Это одна операция! И она называется Compare and Swap(CAS). Мы проверяем значение флага на false и в случае успеха выставляем его в true. Это делается одной инструкцией ассемблера.

Почему тут обязана быть эта операция? Чтобы никто своими надоедливыми записями не вклинился между сравнением и записью. Может получиться так, что и мы и другой поток протестировали значение, оно оказалось false, и оба потока вошли бы в критическую секцию.

Поэтому жизненно важно, чтобы никто не мог увидеть промежуточного результата. Либо флаг true и ничего не происходит, либо как только мы увидели флаг false он тут же стал true.

На уровне машины это происходит примерно так(идейно и упрощенно):

1. Процессор читает область памяти, предназначенное для сравнения, не снимая по завершении чтения блокировку шины..
2. Процессор сравнивает прочтённое значение со значением в аккумуляторе (регистр AL, AX, EAX или RAX). Флагу ZF присваивается значение в зависимости от результата сравнения (1 — если значение в памяти равно значению в аккумуляторе, 0 — если они различаются).
3. Если значение в памяти было равно значению в аккумуляторе, процессор записывает значение  в область памяти. По завершении записи блокировка шины снимается.

Далее программист обязан закодировать проверку флага ZF для выяснения, выполнилась операция успешно или к моменту её начала значение в памяти было заменено другим агентом.

Это мы и делаем в цикле. Если на момент начала операции значение флага равно true, то условие выхода из цикла не выполнено и мы крутимся дальше. Если мы все до конца сделали - выходим из цикла.

Ну и надо заметить, что спинлок - тоже локфри структура. Мы не берем никаких блокировок, а честно крутимся на ядре и тратим его ресурс, пока нам не повезет.

Это в любом случае хорошо. Но CAS позволяет делать намного более сложные штуки, типа стеков и очередей, о чем мы говорили ранее. Продолжим в следующий раз.

Make 2 things at the same time. Stay cool.

#concurrency #memory 



Compare and Swap. Ч2

Давайте вернемся в контекст стека и поймем, как Compare and Swap(CAS) позволяет решить проблему потокобезопасности.




Варианты защиты в многопотоке

Сегодня рассмотрим варианты защиты критических секций в многопотоке на примере нашего стека
```cpp
struct Stack {
	struct Node {
		Type obj;
		Node * next_ptr;
	};
	void push(Node nd) {
		nd.next = head_;
		head_ = &nd;
	}
	Type pop() {
		auto nd = head_;
		head_ = head_->next;
		return nd->obj;
	}
	Node * head_;
}
```

Есть не так много вариантов, как можно обеспечить корректную работу стека в многопотоке:

1 Обложить все мьютексами. Стандартное решение, ничего нового.

```cpp
std::mutex Stack::mtx_;

void Stack::push(Node nd) {
	std::lock_guard lg{mtx_}
	nd.next = head_;
	head_ = &nd;
}

Type Stack::pop() {
	std::lock_guard lg{mtx_};
	auto nd = head_;
	head_ = head_->next;
	return nd->obj;
}
```

2 Защитить не мьютексом, а спинлоком. Идея та же, просто это будет работать чуть быстрее, чем с замками, потому что критическая секция очень маленькая. 

```cpp
SpinLock Stack::splc_;

void Stack::push(Node nd) {
	std::lock_guard lg{splc_}
	nd.next = head_;
	head_ = &nd;
}

Type Stack::pop() {
	std::lock_guard lg{mtx_};
	auto nd = head_;
	head_ = head_->next;
	return nd->obj;
}
```

3 Использовать связку мьютекс+кондвар. Кондвары позволяют усыпить поток до наступления определенного события. А также информировать другие потоки о том, что им бы пора проснуться.

Вы могли заметить, что для метода pop очень хреновые гарантии безопасности. При пустом списке и вызове метода pop будет UB. Ровно [как и в STL](https://t.me/grokaemcpp/465). 

Однако кондвар позволит усыпить поток, который хочет достать элемент из стека, до тех пор, пока там не появятся новые элементы. И в методе пуш позволит уведомить ждущий поток, что данные появились.

```cpp
std::mutex Stack::mtx_;
std::condition_variable Stack::cv_;

void Stack::push(Node nd) {
	std::unique_lock ulck{mtx_}
	nd.next = head_;
	head_ = &nd;
	ul.unlock();
	cv_.notify_one();
}

Type Stack::pop() {
	std::unique_lock ulck(mtx_);
    cv_.wait(ulck, [this] {
      return head_;
    });
	auto nd = head_;
	head_ = head_->next;
	return nd->obj;
}
```
Правда это работает только для одного треда-консюмера.

4 Использовать CAS операцию. Объявить голову атомарным указателем и вызывать метод compare_exchange_weak. Так мы превращаем стек в lock-free структуру данных

Тут мы заснуть не можем, поэтому нужно немного изменить интерфейс pop, чтобы не плодить UB.

```cpp
void Stack::push(Node nd) {
	nd->next = head_.load();
	while (!head_.compare_exchange_weak(nd->next, nd)) {}
}

std::optional<Type> Stack::pop() {
	auto nd = head_.load();
	while(nd && !head.compare_exchange_weak(nd, nd->next)){}
	if (!nd) {
		return std::nullopt;
	}
	
	return nd->obj;
}
```

Вам задание со звездочкой: защитить стек семафором. Свои варианты пишите в комментариях.

Если знаете еще способы защиты - тоже велкам под кат.

Protect your treasure. Stay cool.

#concurrency 


notify_one vs notify_all

Будить спящих почем зря в моем мире карается как минимум словесным буллингом, а как максимум - организацией сглаза у знакомой бабки. 

Потоки тоже не хотели бы, чтобы их будили просто так.

Но не всегда так сходу понятно, когда использовать notify_one, а когда notify_all на кондваре. Сегодня быстренько с этим разберемся.

Естественно, все зависит от контекста. Но все же есть определенная логика.

Очевидно, что, если у вас всего один ждущий тред, то тут без разницы. Один и есть все().

Теперь если много.

Тут надо смотреть на условие ожидания. Если любой из тредов может справиться с наступившим условием, тогда уведомляем любого одного из них. Например, мы положили одну таску в очередь.  Эту одну таску может забрать на выполнение только один поток. Больше никого не нужно будить.

Если не любой из потоков может в итоге продолжить выполнение дальше(например, если условие просыпание уникально для каждого потока), то лучше уведомлять каждого. А они там дальше сами разберутся.

Ну или если у вас сразу много тредов могут продолжить работу после пробуждения, то тоже уведомляем всех. Например, вы положили много тасок в очередь сразу и у вас много читателей. Разбудите всех и им каждому найдется работенка.
Или вы наоборот, ждете момента, чтобы несколько тредов сразу начали генерить данные. Тогда тоже будите всех.

В любой непонятной ситуации просто подумайте, что делают ждуны и что вы для них приготовили. Ответ придет довольно быстро.

Don't bother unnecessarily. Stay cool.

#concurrency 



Правильно уведомляем треды

Вспомним вот этот код:

```cpp
std::mutex Stack::mtx_;
std::condition_variable Stack::cv_;

void Stack::push(Node nd) {
	std::unique_lock ulck{mtx_}
	nd.next = head_;
	head_ = &nd;
	ul.unlock();
	cv_.notify_one();
}

Type Stack::pop() {
	std::unique_lock ulck(mtx_);
    cv_.wait(ulck, [this] {
      return head_;
    });
	auto nd = head_;
	head_ = head_->next;
	return nd->obj;
}
```

Особенно на последние две строчки пуша.

А точно ли правильно уведомлять ждущие потоки о наступлении условия не под локом? Не приведет ли это ни к каким гонкам?

Обратимся к цпп референсу:

```
The notifying thread does not need to hold the lock on the same mutex as the one held by the waiting thread(s); in fact doing so is a pessimization, since the notified thread would immediately block again, waiting for the notifying thread to release the lock.
```

Уведомляющий поток не должен держать замок во время уведомления. Может, но не должен.

Но если он держит замок, то это даже вызвает пессимизацию производительности.

Вот мы уведомили другой поток о наступлении условия пробуждения и дальше хотим освободить лок. В промежуток времени между этими операциями просыпается уведомляемый тред, смотрит на условие - оно верное, а значит он попытается захватить мьютекс. И у него ничего не получится, так как уведомляющий поток все еще держит его залоченным. И уведомляемый поток уходит спать на попытке захватить мьютекс. 

А проснется он непонятно когда, тут уже полная ответственность планировщика.

То есть у нас ситуация: задача есть, но она не выполняется.

Именно поэтому лучше делать нотифаи не под локом.

Don't pessimize your solutions. Stay cool.

#concurrency 
