Оры:
- применяет порядки std::memory_order_acquire и std::memory_order_release на атомиках
- применяет std::atomic_thread_fence acquire+release для форсирования упорядоченного выполнения
- понимает частичный порядок при использовании высокоуровневых инструментов (thread, mutex) 

Структура:

- В прошлом уроке мы говорили про порядок Sequential Consistency, потому что это то, что мы имеем по умолчанию. Этот порядок делает исполнение кода понятным и полностью предсказуемым. Однако это очень жесткий порядок, который требует обильного межядерного общения и запрета оптимизаций. В некоторых ситуациях мы можем несколько ослабить требования к порядку и получать корректное поведение. В этих случаях мы можем использовать более слабые порядки, о которых сейчас и пойдет речь.
- Возвращаемся к одному из примеров прошлого урока и показываем, что при использовании атомика никакие операции сверху не могут быть переупорядочены после атомика и никакие операции снизу не могут быть переупорядочены вверх перед атомиком. Это очень сильные требования, которые не всегда нужны. Посмотрим, как можно их ослабить.
- Можно представить, что атомик - это такой барьер, который не пропускает вверх и вниз какие-то операции. Для неатомиков у нас есть только store и load. Приводим все варианты барьеров: StoreLoad, StoreStore, LoadLoad, LoadStore. Объединяем пары, которые представляют собой acquire и release барьеры. Все 4 - это последовательное выполнение. StoreLoad практически не используется.
- Показываем все слабые порядки из стандартной библиотеки и сопоставляем их с StoreLoad, StoreStore, LoadLoad, LoadStore.
- Приводим примеры для каждого слабого порядка
- acq_rel
- acquire+release
- release+consume
- relaxed
- Однако это еще не все, что нам предоставляет стандартная библиотека. В ней есть функция std::atomic_thread_fence, которая проставляет нужные барьеры памяти. Самое главное, что эти барьеры могут обеспечивать частичный порядок Synchronized-With, а значит и Happens-Before, а значит могут использоваться для написания программ без гонок.
- Однако использование атомиков все же нужно, потому что синхронизация только через них происходит. Отличие в том, что теперь можно использовать relaxed порядок
- Явные барьеры  накладывают более сильные ограничения синхронизации, чем операция атомиков и используются в основном при использовании нескольких атомиков с relaxed моделью, чтобы для них всех задать один порядок. Имеют смысл только явные acquire и release барьеры.
- Закругляемся разговором про то, как устроены высокоуровневые инструменты с точки зрения модели памяти и барьеров. Как конкретно работает мьютекс, какие частичные порядки он навязывает, какие порядки навязывает join треда и тд.


## Введение

В прошлом уроке мы говорили про порядок Sequential Consistency, как поведение по-умолчанию. Этот порядок делает исполнение кода понятным и полностью предсказуемым. Однако это очень жесткий порядок, который требует обильного межядерного общения и запрета оптимизаций. В некоторых ситуациях мы можем несколько ослабить требования к порядку и получать корректное поведение. В этих случаях мы можем использовать более слабые порядки, о которых сейчас и пойдет речь. Сегодня вы узнаете:

- какие бывают виды возможных запретов на реордеринг инструкций.
- какие есть слабые порядки в С++ и какие реордеринги они допускают.
- какие барьеры памяти есть в стандартной библиотеке.
- как устроены высокоуровневые инструменты многопоточной синхронизации с точки зрения отношения порядка.


## Виды реордерингов

Давайте вернемся к примеру из прошлого урока:

```cpp
std::string data;
std::atomic<bool> ready;

void foo() {
	data = "data";                 // 1
	ready.store(true);             // 2
}

void bar() {
	if (ready.load()) {            // 3
		std::println("{}", data);  // 4
	}
}
```

На данный момент мы знаем, что операция 1 "расположена-раньше" 2, операция 2 "синхронизирована-с" 3, а операция 3 "расположена-раньше" 4. Из этого следует, что операция 1 "произошла-раньше" 4.

Однако давайте поразмышляем в терминах реордерингов. 

```cpp
std::string data;
std::atomic<bool> ready;

void foo() {
	data = "data";
//-------------------------------- // первая линия
	ready.store(true);
}

void bar() {
	if (ready.load()) {
//-------------------------------- // вторая линия
		std::println("{}", data);
	}
}
```

Sequential Consistency запрещает компилятору и ядру переставлять все операции, находящихся в областях выше линий, в области ниже линий. И наоборот.

Но в данном случае нам не нужен такой строгий порядок. 

Для первой линии нам достаточно лишь не пропускать никакие операции записи, находящиеся выше линии, в область ниже линии. И не пропускать никакие операции записи, находящиеся ниже линии, в область выше линии.

В этом случае мы корректно запретим опасный реордеринг в функции foo. Однако нам еще нужно корректно данные прочитать в bar. Для второй линии нам достаточно лишь не пропускать никакие операции чтения, находящиеся выше линии, в область ниже линии. И не пропускать никакие операции чтения, находящиеся ниже линии, в область выше линии.

```cpp
void foo() {
	data = "data";
	// не пропускаем сюда никакие записи снизу
//-------------------------------- // первая линия
	// не пропускаем сюда никакие записи сверху
	ready.store(true);
}

void bar() {
	if (ready.load()) {
		// не пропускаем сюда никакие чтения снизу
//-------------------------------- // вторая линия
		// не пропускаем сюда никакие чтения сверху
		std::println("{}", data);
	}
}
```

Таким образом мы ослабим требования к реордерингу и тем самым разрешим более эффективно исполнять код, не теряя при этом в корректности его поведения.

Если чуть присмотреться к этому коду, то станет интуитивно понятно, что мы поставили какой-то барьер, сквозь который не могут проходить определенные инструкции.

Обычно такие барьеры именуют с помощью типа операций, которые они не пропускают вниз и наверх.

Барьер функции foo обозначается, как "StoreStore". Первая часть говорит о том, что запрещается перемещение операций записи ниже барьера. Вторая часть говорит о том, что запрещается перемещение операций записи выше барьера.

Аналогочным образом именуется барьер функции bar - "LoadLoad".

Давайте дадим более точное определение.

## Барьер памяти

Барьер памяти вида "XXYY" гарантирует, что все ХХ-операции до барьера будут выполнены строго до того, как начнут выполняться YY-операции после барьера.

Так как над любой переменной можно выполнять всего 2 типа операций - чтение(Load) и запись(Store), то и соответствующих барьеров существует всего 4 вида: LoadLoad, LoadStore, StoreLoad, StoreStore.


![[Pasted image 20250620203024.png]]


Однако в большинстве процессоров встречаются в основном комбинации этих барьеров: Acquire барьер - это LoadLoad + LoadStore, Release барьер - это LoadStore + StoreStore.

![[Pasted image 20250620210436.png]]

Acquire барьер гарантирует, что любые операции после барьера будут выполнены после того, как будут выполнены все Load-операции до барьера.

Release барьер гарантирует, что любые операции до барьера будут выполнены до того, как начнут выполняться Store-операции после барьера.

Получается, что в нашем знакомом примере эти барьеры могут располагаться вот так:

```cpp
std::string data;
std::atomic<bool> ready;

void foo() {
	data = "data";
	// Release барьер здесь
	ready.store(true);
}

void bar() {
	if (ready.load()) {
		// Acquire барьер здесь 
		std::println("{}", data);
	}
}
```

Можно рассуждать здесь так: Release барьер нужен, чтобы "отправить" данные неатомиков в другой поток(release - "отпустить"), а Acquire барьер нужен, чтобы "принять" в точности те же данные, которые мы отпустили(Acquire - "захватить").

У нас остался еще один барьер - StoreLoad. Это самый "дорогой" с точки зрения производительности барьер, потому что требует полной синхронизации всех кэшей процессора, что очень сильно сказывается на производительности. Плюс количество ситуаций, в которых действительно нужен, очень мало. Поэтому как отдельный барьер его практически не используют.

## Слабые порядки

Мы уже говорили ранее, что по-умолчанию для атомарных переменных используется Sequential Consistency. На самом деле это значило, что операция над атомиками также представляет из себя полный барьер памяти, который состоит из всех приведенных выше барьеров LoadLoad, LoadStore, StoreLoad и StoreStore. Сама атомарная операция запрещает реордеринг всех инструкций до и после себя.

Однако мы может кастомизировать поведение атомиков и сделать так, чтобы барьеры на операциях над ними ослабли.

Для этого в стандартной библиотеке есть перечисление std::memory_order. std::memory_order указывает, как доступы к памяти, включая обычные, неатомные доступы к памяти, должны быть упорядочены вокруг атомарной операции.

Мы от вас долго это скрывали, но каждая атомарная операция принимает дополнительный параметр - порядок, с помощью которого можно ослабить барьеры памяти. Например, метод store класса std::atomic имеет такую сигнатуру:

```cpp
void std::atomic<T>::store( T desired, std::memory_order order = std::memory_order_seq_cst ) noexcept;
```

В атомарных операциях барьеры работают несколько иначе, чем мы описали выше. Для ясности введем следующие понятия:
- AtomicOpRelease - этот барьер гарантирует, что все чтения и записи до барьера будут выполнены строго до того, как будет выполнена запись в атомик. В отличие от барьера Release, любые записи после AtomicOpRelease могут быть переставлены выше барьера.
- AtomicOpAcquire - это барьер гарантирует, что все чтения и записи после барьера будут выполнены строго после того, как будет выполнено чтение из атомика. В отличие от барьера Acquire, любые чтения до AtomicOpAcquire могут быть переставлены ниже барьера.


В С++ существуют следующие порядки:

1. memory_order_seq_cst. Этот порядок мы имеем по-умолчанию и он запрещает любые виды реордерингов.
2. memory_order_acq_rel. Это сочетание 2-х барьеров: AtomicOpAcquire и AtomicOpRelease.
3. memory_order_release - устанавливает AtomicOpRelease барьер.
4. memory_order_acquire - устанавливает AtomicOpAcquire барьер.
5. memory_order_consume. Этот барьер очень похож на AtomicOpAcquire, только он гарантирует упорядоченность только тех операций, которые зависят по данным. В С++26 его объявили "deprecated" или "устаревшим". Это значит, что в следующих стандартах его скорее всего совсем удалят, а сам факт объявления сущности "устаревшей" обычно значит, что ей мало кто пользовался и "лучше бы ее не было". Поэтому мы не будем дальше рассматривать этот порядок подробнее.
6. memory_order_relaxed. Отсутствие каких-либо барьеров. Атомарные операции также остаются атомарными, однако такой порядок разрешает любые виды реордерингов. При использовании этого порядка между store и load операциями не возникает отношение "Синхронизировано-С", поэтому вы лишаетесь возможности синхронизировать неатомарные переменные через атомарные операции.


memory_order_seq_cst мы уже подробно разобрали в уроке про модель памяти, поэтому давайте поговорим про остальные порядки с примерами.

## memory_order_acquire и memory_order_release

Не зря мы так много говорили про эти барьеры, потому что это основные слабые порядки, которые используются для синхронизации неатомарных переменных через атомарные.

В основном общение между потоками исполнения без использования мьютексов выглядит следующим образом. В одном потоке подготовливаются какие-то данные и отправляются в другой поток, чтобы он их прочитал. То есть происходит запись в разделяемые неатомарные объекты в одном потоке, затем идет сигнализация о готовности данных через атомарную переменную и далее чтение данных в другом потоке. Это ровно та схема, которую мы использовали в примере из начала урока. Давайте теперь явно проставим порядки в операциях над атомиком:

```cpp
std::string data;
std::atomic<bool> ready;

void foo() {
	data = "data";
	ready.store(true, std::memory_order_release); // не пропускаем никакие опреации ниже этой строчки
}

void bar() {
	if (ready.load(), std::memory_order_acquire) { // не пропускаем никакие операции выше этой строчки
		std::println("{}", data);
	}
}
```

memory_order_release запрещает записи в data выполнится после записи в атомик ready, а memory_order_acquire запрещает читать data до того, как произойдет чтение значения из ready.

## memory_order_acq_rel

Этот слабый порядок является одновременно проявлением барьеров AtomicOpAcquire и AtomicOpRelease.

Над атомарными переменными можно проводить не только load и store операции, но еще и read-modify-write. Так как такие операции являются одновременно чтением и записью, то они могут одновременно использоваться для приема и отправки данных в другие потоки. По отдельности барьеров AtomicOpAcquire и AtomicOpRelease в таких случаях недостаточно и необходимо использовать комбинированный барьер AtomicOpAcquire+AtomicOpRelease. В С++ такой барьер можно навязать с помощью порядка memory_order_acq_rel.

Возьмем реализацию спинлока из первого урока и проставим в ней более слабые порядка, чем memory_order_seq_cst:

```cpp
class SpinLock {
    std::atomic<bool> locked{false};
public:
    void lock() {
        while (locked.exchange(true, std::memory_order_acq_rel)) {} // (1)
    }
    
    bool try_lock() { 
	    return !locked.exchange(true, std::memory_order_acq_rel))); // (2)
	}
    
    void unlock() {
        locked.store(false, std::memory_order_release); // (3)
    }
};
```


## memory_order_relaxed

Этот порядок не подразумевает никакой синхронизации неатомарных переменных, поэтому если вам это не нужно, то такой порядок обеспечивает самую высокую скорость операций, так как разрешает множество оптимизаций.

Например, вы хотите посчитать, сколько раз вычислилась какая-то функция:

```cpp
std::atomic<int> count;
auto foo(int input) {
	auto result1 = process1(input);
	auto result2 = process2(result1);
	count.fetch_add(1, std::memory_order_relaxed);
	return process3(result2);
}
```

Вам неважно, в каком месте функции окажется эта инструкция, что было до нее или после. Поэтому здесь отлично вписывается самый слабый порядок.

## std::atomic_thread_fence

В С++ не только атомарные операции могут выступать в качестве барьеров памяти. В стандартной библиотеке есть функция std::atomic_thread_fence, которая в любом месте программы проставляет нужные барьеры памяти.

```cpp
void atomic_thread_fence( std::memory_order order ) noexcept;
```

Она принимает такие же порядки, что и атомарные операции.

Хорошие новости в том, что std::atomic_thread_fence проставляет ровно те самые барьеры LoadLoad, LoadStore, StoreLoad и StoreStore и их комбинации, без каких либо оговорок:

- std::atomic_thread_fence(std::memory_order_seq_cst) - полный барьер, запрещающий все виды реордерингов.
- std::atomic_thread_fence(std::memory_order_acq_rel) - Acquire+Release барьер.
- std::atomic_thread_fence(std::memory_order_release) - Release барьер.
- std::atomic_thread_fence(std::memory_order_acquire) - Acquire барьер.
- std::atomic_thread_fence(std::memory_order_consume) - Acquire барьер.
- std::atomic_thread_fence(std::memory_order_relaxed) - отсутствие барьера, функция не имеет никакого эффекта.

Тем самым барьер std::atomic_thread_fence предоставляет более строгие гарантии на запрет реорерингов, чем атомарная операция с тем же std::memory_order. Например атомарный store с порядком std::memory_order_release предоствращает все чтения и записи перед store перемещаться после этой операции. А std::atomic_thread_fence(std::memory_order_release) предотвращает все предшествующие барьеру чтения и записи от перемещения ниже всех следующих операций store.

Из-за этой особенности std::atomic_thread_fence обычно используется для добавления синхронизации в последовательность нескольких relaxed атомарных операций.

```cpp
std::string computation(int);
void print(std::string);

std::atomic<int> ready0 = -1, ready1 = -1, ready2 = -1;
std::string data[1000]; //non-atomic data

// Thread A, вычисляем 3 значения.
void ThreadA(int v0, int v1, int v2) {	
	data[v0] = computation(v0);
	data[v1] = computation(v1);
	data[v2] = computation(v2);
	// нужен барьер, чтобы все записи выше произошли строго до всех записей ниже
	std::atomic_thread_fence(std::memory_order_release);
	ready0.store(v0, std::memory_order_relaxed);
	ready1.store(v1, std::memory_order_relaxed);
	ready2.store(v2, std::memory_order_relaxed);
}

// Thread B, prints between 0 and 3 values already computed.
void ThreadB() {
	int v0 = ready0.load(std::memory_order_relaxed);
	int v1 = ready1.load(std::memory_order_relaxed);
	int v2 = ready2.load(std::memory_order_relaxed);
	// нужен барьер, чтобы все чтения выше произошли строго до всех чтений ниже
	std::atomic_thread_fence(std::memory_order_acquire);
	// не гарантируется, что все переменные v0, v1, v2 будут отличны от -1, однако строго гарантируется, что когда в какую-то из них записывается значение, то мы сможем прочитать корректное значение data
	if (v0 != -1)
		print(data[v0]);
	if (v1 != -1)
		print(data[v1]);
	if (v2 != -1)
		print(data[v2]);
}
```

std::atomic_thread_fence безопасно использовать только в сочетании с атомарными переменными. Без атомарных операций, даже с самым слабым порядком синхронизиция неатомарных переменных невозможна.

Если барьер std::atomic_thread_fence(std::memory_order_release) R "расположен-раньше" записи в атомарную переменную, и существует чтение из этой атомарной переменной, которое "расположено-раньше" барьера std::atomic_thread_fence(std::memory_order_acquire) A, то R "синхронизировано-с" A. В этом случае все неатомарные изменения перетекают в другие потоки именно благодаря барьерам, а не атомикам.

Подходящие кейсы применения явных барьеров std::atomic_thread_fence очень редки, поэтому они используются в очень специфических местах сложной синхронизации.

## Высокоуровневые инструменты и модель памяти

Когда мы пользуемся высокоуровневыми инструментами из библиотеки многопоточности, мы обычно не задумываемся, как и почему они работают. Нам важен результат и то, какие гарантии обеспечивает инструмент. Но раз уж мы и так находимся на таком низком уровне, давайте посмотрим, как с точки зрения модели памяти работают высокоуровневые инструменты при работе с многопоточностью.

Существует немало реализаций мьютексов, спинлоков и других примитивов синхронизации, которые обеспечивают свойство взаимного исключения. Однако принцип всегда один: lock() - это атомарный load с порядком std::memory_order_acquire, а unlock() - это атомарный store с порядком std::memory_order_release. 

Также каждый вызов unlock "синхронизируется-с" вызовом lock() и успешным вызовом try_lock. Именно благодаря установлению такого отношения между операциями возможно установление межпотоковой синхронизации данных, при которой все изменения в одной критической секции становятся видны другим потокам, захватившим примитив синхронизации.

std::condition_variable - это просто оптимизация цикла busy-ожидания, поэтому вся синхронизация предоставляется самим lockable объектом.

Даже в самом классе std::thread есть места синхронизации. 

Завершение конструктора std::thread "синхронизировано-с" вызовом функции потока. Это позволяет запустить функцию на уже корректно созданном и инициализированном потоке.

Также завершение потока "синхронизировано-с" возвращением из метода join(). Это позволяет корректно использовать все данные из дочернего потока в родительском потоке, который вызвал join().

Благодаря высокоуровневым инструментам работы с многопоточностью мы можем напрямую не взаимодействовать с моделью памяти и нюансами ее работы. Но важно понимать, как эти инструменты работают на низком уровне, чтобы использовать их с максимальной эффективностью.

**Кнопка**: К итогам!

## Заключение

В этом уроке вы узнали:

- Всего бывает 4 вида переупорядочиваний инструкций и соответствующих барьеров, которые предотвращают эти упорядочивания:  LoadLoad, LoadStore, StoreLoad, StoreStore.
- 2 барьера LoadLoad и LoadStore объединяются в Acquire барьер.
- 2 барьера LoadStore и StoreStore объединяются в Release барьер.
- Для каждой атомарной операции можно указать порядок - набор барьеров, который будут запрещать определенные переупорядочивания. К таким порядкам относятся std::memory_order_seq_cst, std::memory_order_acq_rel, std::memory_order_release, std::memory_order_acquire, std::memory_order_consume, std::memory_order_relaxed.
- Атомарный load с порядком memory_order_acquire в сочетании атомарным store с порядком std::memory_order_release образуют отношение "синхронизировано-с", поэтому могут использоваться для более быстрого обмена данными между потоками, за счет смягчения требований к переупорядочиванию.
- В С++ с помощью std::atomic_thread_fence можно явно проставить барьер памяти, который не будет привязан с конкретной атомарной операции. Однако для обеспечения отношения "синхронизировано-с" и межпоточной коммуникации нужно использовать Acquire и Release барьер в сочетании с relaxed атомарными операциями.
- благодаря тому, что освобождение и захват мьютекса связаны между собой отношением "синхронизировано-с", результаты все операции критической секции становятся доступны другим потокам.

 





