
Оры:

- понимает концепции программирования без блокировок и ожиданий в сравнении с блокировками
- понимает идею написания стэка без блокировок


Структура:

- мы познакомились с инструментами С++, которые предоставляют возможность оперировать любыми данными потокобезопасно - мьютексы. Также мы познакомились с инструментами управления данными без блокировок - атомики. Использование этих инструментов порождает разные концепции программирования, которые резко отличаются друг от друга и важно понимать их различия
- начнем с программирования с замками. Только один поток выполняется в одно время и то не гарантировано, возможны дедлоки при использовании нескольких локов. Сложности одновременного захвата нескольких замков. Проблема конвоирования. Тем не менее можно относительно просто управлять любыми данными и при большом размере критической секции это оптимальный подход. Так же под каждую задачу можно применить свою версию лока и, например, к короткой критической секции можно применить спинлок и он будет эффективнее мьютекса в этой ситуации.
- программирование без ожиданий. Все потоки в любой момент времени совершают прогресс. С этой концепцией можно получить самую высокую скорость исполнения, но обычно ее можно реализовать только для самых простых операций, типа инкремента счетчика.
- программирование без блокировок. Оно основано на CAS и предполагает ожидание в цикле до тех пор, пока поток не получит актуальную информацию о значении разделенных данных и не заменит ее на нужную. Как и в случае с программированием с замками, только один поток прогрессирует. Разница в том, что мы наверняка знаем о прогрессе, как минимум один поток никогда и нигде не ждет. Не проблем с дедлоками, захватами нескольких замков и конвоированием. Однако непрогрессирующие потоки активно тратят cpu, а писать программы без блокировок очень сложно.
- Квиз 1
- Для демонстрации концепции программирования без блокировок, напишем lock-free stack.
- Начинаем с реализации с мьютексами. Объясняем как работает, почему такой интерфейс.
- Пытаемся улучшить производительность стека, поэтому приходим к lock-free реализации. 
- Описываем, почему сложно реализовать стек на буффере: нужно трекать ячейки с которыми работают консюмеры и продюсеры. Вместо этого можно использовать связный список - тогда все работают только с головой стека. Реализация на атомарных указателях.
- Пишем метод push.
- Пишем метод pop.
- Говорим, что у такой реализации есть проблема - утечка ресурсов. Отсылаемся на прошлый урок и переписываем на атомарный шаред птр.
- Квиз 2


## Введение

Мы познакомились с инструментами С++, которые предоставляют возможность оперировать любыми данными потокобезопасно - мьютексы. Также мы познакомились с инструментами управления данными без блокировок - атомарные переменные. Использование этих инструментов порождает разные концепции программирования, о которых мы сегодня поговорим. Вы узнаете:

- какие бывают концепции многопоточного программирования, их плюсы и минусы.
- как написать свой стек без блокировок.

## Концепции многопоточного программирования

Мьютексы позволили нам безопасно использовать разделяемые данные в многопоточной среде. Однако только один поток в один момент времени может получить доступ к разделяемым данным. Тем самым несколько теряется преимущество многопоточной среды. Будем называть такую концепцию - программирование с блокировками.

Атомарные же переменные и операции над ними позволяют реализовывать многопоточные программы совершенно на других принципах. К разделяемым данным можно получить доступ кому-угодно и в любой момент времени. На атомиках можно реализовывать два подхода - программирование без ожиданий и программирование без блокировок.

Чтобы понимать, в какой ситуации какую концепцию использовать, нужно знать их особенности. Давайте поговорим о них более подробно.
## Программирование с блокировками

Когда мы используем мьютексы:

```cpp
std::mutex m;
size_t count; // защищено m

void foo() {
	std::lock_guard l(m);
	++count;
}
```

мы используем блокировки. Это значит, что только один поток может войти в критическую секцию, а все остальные потоки ждут, пока он закончит работать с данными. Как только блокировка будет снята, другой сможет захватить мьютекс и увеличить count. В любой момент времени всего один поток совершает работу. Или нет?

На самом деле даже это не гарантировано. 

Большой и сложный С++ проект будет скорее всего использовать множество мьютексов. Если потоку нужен доступ к другой общей переменной, он может ждать захвата эксклюзивного доступа к ней, которая удерживается каким-то другим потоком. И это ожидание может длится сколь угодно долго. Вплоть до бесконечности в случае дедлоков, когда потоки по кругу ждут принадлежащих друг другу ресурсов. Или неопределенного количества времени в случае использования std::scoped_lock, который в силу особенностей реализации(Всплывашка: std::scoped_lock позволяет безопасно блокировать несколько мьютексов без угрозы для дедлока. Принцип и алгоритм его работы довольно сложен, он состоит из неупорядоченного вызова методов try_lock, lock и unlock у переданных мьютексов. На пальцах: он пытается захватить все переданные мьютексы с помощью try_lock и если на каком-то из них захват закончился неудачей, то std::scoped_lock отпускает все уже захваченные мьютексы и пытается захватить их снова) может привести к лайвлоку.

Фундаментальная проблема работы с несколькими мьютексами заключается в том, что они плохо сочетаются: нет хорошего способа объединить два или более замков в один.

Даже без учета лайвлоков и дедлоков, программы, основанные на блокировках, страдают от других проблем. Один из самых частых и та, которую трудно диагностировать, называется эффектом конвоя.

Допустим, у нас есть код, защищённый блокировкой. Поток А захватывает блокировку и работает с общими данными, а другие потоки ждут. Но работа не одноразовая — каждый поток выполняет много задач, и для каждой задачи нужно захватывать блокировку снова. Поток А завершает одну задачу, освобождает блокировку, быстро переходит к следующей задаче и снова захватывает блокировку. Но другие потоки не успевают "проснуться" и конкурировать за блокировку, потому что поток А активный и он сразу берёт её снова.

В результате задачи потока А проносятся, как машины в колонне, а другие потоки практически не прогрессируют. Отсюда и название - эффект конвоя.

Но даже не смотря на все эти недостатки, программирование на блокировках - это основа подавляющего большинства многопоточных С++ проектов. Причин несколько:

- использовать блокировки относительно просто, такой код понимает большинство разработчиков, его легко читать и модифицировать.
- позволяет защищать критическую секцию любого размера, в которой работа ведется с любыми типами данных.
- блокировки бывают разные и под разные задачи можно использовать свой вид блокировки. Если операции в критической секции короткие, то можно использовать спинлок, если длинные - мьютекс.


## Программирование без ожиданий

Атомарные переменные привнесли новые возможности - теперь любой поток может изменять данные без использования блокировок и это не будет приводить к гонке данных! Доступ к атомарной переменной ничем не ограничен - нет ожидающих потоков, они все могут одновременно получать доступ к переменной и совершать прогресс в исполнении. Отсюда и название концепции - программирование без ожиданий. Ни один поток ничего не ждет, а просто выполняет операции.

```cpp
std::atomic<size_t> count;

void foo() {
	count.fetch_add(1, std::memory_order_relaxed);
}
```

В этом случае можно достичь самой высокой скорости обработки.

Однако вариативность операций над атомарными переменными не очень впечатляет. И количество случаев применения, где логика использования атомика не завязана на предыдущее его значение, тоже невелико.

На переднем крае computer science инженеры придумывают реализации алгоритмов и структур данных на базе программирования без ожиданий. Но такие реализации очень громоздки и сложны для понимания.

Поэтому программирование без ожиданий используется в явном виде довольно редко, в основном для реализации атомарных счетчиков.

## Программирование без блокировок

К счастью, существует своего рода «универсальная» атомарная операция, которую можно использовать для создания любой read-modify-write операций практически любой степени сложности.

Эта операция Compare-And-Swap. В С++ она представлена методами атомика compare_exchange_strong и compare_exchange_weak. Она делает условную запись: если текущее значение атомика соответствует ожидаемому, то текущее значение заменяется на новое.

С помощью этой операции можно, например, увеличивать счетчик в 2 раза

```cpp
std::atomic<size_t> count;

void foo() {
	size_t expected = count.load(std::memory_order_relaxed);
	while (!count.compare_exchange_strong(expected, expected * 2, std::memory_order_relaxed, std::memory_order_relaxed));
}
```

Чтобы увеличить именно текущее значение счетчика нам нужно дождаться, пока у нас будут актуальные данные о его значении. Методы compare_exchange_* записывают актуальное состояние атомика в первый аргумент, если ожидаемое значение не соответствует реальному. И в цикле мы дожидаемся момента, когда у потока будет актуальное ожидаемое значение, и производим подмену. 

Разобраться в работе этого кода сложнее, чем во всех предыдущих примерах. Хотя здесь нет блокировок, используется цикл, который может выполняться неопределенно количество раз. В этом смысле такой подход похож на программирование с блокировками: любой поток, пытающийся получить захваченную блокировку, попадает в похожий цикл и нет информации о том, когда он из него выйдет.

Однако есть одно ключевое различие. В программировании с блокировками мы не знаем, когда поток освободит замок и совершает ли вообще прогресс. Может, он завис или ждёт какого-то другого события.

В программе, основанной на compare-and-swap, единственный вариант, при котором не сможет обновить разделяемую переменную - какой-то другой поток обновил переменную раньше. Поэтому мы знаем, что из всех потоков, пытающихся одновременно увеличить счетчик, по крайней мере, один всегда будет успешным. 

В таких программах потоки ожидают определенного события, но исполнение никогда не блокируется. Как минимум один поток гарантированно прогрессирует. Такая концепция многопоточного программирования называется программирование без блокировок.

В программировании без блокировок не проблем с дедлоками, лайвлоками и конвоированием.

Однако не все так радужно. Писать и читать программы без блокировок очень сложно, стоимость их поддержки по этой причине высокая. Грамотно протестировать такие программы тоже сложно, потому что порядок вычисления недетерминирован и многое зависит от планирования исполнения потоков, на который мы повлиять не можем.

К тому же потоки, которые крутятся в CAS цикле активно тратят cpu, что может сильно нагружать процессор так, что на другие задачи времени не останется. 

## Стек без блокировок

Для того, чтобы продемонстрировать концепцию программирования без блокировок, давайте напишем lock-free стек.

Стек - структура данных, которая подчиняется правилу LIFO(Last In First Out) - последний помещенный элемент в стек достается самым первым из него. 

В С++ есть адаптер для стандартных контейнеров std::stack, который реализует данную структуру данных. Но он рассчитан на безопасное использование только в однопоточной среде. Для использования в многопоточной среде нам нужно сделать определенные корректировки.

Для начала, нам придется отказаться от таких методов, как top, empty и size. Они просто не имеют смысла в многопоточной среде:

```cpp
ThreadSafeStack<int> stack;

// thread 1
if (stack.empty()) {
	std::println("Stack size = {}, top = {}", stack.size(), stack.top())
}

// thread 2
stack.pop();
```

В примере выше потоки могут так запланироваться, что в момент после вызова метода empty в первом потоке второй поток достанет последний элемент из стека. Получается, что мы вошли в условие, предполагая одно состояние стека, а внутри условия работаем уже с другим состоянием. Получение верхнего значения стека в момент, когда он пустой, может привести к неопределенному поведению или к вылету исключения. В общем, приятного мало.

Нельзя добавлять в многопоточный стек методы, которые сообщают о его внутреннем состоянии, потому что он может в любой момент стать неактуальным.

Получается, что потокобезопасный стек должен иметь 2 метода: push и pop. Причем pop должен в каком-то виде возвращать элемент, который он достал из стека, чтобы мы могли оперировать этим элементом:

```cpp
template<typename T>
struct ThreadSafeStack {
	void push(const T& value);

	T pop();
};
```

Далее нам нужно выбрать основу для будущего стека без блокировок. Готовые решения из стандартной библиотеки нам априори не подходят - они написаны без использования атомарных операций. Нужно писать свое с нуля.

Тут два подхода. Первый - элементы стека находятся в буфере подряд идущих ячейках памяти, который динамически расширяется при добавлении новых элементов. Похоже на std::vector. Выглядит это вот так:

![[Pasted image 20250703212920.png]]
Каждый push будет атомарно увеличивать текущий счетчик элементов, занимая слот для будущего элемента, и после этого создает объект на зарезервированном участке памяти:

```cpp
const size_t top = top_.fetch_add(1);
new (&data[top]) Element(… constructor arguments … );
```

Однако конструирование объект не всегда происходит быстро. Одновременно в стеке могут быть несколько ячеек, которые зарезервированы под элемент, но сам элемент еще до конца не сконструировался:

![[Pasted image 20250703213704.png]] (Здесь надо дизайнерам сказать, что крайний левый элемент должен быть N - 4)

Представим, что именно в этот момент другой поток вызвал метод pop. 

*Практикум* Какой элемент должен вернуть метод pop?

*Студент* Кажется, я знаю!

Элементы N - 1 и N - 2 он не может вернуть, потому что они еще до конца не сконструировались.

Можно вернуть N - 3. Но тогда в стеке появятся дырки, которые непонятно, как обрабатывать.

Разумным решением будет дождаться создания последнего объекта и вернуть его. Но это сильно усложняет логику реализации.

Более простой стек можно написать на основе второго подхода - связного списка. 

![[Pasted image 20250703215325.png]]

И push, и pop в такой схеме работают только с головой стека. Они вставляют и достают уже готовые объекты, им достаточно всего лишь правильно перекинуть указатели. И на наше счастье мы можем работать с указателями атомарно!

Давайте отобразим структуру будущего стека в коде:

```cpp
template<typename T>
class lock_free_stack {
	// узлы стека состоят из данных и указателя на следующий элемент
	struct node {
		T data;
		node* next;
		node(const T& data_) : data(data_) {}
	};
	// атомарный указатель на голову стека
	std::atomic<node*> head;
}
```

Элементы стека связаны друг с другом внутренними указателями, а оперируем мы только атомарным указателем на голову стека
## Push

Что нужно, чтобы вставить в связанный список новый элемент?

1. Создать новую ноду с готовыми данными.
2. Присвоить указателю next указатель head.
3. Присвоить head указатель на новую ноду

Это работает прекрасно в однопоточном окружении. Но в присутствии других потоков нам просто необходимо пункты 2 и 3 делать подряд так, чтобы между этими операциями состояние состояние стека не изменилось, иначе получим неконсистентный стек и неопределенное поведение.

Однако у атомиков есть идеальный инструмент для этого - операция CAS. Она позволит убедиться, что у потока в данный момент актуальные данные о состоянии стека и только в этом случае произвести подмену:

```cpp
void push(const T& data) {
	// полностью конструируем новый элемент
	node* const new_node=new node(data);
	// получаем значение указателя головы стека
	new_node->next=head.load();
	// если у нас актуальные данные, то производим подмену указателей
	// если не актуальные, то актуализируем значение new_node->next и пробуем снова сделать подмену
	while(!head.compare_exchange_weak(new_node->next, new_node));
}
```

Таким образом мы избежим состояния гонки и будет консистентно класть элементы в стек.

## Pop

Теперь надо научиться извлекать элементы из стека. Для этого нужно выполнить следующие шаги:

1. Прочитать значение указателя head.
2. Прочитать значение указателя head->next.
3. Установить head->next новой головой стека.
4. Вернуть элемент, который изначально содержался по адресу head.
5. Освободить память под ноду, на которую изначально указывал head.

И снова нам критически важно выполнить шаги 1-3 атомарно и для этого нам поможет метод compare_exchange_weak:

```cpp
std::shared_ptr<T> pop() {
	// получаем актуальную голову
	node* old_head=head.load();
	// если стек непустой и мы имеем актуальные данные о значении головного указателя, то производим подмену
	while(old_head && !head.compare_exchange_weak(old_head, old_head->next));
	// оборачиваем данные ноды в std::shared_ptr 
	return old_head ? old_head->data : std::shared_ptr<T>();
}
```

Чтобы не иметь проблем с исключениями при возврате данных по значению, оборачиваем указатель на элемент стека в умный указатель. Тем самым предотвращая любые манипуляции с объектом - он никуда не копируется и не перемещается.

Однако в этой реализации есть большая проблема. Но в многопоточной среде просто не бывает. Мы не делаем 5 шаг, не освобождаем память, занимаемую узлами стека. И на это есть причина.

Если два потока одновременно удаляют элементы из стека, они оба могут прочитать одно и то же значение `head` на шаге 1. Если первый поток успеет выполнить все шаги вплоть до 5-го(удаления ноды) до того, как второй поток дойдёт до шага 2, второй поток обратится к **висячему указателю** (dangling pointer). А значит будет UB

Все потому что мы использовали обычные указатели в качестве поля узла. 

Как решить эту проблему?

*Кнопка* Я вспомнил!

Использовать атомарный std::shared_ptr конечно. С его помощью мы можем не заботиться о освобождении ресурсов - за нас все сделает умный указатель. С ним метод pop выглядит так:

```cpp
std::shared_ptr<T> pop() {
	// получаем актуальную голову
	std::shared_ptr<node> old_head=head.load();
	// если стек непустой и мы имеем актуальные данные о значении головного указателя, то производим подмену
	while(old_head && !head.compare_exchange_weak(old_head, old_head->next.load()));
	if(old_head) {
		// атомарно заменяем на пустой указатель, чтобы отрезать его от стека
		old_head->next.store(std::shared_ptr<node>());
		return old_head->data;
	}
	return std::shared_ptr<T>();
}
```

И никаких утечек памяти!

Итоговая реализация стека без блокировок выглядит вот так:

```cpp
template<typename T>
class lock_free_stack {
	// узлы стека состоят из данных и указателя на следующий элемент
	struct node {
		std::shared_ptr<T> data;
		std::atomic<shared_ptr<node>> next;
		node(const T& data_) : data(std::make_shared<T>(data_)) {}
	};
	// атомарный умный указатель на голову стека
	std::atomic<shared_ptr<node>> head;
public:
	void push(const T & data) {
		// полностью конструируем новый элемент
		const std::shared_ptr<node> new_node=std::make_shared<node>(data);
		// получаем значение указателя головы стека
		new_node->next=head.load();
		// если у нас актуальные данные, то производим подмену указателей
		// если не актуальные, то актуализируем значение new_node->next и пробуем снова сделать подмену
		while(!head.compare_exchange_weak(new_node->next,new_node));
	}
	
	std::shared_ptr<T> pop() {
		// получаем актуальную голову
		std::shared_ptr<node> old_head=head.load();
		// если стек непустой и мы имеем актуальные данные о значении головного указателя, то производим подмену
		while(old_head && !head.compare_exchange_weak(old_head, old_head->next.load()));
		if(old_head) {
			// атомарно заменяем на пустой указатель, чтобы отрезать его от стека
			old_head->next=std::shared_ptr<node>();
			return old_head->data;
		}
		return std::shared_ptr<T>();
	}
	
	~lock_free_stack(){
		// достаем все элементы из стека; для каждого из них тут же вызовется деструктор
		while(pop());
	}

};
```


**Кнопка**: К итогам!

## Заключение

В этом уроке вы узнали:

- Существуют 3 концепции программирования в многопоточной среде: программирование с блокировками, без блокировок и без ожидания.
- Программы с блокировками защищают критические секции инструментами взаимного исключения потоков. Эти программы просто читать и отлаживать, однако они страдают от дедлоков, лайвлоков, конвоирования и низкой скорости работы.
- Программирование без ожиданий потенциально предоставляет самую высокую скорость работы алгоритмов, потому что любой поток в любой момент времени совершает прогресс и не зависит от операций в других потоках. Но алгоритмы без ожиданий либо ограничиваются атомарными счетчиками, либо очень сложны для понимания и поддержки.
- Программы без блокировок основаны на операции Compare-And-Swap. Они гарантируют, что по крайней мере один поток в любой момент времени совершать прогресс в исполнении, что не будет дедлоков и лайвлоков. Но активно ждущие потоки также активно потребляют ресурс CPU, что может негативно сказаться на пиковой нагрузке и других приложениях в системе.
- Стек без блокировок не может иметь методов, возвращающих его состояние, потому что это состояние может стать неактуальным в любой момент времени.
- Простой стек без блокировок основан на связном списке и операции Compare-And-Swap. Его идея: поток ждет, пока получит актуальные данные о голове стека, и производит нужную замену.
- Использование атомарных std::shared_ptr помогает предотвратить утечку узлов.