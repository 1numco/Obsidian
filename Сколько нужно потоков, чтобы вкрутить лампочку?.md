Почти каждое продуктовое приложение или библиотека подразумевает использование многопоточности. Либо для собственных вычислений, либо в качестве окружения, в котором будут использоваться наши модули. Поэтому критически важно даже на начальном уровне иметь представление о том, как concurrency работает в плюсах и за счет чего она реализуется.

Потоки - нити выполнения кода. То есть, если какой-то код выполняется, значит он делает это в рамках треда. Даже не так. Исполнение - это и есть тред. Это по факту просто набор структур, с помощью которых это исполнение и реализовывается.

Мы знаем, что в с С++11 у нас появилось стандартное средство для запуска потоков - std::thread. Создаем объект потока, передаем в него функцию, которую мы хотим в отдельном потоке запустить - и вот у нас уже есть отдельное исполнение. И ничто нас не останавливает от запуска одного, двух, трех или тысячи дополнительных потоков.

И первая мысль, которая может прийти в голову - запущу 100кк потоков и буду богом вычислений. Каждый поток ведь исполняет функцию. Получается и могу 100млн раз исполнить какие-то функций. Красота!

Потом в голову ударяет логика. Человек, хоть и многозадачное существо, не может делать миллион дел сознательно одновременно. Так и процессор, он не может делать, все что ему скажут. Хотя было бы очень весело и полезно. Но он не всесильный и у него есть объективные ограничения по частоте. Но если есть ограничения, то хотелось бы знать, какие они, касательно количества потоков?

Важный дисклеймер, что тут надо бы упомянуть про процессы и как они связаны с потоками, но это отдельная тема и не об этом сегодня. На сегодня опустим этот термин, потому что не прям он так и важен сейчас в контексте. Программы исполняются потоками, и это правда, которая сейчас нужна. Младшие ребята - ждите дополнительных разъяснений, а старшие - не кидайтесь шапками за недосказанность.

В давние времена процессор содержат лишь одно ядро и, соотвественно, в один момент времени только один поток команд мог исполняться. Но людям очень хотелось выполнять несколько задач одновременно. И окошко открыть, и мышкой двигать, и все это под ритм бразильского фонга. Но вот проблема - если запустить отдельные потоки под эти задачи(я сейчас очень упрощаю все и не касаюсь всяких асинхронных операций), то они просто будут простаивать. И чтобы хоть как-то иметь возможность иметь много задач на компьютере был придуман планировщик задач. Это такой распределитель ресурсов процессора. Он решает, когда и какому именно потоку выдать ресурсы. Но и даже с этим инструментом в один момент времени выполняется только один поток. Остальные ждут своей очереди и не продвигаются дальше. Но если эти переключения потоков делать достаточно быстро и грамотно, то человек особо не почувствует задержек и будет думать, что все работает одновременно. Это называется псевдопараллельность.

На наших машинках сегодня очень много приложений запущено и соотвественно много потоков исполнения. Нам сильно везет, что они спят большую часть времени. Но все равно в каждый момент времени эти потоки конкурируют за ресурсы. То есть за процессорное время. 

Одно ядро, как правило, в один момент времени может выполнить одну условную инструкцию. И ему в целом без разницы, из какого конкретного потока будет эта инструкция. Ядро выступает в роли разделяемого ресурса, за который сражаются потоки.

Теперь же у нас есть прям пользовательские компьютеры с 32-мя процессорными ядрами, не говоря уже про серверы. А про видеокарты я вообще молчу. Там их тысячи.

То есть теперь мы можем исполнять несколько тредов в один и тот же момент времени! Истинная параллельность!

И получается, что вопрос не в том, сколько мы потоков можем запустить. Можем хоть десять, хоть тысячу. Вопрос в том, как будет эффективнее? В конце концов нас почти всегда интересует скорость работы.

Представим, что у нас есть огромная гора файлов, которые нам нужно токенизировать и подсчитать частоту токенов во всей этой горе файлов. Задача - однотипная и действия, которые мы совершаем над одним файлом, можно применить и для всех других. Напрашивается распараллеливание этой задачи по файлам. Условно - запускаем много-много потоков и они делают одно и то же, только со своими файлами. Так вот вопрос - сколько можно таких потоков запустить, чтобы минимизировать время подсчета частоты токенов для всех файлов?

Простой ответ - std::thread::hardware_concurrency. Это число, которое говорит вам, сколько реально конкурентных потоков(тех которые выполняются в один и тот же момент времени) вы можете запустить, чтобы это было поддержано железом. Но внимание! Это всего лишь подсказка, а не точное значение. Более того, оно предоставляется во время выполнения и в целом может равняться нулю, если информация недоступна! Но как бы предполагается, что это значением равняется количеству ядер процессора. Оно и понятно: если одно ядро выполняет одну инструкцию в один момент времени, то параллельно могут исполняться столько инструкций, сколько ядер доступно системе.

Чуть сложнее ответ - надо мерять. Разный энвайромент будет по разному влиять на скорость вычислений. Самое простое ограничение - диспетчер задач. Он же тоже занимает какое-то количество времени на свою работу. И если потоков в системе очень много (например, еще несколько ресурсоемких приложений запущено), то все больше и больше времени будет тратиться не на выполнение задач, а на переключение контекстов выполнения этих потоков. В пределе может получится так, что система будет заниматься только этим бесполезным с функциональной точки зрения заданием и не выполнять полезной работы.

Поэтому

Measure your performance. Stay cool.

#multitasking #OS

Проверить скорость вычислений от количества потоков

зачем может быть нужен std::thread::id

Когда в процессе может существовать несколько потоков(а сейчас обычно это условие выполняется), то очевидно, что эти потоки надо как-то идентифицировать. Они будут конкурировать друг с другом за ресурсы и планировщику нужно знать, кому именно нужно выдавать заветное процессорное время. И действительно, у каждого потока в системе есть свой уникальный номер(лучше сказать идентификатор). И мы, как прикладные разработчики, можем даже его получить. С появлением С++11 у нас есть стандартное средство для этого - std::thread::id. Это тип, которые и представляет собой идентификатор потока.

Его можно получить двумя способами - снаружи потока и внутри него. 

Снаружи мы должны иметь объект std::thread, у которого хотим узнать id, и вызвать у него метод get_id(). Если с объектом не связан никакой поток исполнения, то вернется дефолтно-сконструированный объект, обозначающий "я девушка свободная, не обременненная никаким исполнением". 

Внутри id можно достать с помощью свободной функции std::this_thread::get_id().

Объекты типа std::thread::id могут свободно копироваться и сравниваться. Иначе их нельзя было бы использовать, как идентификаторы. Если два объекта типа std::thread::id равны, то они репрезентуют один и тот же тред. Или оба являются свободными девушками. Если объекты не равны, то они представляют разные треды или один из них создан конструктором по умолчанию.

Стандартная библиотека никак не ограничивает вас в проверке одинаковые ли идентификаторы или нет: для объектов std::thread::id предусмотрен полный набор операторов сравнения, которые предоставляют возможность упорядочить все отличные друг от друга значения. Эта возможность позволяет использовать id в качестве ключей в ассоциативных контейнерах, они могут быть отсортированы и тд. Все вытекающие плюшки. Операторы сравнения обеспечивают свойство ассоциативности(?) для объектов. То есть, если a < b и b < c, то a < c. Также у нас из коробки есть возможность получить хэш id с помощью std::hash<std::thread::id>, что позволяет использовать идентификаторы потоков в хэш-таблицах, аля unordered контейнерах.

На самом деле, не очень тривиально понять, где и как эти айдишники могут быть использованы, поэтому в следующем посте проясню этот момент подробно.

Identify yourself. Stay cool.

#multitasking #cpp11 

shared_ptr и массивы.

Есть одна не самая приятная вещь при работе с std::shared_ptr. С момента его выхода в С++11 и в С++14 он не может быть использован из коробки для того, чтобы хранить динамические массивы. По дефолту во всех случаях при исчерпании ссылок на объект, шареный указатель вызывает оператор delete. Однако, когда мы аллоцируем динамический массив new[], мы хотим вызвать delete[] для его удаления. Но shared_ptr вызовет delete. А это неопределенное поведение.

То есть я не могу просто так вот взять и написать

```cpp
shared_ptr<int[]> sp(new int[10]);
```

Кстати говоря, у его собрата std::unique_ptr с этим все получше. У него есть отдельная частичная специализация для массивов. Поэтому вот так я могу написать спокойно:

```cpp
std::unique_ptr<int[]> up(new int[10]); // вызовется корректный delete[]
```

Что можно сделать, чтобы таки использовать сишные массивы с шареным указателем?

1)Обернуть указатель на массив в класс и шарить уже объекты этого класса. Типа того(упрощенно):
```cpp
template <class T>
struct DynamicArrayWrapper {
	DynamicArrayWrapper(size_t size) : ptr{new T[size]} {}
	~DynamicArrayWrapper() {delete[] ptr;}
	T * ptr;
};

std::shared_ptr<DynamicArrayWrapper> sp{10};
```

У такого метода есть 2 проблемы. Первое - прокси класс. Дополнительные обертки увеличивают объем и сложность кода и затрудняют его понимание кода. Второе - перформанс. Здесь уже два уровня индирекции, что замедлит обработку.

2)Передать свой кастомный делитер. Тут тоже несколько вариантов.
Написать свой:
```cpp
template< typename T >
struct array_deleter
{
  void operator ()( T const * p)
  { 
    delete[] p; 
  }
};

std::shared_ptr<int> sp(new int[10], array_deleter<int>());
```

Использовать лямбду:
```cpp
std::shared_ptr<int> sp(new int[10], [](int *p) { delete[] p; });
```

Ну или воспользоваться уже готовым вариантом:
```cpp
std::shared_ptr<int> sp(new int[10], std::default_delete<int[]>());
```
std::default_delete имеет частичную специализацию для массивов.

Но! Какой хороший все-таки стандарт С++17, который поправил многие такие маленькие косячки. А как он это сделал - увидим в следующий раз)

Be comfortable to work with. Stay cool.

#cpp11  #memory

Исправляем косяк std::shared_ptr с массивами

В прошлом посте мы говорили, что шареный указатель не работает с массивами из коробки, как это делает unique_ptr. Однако стандарт С++17 исправляет этот момент.

Что мы теперь имеем.

Для создания объекта таким конструктором:
```cpp
template< class T >   
explicit shared_ptr( T* ptr );
```

используется делитер delete ptr, если T - не массив, и delete[] ptr если Т -массив.

Также теперь изменился тип element_type, то есть тип хранимого объекта. Раньше от был просто Т, теперь же это 
```cpp
using element_type = remove_extent_t<T>;
```
std::remove_extent - это такой type_trait. Все, что нужно о нем знать - если Т - массив, то тип element_type будет совпадать с типом элементов массива.

Теперь мы даже можем использовать operator[] для доступа к элементам массива. Делается это так:
```cpp
std::shared_ptr<int[]> num(new int[10]{0, 1, 2, 3, 4, 5, 6, 7, 8, 9});
    for (std::size_t i = 0; i < 10; ++i)
        std::cout << num[i] << ' ';
```

Так что теперь это действительно полноценные шареные массивы из коробки. Весь интерфейс подогнали под это дело.

Но вот вопрос: а нафига это вообще надо? Когда кто-то вообще в последний раз использовал динамический массив?

Мы же вроде на плюсах пишем. Есть плюсовые решения - std::vector, если размер не известен на момент компиляции, и std::array, если известен. У них и интерфейс удобный и унифицированный и все-таки это объектно-ориентированный подход. И сердцу тепло, и глаз радуется. Динамические массивы выглядят, как окаменелые какашки динозавров. 

C std::array соглашусь. Думаю, что нет адекватных оправданий использования динамических и статических массивов, длина которых известна в compile-time.

Но вот с векторами немного сложнее. Удобство требует жертв. Именно в плане производительности. Поэтому в узких бутылочных горлышках, где надо выжимать всю скорость из кода, лучше использовать динамические массивы вместо std::array. Но обычному бэкэдеру, думаю, это в принципе не понадобится.

Если фича есть, значит она кому-то нужна. Просто иногда интересно узнать о таких минорных изменениях. А кому-то поможет больше не использовать кастомные делитеры и иметь более понятный код.

Fix your flaws. Stay cool.

#cpp17 #memory


std::make_shared в С++20

Начиная со стандарта С++11 в С++ появилась поддержка создания std::shared_ptr при помощи фабричной функции std::make_shared. У нас даже есть пост про особенности этой функции вот здесь. Но у нее были такие же недостатки, как и у std::shared_ptr до С++17. Нельзя было ее использовать для массивов. Но начиная с С++20 эта фабричная функция синхронизировалась со своим вдохновителем и теперь тоже поддерживает создание массивов из std::shared_ptr. Например:

-   std::shared_ptr<double[]> shar = std::make_shared<double[]>(1024): создает std::shared_ptr c 1024 значениями типа double, проинициализированными по умолчанию;
    
-   std::shared_ptr<double[]> shar = std::make_shared<double[]>(1024, 1.0): создает std::shared_ptr c 1024 значениями типа double, проинициализированными значениями, равными 1,0.

Как обычно make функции немного тормозят относительно типов, для которых они созданы. Типа std::make_unique появился только в с++14, хотя сам уникальный указатель был представлен в предыдущем релизе. Но главное, что эти особенности все-таки доезжают, что не может не радовать.

Enjoy small things. Stay cool.

#cpp20 #memory



Объединения условий в enable_if

Иногда мы хотим сильно ограничить свойства типов, с которыми мы хотим инстанцировать шаблон. Например, тип должен быть default-constructed и иметь оператор сравнения. У нас есть для этого метафункция std::enable_if, которая позволяет нам проверять наличие свойств у типов. Но вот незадача, как проверить два условия одновременно? Я хочу и то, и то.

Ранее для этого требовалось ???

Однако в С++17 появились специальные метафункции, которые позволяют комбинировать условия. Это 

• template<class... B> struct conjunction; -  логическое И 
• template<class... B> struct disjunction; - логическое ИЛИ
• template<class B> struct negation; - логичесткое НЕ

Эти функции имеют подходящие осмысленные имена, поэтому их использование повышает читаемость кода. Пример с несколькими интами из книжки.